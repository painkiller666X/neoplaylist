#!/usr/bin/env python3
# coding: utf-8
"""
NeoPlaylist API - refined V15
- Basada en V10 funcional
- Mejoras:
  * Parsing robusto de respuestas Ollama (maneja JSON mal formateado y listas en texto)
  * Ciclo h√≠brido DB-assisted m√°s s√≥lido (pide sugerencias, valida, pasa artistas locales, fallback directo)
  * Registro h√≠brido persistente (logs/hybrid_results_log.json)
  * Popularidad relativa por g√©nero
  * Filtros emocionales aplicados s√≥lo si prompt contiene indicadores emocionales
  * Inspecci√≥n final para eliminar incongruencias groseras
  * Mantiene dedupe, preferencia por bitrate, ranking, m3u, endpoints
"""

# ============================================================
# üß© IMPORTS LIMPIOS Y ORGANIZADOS
# ============================================================

# --- Librer√≠as est√°ndar ---
import os
import re
import json
import math
import time
import uuid
import logging
import urllib.parse
from datetime import datetime
from collections import Counter
from statistics import mean
from typing import List, Dict, Any, Optional, Tuple
from urllib.parse import quote_plus

# --- Librer√≠as de terceros ---
import requests
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Request
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from pymongo import MongoClient
from bson import ObjectId
import uvicorn

# --- M√≥dulos locales ---
from auth_beta2 import router as auth_router


load_dotenv()

# Codifica contrase√±a autom√°ticamente
mongo_user = os.getenv("MONGO_USER", "NeoPlaylistUser")
mongo_pass = os.getenv("MONGO_PASS", "NeoUser123.!")
mongo_host = os.getenv("MONGO_HOST", "localhost:27017")
mongo_db_music = os.getenv("MONGO_DB_MUSIC", "musicdb")

# -----------------------
# Config
# -----------------------
#MONGO_URI_PL = os.getenv("MONGO_URI_PL", "mongodb://localhost:27017")

# Base de datos de usuarios / auth
MONGO_URI = os.getenv("MONGO_URI", "mongodb://localhost:27017/?authSource=authdb")

#MONGO_URI = os.getenv("MONGO_URI", "mongodb://192.168.100.169:27017/?authSource=authdb")



# Base de datos musical
MONGO_URI_MUSIC = f"mongodb://{mongo_user}:{quote_plus(mongo_pass)}@{mongo_host}/{mongo_db_music}?authSource={mongo_db_music}"


MONGO_DB = os.getenv("MONGO_DB", "musicdb")

#OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434/api/generate")
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://127.0.0.1:11434/api/generate")
MODEL_NAME = os.getenv("MODEL_NAME", "neoplaylist-agent")
GENERATED_DIR = os.path.join(os.getcwd(), "generated_playlists")
LOGS_DIR = os.path.join(os.getcwd(), "logs")
HYBRID_LOG_PATH = os.path.join(LOGS_DIR, "hybrid_results_log.json")
os.makedirs(GENERATED_DIR, exist_ok=True)
os.makedirs(LOGS_DIR, exist_ok=True)

# -----------------------
# Logging refinado (versi√≥n robusta)
# -----------------------
logger = logging.getLogger("neoplaylist_v15")

# Evita duplicar handlers al recargar
if not logger.hasHandlers():
    logger.setLevel(logging.DEBUG)

    # üî∏ Consola (solo INFO+)
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s"))

    # üî∏ Archivo completo (DEBUG)
    os.makedirs("logs", exist_ok=True)
    file_handler = logging.FileHandler(os.path.join("logs", "debug_full.log"), mode="a", encoding="utf-8")
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(message)s"))

    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

    logger.info("üü£ [NeoPlaylist V15] Logging inicializado correctamente.")
    logger.debug("============================================")
    logger.debug(" Nuevo ciclo de ejecuci√≥n iniciado")
    logger.debug("============================================")

# üîá Silencia log ra√≠z de Uvicorn
logging.getLogger("uvicorn").setLevel(logging.WARNING)
logging.getLogger("uvicorn.error").setLevel(logging.WARNING)
logging.getLogger("uvicorn.access").setLevel(logging.WARNING)

# Mongo

# Conexiones separadas

client_music = MongoClient(MONGO_URI_MUSIC)
db_music = client_music[mongo_db_music]


client_auth = MongoClient(MONGO_URI)
db_auth = client_auth["authdb"]


tracks_col = db_music["tracks"]
playlists_col = db_music["playlists"]
feedback_col = db_music["playlist_feedback"]

app = FastAPI(title="NeoPlaylist API (V15 definitive)")

# ‚úÖ CORS debe venir antes de los routers
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)




# Montar acceso est√°tico a tu carpeta de m√∫sica
app.mount("/media", StaticFiles(directory="F:\\Musica"), name="media")

# If you have an auth router file, include it here. It'll be optional.
# üîê Importar rutas de autenticaci√≥n
try:
    app.include_router(auth_router)
    logger.debug("‚úÖ auth_router cargado desde auth_beta2.py")
except ImportError:
    logger.debug("‚ö†Ô∏è No se encontr√≥ auth_beta2.py, continuando sin rutas de auth")


# -----------------------
# Campos permitidos y mapeos emocionales
# -----------------------
ALLOWED_FIELDS = {
    "Genero", "A√±o", "Decada", "TempoBPM", "EnergyRMS", "LoudnessLUFS",
    "SpectralCentroidHz", "CrestFactordB", "EMO_Context1", "EMO_Sound",
    "EMO_Lyrics", "PopularityScore", "LastFMPlaycount", "YouTubeViews",
    "LastFMListeners", "TopCountry1", "EstimatedKey", "Titulo", "Artista", "Album", "Idioma"
}
ALLOWED_OPERATORS = {"$gt", "$lt", "$gte", "$lte", "$in", "$regex", "$options", "$not", "$ne", "$exists", "$eq"}

# EMO maps (compact, extendible)
EMO_LYRICS_MAP = {
    "feliz": "Joy / Happy", "alegre": "Joy / Happy", "alegria": "Joy / Happy",
    "amor": "Love / Romantic", "romantico": "Love / Romantic", "rom√°ntico": "Love / Romantic",
    "triste": "Sadness", "melancol": "Sadness", "melanc√≥lico": "Sadness",
    "enojo": "Anger", "enojado": "Anger", "miedo": "Fear / Anxiety",
    "sorpresa": "Surprise / Wonder", "neutral": "Neutral / Storytelling",
    "desilusion": "Disappointment", "disappointment": "Disappointment",
    "curiosidad": "Curiosity", "confusion": "Confusion", "desaprobacion": "Disapproval",
    "deseo": "Desire", "desire": "Desire", "gracias": "Gratitude", "gratitud": "Gratitude",
    "superacion": "Joy / Happy", "superaci√≥n": "Joy / Happy"
}

EMO_SOUND_MAP = {
    "energetic": "Energetic / Uplifting", "energ√©tica": "Energetic / Uplifting",
    "uplifting": "Energetic / Uplifting", "positivo": "Groovy / Positive", "positiva": "Groovy / Positive",
    "groovy": "Groovy / Positive", "bailable": "Groovy / Positive", "calm": "Calm / Neutral",
    "calma": "Calm / Neutral", "relaj": "Calm / Neutral", "sad": "Sad / Melancholic",
    "melancolic": "Sad / Melancholic", "melanc√≥lico": "Sad / Melancholic"
}

EMO_CONTEXT_FAMILIES = {
    "dolor": "Dolor y p√©rdida", "p√©rdida": "Dolor y p√©rdida", "desamor": "Dolor y p√©rdida",
    "soledad": "Dolor y p√©rdida", "nostalgia": "Dolor y p√©rdida",
    "amor": "Amor y deseo", "romance": "Amor y deseo",
    "traici√≥n": "Conflicto y traici√≥n", "venganza": "Conflicto y traici√≥n",
    "superaci√≥n": "Superaci√≥n y resiliencia", "resiliencia": "Superaci√≥n y resiliencia",
    "fiesta": "Celebraci√≥n y vida social", "baile": "Celebraci√≥n y vida social",
    "amistad": "Celebraci√≥n y vida social",
    "guerra": "Conflictos humanos", "protesta": "Conflictos humanos",
    "orgullo": "Orgullo y poder", "existencial": "Existencial / espiritual", "espiritual": "Existencial / espiritual"
}

# terms that indicate emotional intent in prompt (if present -> apply emotion filters)
EMOTION_INDICATORS = set(list(EMO_LYRICS_MAP.keys()) + list(EMO_SOUND_MAP.keys()) + list(EMO_CONTEXT_FAMILIES.keys()) + [
    "triste", "nostalg", "romant", "amor", "ira", "feliz", "alegr", "melancol", "enoj", "emocion", "emocional", "superaci√≥n", "superacion"
])

# dance-like genres regex for quick checks
DANCE_GENRE_REGEX = re.compile(r"(dance|dancehall|disco|house|reggaeton|cumbia|salsa|merengue|funk|pop|electr[o√≥]nica|latina|tropical|afrobeat|samba|bachata)", re.I)
HEAVY_GENRE_REGEX = re.compile(r"(metal|heavy|hard rock|thrash|death metal|grindcore|metalcore|stoner|grunge)", re.I)


def parse_filters_from_llm(llm_filters: dict) -> dict:
    """
    Normaliza filtros que provienen del LLM con soporte para pa√≠ses, a√±os espec√≠ficos y d√©cadas.
    Maneja diferentes formas en que el LLM puede expresar la temporalidad y ubicaci√≥n.
    """
    if not llm_filters:
        return {}

    out = {}
    decada_detectada = None

    # ‚úÖ NUEVO: Manejar filtros de pa√≠s (ORIGEN vs POPULARIDAD)
    if "country" in llm_filters and llm_filters["country"]:
        country = llm_filters["country"]
        country_type = llm_filters.get("country_type", "origin")
        
        if country_type == "origin":
            # Filtro por pa√≠s de origen del artista
            out["ArtistArea"] = {"$regex": f"^{re.escape(country)}$", "$options": "i"}
            logger.debug(f"üá®üá± Filtro por pa√≠s de origen: {country}")
        elif country_type == "popular_in":
            # Filtro por popularidad en el pa√≠s (TopCountry1, TopCountry2, TopCountry3)
            out["$or"] = [
                {"TopCountry1": {"$regex": f"^{re.escape(country)}$", "$options": "i"}},
                {"TopCountry2": {"$regex": f"^{re.escape(country)}$", "$options": "i"}},
                {"TopCountry3": {"$regex": f"^{re.escape(country)}$", "$options": "i"}}
            ]
            logger.debug(f"üá®üá± Filtro por popularidad en pa√≠s: {country}")

    # ‚úÖ MEJORADO: Distinguir entre A√ëO ESPEC√çFICO y D√âCADA
    # Prioridad: a√±o espec√≠fico > rango de a√±os > d√©cada
    
    # 1Ô∏è‚É£ A√ëO ESPEC√çFICO (ej: "2015", "del 2018")
    if "year" in llm_filters and llm_filters["year"] is not None:
        year_val = llm_filters["year"]
        if isinstance(year_val, (int, float)) and 1950 <= year_val <= 2030:
            out["A√±o"] = {"$gte": int(year_val), "$lt": int(year_val) + 1}
            logger.debug(f"üìÖ Filtro por A√ëO ESPEC√çFICO: {year_val}")
            # Si hay a√±o espec√≠fico, NO aplicar d√©cada
            decada_detectada = None

    # 2Ô∏è‚É£ RANGO DE A√ëOS ESPEC√çFICOS (ej: "entre 2010 y 2015")
    elif "year_range" in llm_filters and isinstance(llm_filters["year_range"], dict):
        year_range = llm_filters["year_range"]
        if "from" in year_range and "to" in year_range:
            try:
                start_year = int(year_range["from"])
                end_year = int(year_range["to"])
                if 1950 <= start_year <= end_year <= 2030:
                    out["A√±o"] = {"$gte": start_year, "$lte": end_year}
                    logger.debug(f"üìÖ Filtro por RANGO DE A√ëOS: {start_year}-{end_year}")
                    # Si hay rango de a√±os, NO aplicar d√©cada
                    decada_detectada = None
            except (ValueError, TypeError):
                pass

    # 3Ô∏è‚É£ D√âCADA (solo si no hay a√±o espec√≠fico ni rango)
    elif "decada" in llm_filters or "d√©cada" in llm_filters or "decade" in llm_filters:
        decade_key = None
        for key in ["decada", "d√©cada", "decade"]:
            if key in llm_filters:
                decade_key = key
                break
        
        if decade_key:
            v = llm_filters[decade_key]
            
            # ‚úÖ SOPORTE PARA LISTAS DE D√âCADAS (ej: "los 80 y 90")
            if isinstance(v, list):
                decade_ranges = []
                valid_decades = []
                for decade_str in v:
                    if isinstance(decade_str, str):
                        m = re.search(r"(\d{2,4})", decade_str)
                        if m:
                            yy = m.group(1)
                            if len(yy) == 2:
                                start = 1900 + int(yy)
                            else:
                                start = int(yy) if len(yy) == 4 else None
                            if start and 1950 <= start < 2030:
                                decade_ranges.append({"$gte": start, "$lt": start + 10})
                                valid_decades.append(decade_str)
                
                if decade_ranges:
                    # Crear condici√≥n OR para m√∫ltiples rangos de a√±os
                    out["A√±o"] = {"$or": decade_ranges}
                    out["Decada"] = {"$in": valid_decades}
                    logger.debug(f"üï∞Ô∏è M√öLTIPLES D√âCADAS aplicadas: {valid_decades}")
                    
            elif isinstance(v, str):
                # Procesamiento normal para d√©cada √∫nica
                m = re.search(r"(\d{2,4})", v)
                if m:
                    yy = m.group(1)
                    if len(yy) == 2:
                        start = 1900 + int(yy)
                    else:
                        start = int(yy) if len(yy) == 4 else None
                    if start and 1950 <= start < 2030:
                        out["A√±o"] = {"$gte": start, "$lt": start + 10}
                        decada_detectada = f"{start}s"
                        out["Decada"] = decada_detectada
                        logger.debug(f"üï∞Ô∏è D√âCADA √∫nica aplicada: {decada_detectada}")
                        
            elif isinstance(v, dict):
                # Manejo de d√©cadas en formato dict (compatibilidad)
                if "$gte" in v or "$gt" in v or "$lte" in v or "$lt" in v:
                    out["A√±o"] = {}
                    for op in ("$gte", "$gt", "$lte", "$lt"):
                        if op in v:
                            out["A√±o"][op] = v[op]
                    start = out["A√±o"].get("$gte")
                    if isinstance(start, (int, float)) and 1950 <= start < 2030:
                        decada_detectada = f"{int(start)//10}0s"
                        out["Decada"] = decada_detectada
                        logger.debug(f"üï∞Ô∏è D√âCADA desde dict: {decada_detectada}")
                        
            elif isinstance(v, (int, float)) and 1950 <= v < 2030:
                start = int(v)
                out["A√±o"] = {"$gte": start, "$lt": start + 10}
                decada_detectada = f"{start}s"
                out["Decada"] = decada_detectada
                logger.debug(f"üï∞Ô∏è D√âCADA desde n√∫mero: {decada_detectada}")

    # üîπ MANEJO TRADICIONAL del campo "A√±o" (para compatibilidad)
    if "A√±o" in llm_filters and "A√±o" not in out:
        v = llm_filters["A√±o"]
        if isinstance(v, dict):
            out["A√±o"] = v
            start = v.get("$gte") or v.get("$gt")
            if isinstance(start, (int, float)) and 1950 <= start < 2030:
                decada_detectada = f"{int(start)//10}0s"
                out["Decada"] = decada_detectada
        elif isinstance(v, (int, float)) and 1950 <= v < 2030:
            out["A√±o"] = {"$gte": int(v), "$lt": int(v) + 1}
            decada_detectada = f"{int(v)//10}0s"
            out["Decada"] = decada_detectada
        else:
            # Extraer a√±os del string
            m = re.findall(r"\d{4}", str(v))
            if len(m) == 1:
                year_val = int(m[0])
                if 1950 <= year_val < 2030:
                    out["A√±o"] = {"$gte": year_val, "$lt": year_val + 1}
                    decada_detectada = f"{year_val//10}0s"
                    out["Decada"] = decada_detectada
            elif len(m) == 2:
                start_year, end_year = int(m[0]), int(m[1])
                if 1950 <= start_year <= end_year < 2030:
                    out["A√±o"] = {"$gte": start_year, "$lt": end_year + 1}
                    decada_detectada = f"{start_year//10}0s"
                    out["Decada"] = decada_detectada

    # üîπ G√âNERO (evitar sesgos autom√°ticos como "pop" para "m√∫sica chilena")
    if "genero" in llm_filters or "g√©nero" in llm_filters or "genre" in llm_filters:
        genre_key = None
        for key in ["genero", "g√©nero", "genre"]:
            if key in llm_filters:
                genre_key = key
                break
        
        if genre_key:
            v = llm_filters[genre_key]
            # ‚úÖ SOLO aplicar g√©nero si fue EXPL√çCITAMENTE solicitado
            # Evitar que el LLM a√±ada g√©neros por su cuenta
            if v and v not in ["pop", "rock", "otros g√©neros comunes"]:  # Filtrar sugerencias autom√°ticas
                if isinstance(v, str):
                    out["Genero"] = {"$regex": v, "$options": "i"}
                    logger.debug(f"üéµ G√©nero aplicado (expl√≠cito): {v}")
                elif isinstance(v, list):
                    escaped = "|".join([re.escape(str(x)) for x in v if x])
                    if escaped:
                        out["Genero"] = {"$regex": f"({escaped})", "$options": "i"}
                        logger.debug(f"üéµ M√∫ltiples g√©neros aplicados: {v}")
                elif isinstance(v, dict):
                    out["Genero"] = v

    # üîπ CAMPOS EMOCIONALES (EMO_Sound, EMO_Lyrics, EMO_Context)
    for emo_field in ["EMO_Sound", "EMO_Lyrics", "EMO_Context1", "EMO_Context2", "EMO_Context3"]:
        if emo_field in llm_filters:
            v = llm_filters[emo_field]
            if isinstance(v, str):
                out[emo_field] = {"$regex": v, "$options": "i"}
            elif isinstance(v, dict):
                out[emo_field] = v

    # üîπ OTROS CAMPOS PERMITIDOS
    allowed_fields = {
        "TempoBPM", "EnergyRMS", "LoudnessLUFS", "SpectralCentroidHz", 
        "CrestFactordB", "PopularityScore", "LastFMPlaycount", "YouTubeViews",
        "LastFMListeners", "EstimatedKey", "Titulo", "Artista", "Album", "Idioma"
    }
    
    for k, v in llm_filters.items():
        if k in allowed_fields and k not in out:
            if isinstance(v, str):
                out[k] = {"$regex": v, "$options": "i"}
            else:
                out[k] = v

    # üîπ CONVERSI√ìN FINAL: Si no hay a√±o pero s√≠ d√©cada detectada, convertir por compatibilidad
    if "A√±o" not in out and decada_detectada:
        try:
            start = int(decada_detectada[:4])
            if 1950 <= start < 2030:
                out["A√±o"] = {"$gte": start, "$lt": start + 10}
                logger.debug(f"üï∞Ô∏è D√©cada convertida a rango de a√±os: {decada_detectada}")
        except Exception:
            pass

    # ‚úÖ LOG FINAL DE FILTROS APLICADOS
    if out:
        logger.debug(f"üéØ FILTROS FINALES APLICADOS:")
        for key, value in out.items():
            if key == "$or":
                logger.debug(f"   ‚Ü≥ {key}: [condiciones de pa√≠s]")
            else:
                logger.debug(f"   ‚Ü≥ {key}: {value}")
    else:
        logger.debug("üéØ No se aplicaron filtros espec√≠ficos")

    return out


# -----------------------
# Helpers: LLM / sanitize / parse AI outputs robustly
# -----------------------
# =============================================================
# [V11.1+] Bloque de compatibilidad con nuevo Modelfile h√≠brido
# =============================================================


def parse_llm_response_v11_1(data: Any) -> Dict[str, Any]:
    """
    Interpreta el nuevo formato JSON h√≠brido:
    {
      "filters": {...},
      "suggestions": [...],
      "context_validation": {...},
      "sort_by": "...",
      "order": -1,
      "limit": 40
    }
    """
    if not data:
        return {"filters": {}, "suggestions": []}

    if isinstance(data, str):
        try:
            data = json.loads(data)
        except Exception:
            try:
                m = re.search(r"(\{(?:.|\s)*\})", data)
                if m:
                    data = json.loads(m.group(1))
            except Exception:
                return {"filters": {}, "suggestions": []}

    filters = data.get("filters", {}) if isinstance(data.get("filters"), dict) else {}
    suggestions = data.get("suggestions", []) or []
    if not isinstance(suggestions, list):
        suggestions = []

    context_validation = data.get("context_validation", {})
    sort_by = data.get("sort_by")
    order = data.get("order", -1)
    limit = data.get("limit", 50)

    return {
        "filters": filters,
        "suggestions": suggestions,
        "context_validation": context_validation,
        "sort_by": sort_by,
        "order": order,
        "limit": limit
    }


def collect_local_context(max_artists: int = 100, max_genres: int = 60) -> Dict[str, List[str]]:
    """Obtiene artistas y g√©neros de la DB local para dar contexto al modelo."""
    try:
        artists = tracks.distinct("Artista")
        genres = tracks.distinct("Genero")
        artists = [a for a in artists if isinstance(a, str) and len(a.strip()) > 1][:max_artists]
        genres = [g for g in genres if isinstance(g, str) and len(g.strip()) > 1][:max_genres]
        return {"artists": artists, "genres": genres}
    except Exception as e:
        logger.debug(f"Error obteniendo contexto local: {e}")
        return {"artists": [], "genres": []}


def call_ollama_v11_1(prompt: str, context: Optional[Dict[str, List[str]]] = None, timeout: int = 40, max_retries: int = 2):
    """
    Env√≠a prompt a Ollama (modelo neoplaylist-agent) con manejo robusto:
      - Soporta contexto local (artistas/g√©neros)
      - Timeouts y reintentos
      - Logs detallados del contenido y del JSON parseado
    """
    OLLAMA_URL = "http://localhost:11434/api/generate"
    MODEL_NAME = "neoplaylist-agent"

    if context:
        ctx_artists = ", ".join(context.get("artists", [])[:40])
        ctx_genres = ", ".join(context.get("genres", [])[:30])
        prompt = (
            f"{prompt}\n\n"
            f"--- CONTEXTO LOCAL ---\n"
            f"Artistas disponibles localmente:\n{ctx_artists}\n\n"
            f"G√©neros locales:\n{ctx_genres}\n"
        )

    logging.info(f"üß† Llamando a Ollama ({MODEL_NAME}) con timeout={timeout}s")
    payload = {"model": MODEL_NAME, "prompt": prompt, "stream": False}

    for attempt in range(1, max_retries + 1):
        try:
            logging.debug(f"‚öôÔ∏è Intento {attempt}/{max_retries} ‚Üí prompt parcial: {prompt[:120]}...")
            r = requests.post(OLLAMA_URL, json=payload, timeout=timeout)
            if r.status_code != 200:
                logging.warning(f"‚ö†Ô∏è Ollama devolvi√≥ {r.status_code}: {r.text}")
                continue

            raw_text = r.text.strip()
            logging.debug(f"üîç Respuesta bruta ({len(raw_text)} bytes): {raw_text[:300]}")

            # Extraer bloque JSON v√°lido
            try:
                data = json.loads(raw_text)
            except json.JSONDecodeError:
                json_str = raw_text[raw_text.find("{"): raw_text.rfind("}") + 1]
                data = json.loads(json_str)

            if not isinstance(data, dict):
                logging.warning("‚ö†Ô∏è Respuesta no es JSON dict. Devolviendo vac√≠o.")
                return {"filters": {}, "error": "respuesta malformada"}

            # Validaci√≥n b√°sica
            if "filters" not in data:
                logging.warning("‚ö†Ô∏è Falta campo 'filters' en respuesta Ollama.")
                data["filters"] = {}

            logging.info(f"‚úÖ Ollama devolvi√≥ filtros: {list(data['filters'].keys())}")
            if "suggestions" in data:
                logging.info(f"üí° {len(data['suggestions'])} sugerencias h√≠bridas incluidas.")
            if "context_validation" in data:
                logging.info(f"üìò Contexto validado por modelo: {data['context_validation']}")

            return data

        except requests.exceptions.Timeout:
            logging.error(f"‚è≥ Ollama no respondi√≥ en {timeout}s (intento {attempt}).")
        except requests.exceptions.ConnectionError:
            logging.error("üö´ No se pudo conectar a Ollama (verifica que est√© ejecut√°ndose).")
        except Exception as e:
            logging.exception(f"‚ùå Error inesperado llamando a Ollama: {e}")

    logging.error("‚ùå Todos los intentos de conexi√≥n fallaron. Se usar√° solo Mongo.")
    return {"filters": {}, "error": "Ollama no respondi√≥"}


def hybrid_playlist_cycle(user_prompt: str, model="neoplaylist-agent", default_limit=30):
    """
    Ciclo h√≠brido de generaci√≥n de playlist MEJORADO:
    1Ô∏è‚É£ An√°lisis de intenci√≥n sem√°ntica
    2Ô∏è‚É£ Recomendaciones iniciales del modelo  
    3Ô∏è‚É£ Completitud con artistas locales si faltan resultados
    4Ô∏è‚É£ Validaci√≥n y equilibrio final
    """

    logger.debug(f"üß† Nueva consulta h√≠brida: {user_prompt}")

    # --- FASE 0: AN√ÅLISIS SEM√ÅNTICO MEJORADO ---
    llm_analysis = analyze_query_intent(user_prompt)
    detected_limit = llm_analysis.get("detected_limit", default_limit)
    actual_limit = min(detected_limit, 100)  # L√≠mite m√°ximo por seguridad
    limit = actual_limit
    
    # ‚úÖ EXTRAER FILTROS DEL AN√ÅLISIS SEM√ÅNTICO
    semantic_filters = {}
    
    # A√±adir g√©nero si est√° presente
    genre = llm_analysis.get("genre")
    if genre:
        semantic_filters["Genero"] = {"$regex": genre, "$options": "i"}
        logger.debug(f"üéµ Filtro sem√°ntico de g√©nero: {genre}")
    
    # A√±adir d√©cada si est√° presente (CR√çTICO - esto es lo que falta)
    decade = llm_analysis.get("decade")
    if decade:
        semantic_filters["Decada"] = decade
        logger.debug(f"üï∞Ô∏è Filtro sem√°ntico de d√©cada: {decade}")
        
        # Tambi√©n a√±adir rango de a√±os para compatibilidad
        if decade == "1980s":
            semantic_filters["A√±o"] = {"$gte": 1980, "$lt": 1990}
        elif decade == "1990s":
            semantic_filters["A√±o"] = {"$gte": 1990, "$lt": 2000}
        elif decade == "2000s":
            semantic_filters["A√±o"] = {"$gte": 2000, "$lt": 2010}
        elif decade == "2010s":
            semantic_filters["A√±o"] = {"$gte": 2010, "$lt": 2020}
        elif decade == "2020s":
            semantic_filters["A√±o"] = {"$gte": 2020, "$lt": 2030}
    
    # A√±adir mood/emoci√≥n si est√° presente
    mood = llm_analysis.get("mood")
    if mood:
        semantic_filters["EMO_Sound"] = {"$regex": mood, "$options": "i"}
        logger.debug(f"üòä Filtro sem√°ntico de mood: {mood}")

    logger.debug(f"üéØ An√°lisis sem√°ntico: {llm_analysis}")
    logger.debug(f"üîç Filtros sem√°nticos extra√≠dos: {semantic_filters}")

    # --- FASE 1: Recomendaciones iniciales del modelo ---
    result = call_ollama_safe(user_prompt, model) or {}
    
    # ‚úÖ DEBUG DETALLADO DE LA RESPUESTA
    if "error" in result:
        logger.warning(f"‚ö†Ô∏è Error en llamada a Ollama: {result['error']}")
    else:
        logger.debug(f"‚úÖ Respuesta Ollama recibida, keys: {list(result.keys())}")
        
    llm_filters = result.get("filters", {}) or {}
    suggestions = result.get("suggestions", [])

    # --- COMBINAR FILTROS SEM√ÅNTICOS + FILTROS OLLAMA ---
    filters = parse_filters_from_llm(llm_filters)
    
    # ‚úÖ COMBINAR CON FILTROS SEM√ÅNTICOS (los sem√°nticos tienen prioridad)
    for key, value in semantic_filters.items():
        if key not in filters:  # Los filtros sem√°nticos no sobrescriben los de Ollama
            filters[key] = value
            logger.debug(f"‚ûï A√±adido filtro sem√°ntico: {key} = {value}")

    # üîπ Normalizar campo temporal antes de aplicar filtro
    if "A√±o" in filters and isinstance(filters["A√±o"], dict):
        rango = filters["A√±o"]
        if "$gte" in rango and "$lt" in rango:
            start = rango["$gte"]
            if isinstance(start, (int, float)) and 1950 <= start < 2030:
                decada = f"{int(start)//10}0s"
                filters["Decada"] = decada
                logger.debug(f"üï∞Ô∏è Convertido rango de a√±os {rango} ‚Üí D√©cada '{decada}'")
        filters.pop("A√±o", None)
    elif "A√±o" in filters and isinstance(filters["A√±o"], str):
        if filters["A√±o"].endswith("s"):
            filters["Decada"] = filters.pop("A√±o")

    logger.debug(f"üîç Filtros combinados finales: {filters}")

    # --- Buscar coincidencias locales flexibles ---
    local_tracks = search_tracks_with_emotional_filters(filters, limit, tracks_col)
    logger.debug(f"üéØ Fase 1: {len(local_tracks)} pistas encontradas / objetivo {limit}")

    if len(local_tracks) >= limit:
        return finalize_response(user_prompt, filters, local_tracks, 1, limit)

    # --- FASE 2: Completitud (faltan resultados) ---
    missing = limit - len(local_tracks)
    artists_local = list(tracks_col.distinct("Artista"))
    max_suggestions = min(30, missing * 3)

    completion_prompt = (
        f"Faltan resultados para completar la playlist del usuario.\n\n"
        f"Petici√≥n original: \"{user_prompt}\"\n\n"
        f"An√°lisis sem√°ntico: {json.dumps(llm_analysis, ensure_ascii=False, default=str)}\n\n"
        f"Filtros aplicados: {json.dumps(filters, ensure_ascii=False, default=str)}\n\n"
        f"A continuaci√≥n, una lista de artistas disponibles localmente:\n"
        + ", ".join(artists_local[:30]) + ("\n..." if len(artists_local) > 30 else "\n")
        + f"\nProvee hasta {max_suggestions} sugerencias adicionales de canciones o artistas que encajen con la petici√≥n, "
        "manteniendo los mismos filtros de g√©nero, d√©cada, energ√≠a y emoci√≥n.\n"
        "Devuelve EXCLUSIVAMENTE JSON v√°lido con formato:\n"
        "{\"suggestions\": [{\"titulo\": \"...\", \"artista\": \"...\", \"album\": \"...\"}]}\n"
        "Si no puedes sugerir nada coherente, devuelve {\"suggestions\": []}."
    )

    result2 = call_ollama_safe(completion_prompt, model) or {}
    suggestions2 = result2.get("suggestions", [])

    # üîπ Mantener filtros previos si el modelo no devuelve nuevos
    filters = result2.get("filters") or filters or {}

    # üîπ Reaplicar normalizaci√≥n temporal por seguridad
    if "A√±o" in filters and isinstance(filters["A√±o"], dict):
        rango = filters["A√±o"]
        if "$gte" in rango and "$lt" in rango:
            start = rango["$gte"]
            if isinstance(start, (int, float)) and 1950 <= start < 2030:
                decada = f"{int(start)//10}0s"
                filters["Decada"] = decada
                logger.debug(f"üï∞Ô∏è Convertido rango de a√±os {rango} ‚Üí D√©cada '{decada}'")
        filters.pop("A√±o", None)

    local_tracks2 = search_tracks_in_mongo(suggestions2, filters, missing, tracks_col)
    local_tracks += local_tracks2
    logger.debug(f"üéØ Fase 2: +{len(local_tracks2)} nuevas pistas ‚Üí total {len(local_tracks)}")

    if len(local_tracks) >= limit:
        return finalize_response(user_prompt, filters, local_tracks, 2, limit)

    # --- FASE 3: Validaci√≥n y equilibrio ---
    validation_prompt = (
        f"Valida y depura esta lista de {len(local_tracks)} pistas seg√∫n el prompt original:\n"
        f"\"{user_prompt}\"\n\n"
        f"An√°lisis sem√°ntico: {json.dumps(llm_analysis, ensure_ascii=False, default=str)}\n\n"
        f"Filtros aplicados: {json.dumps(filters, ensure_ascii=False, default=str)}\n\n"
        "Elimina canciones incoherentes con el g√©nero, √©poca, energ√≠a o emoci√≥n del prompt.\n"
        "Evita m√°s del 20% de pistas por artista y m√°ximo 2 del mismo √°lbum.\n"
        "Devuelve SOLO JSON v√°lido en formato:\n"
        "{\"suggestions\": [{\"titulo\": \"...\", \"artista\": \"...\", \"album\": \"...\"}]}\n"
        "Si consideras que la lista ya es coherente, devu√©lvela igual."
    )

    validation_input = (
        validation_prompt
        + "\n\nLista de pistas actuales:\n"
        + json.dumps([{k: v for k, v in track.items() if k != '_id'} for track in local_tracks], 
                    ensure_ascii=False, default=str)
    )

    result3 = call_ollama_safe(validation_input, model) or {}

    # üîπ Preservar filtros entre fases
        # SOLUCI√ìN:
    if isinstance(result3, dict):
        filters = result3.get("filters") or filters or {}
    else:
        # Si result3 es una lista u otro tipo, mantener los filtros anteriores
        filters = filters or {}
        logger.warning(f"‚ö†Ô∏è Result3 no es dict, es {type(result3)}. Manteniendo filtros anteriores.")

    # üîπ Revalidar campo temporal si reaparece "A√±o"
    if "A√±o" in filters and isinstance(filters["A√±o"], dict):
        rango = filters["A√±o"]
        if "$gte" in rango and "$lt" in rango:
            start = rango["$gte"]
            if isinstance(start, (int, float)) and 1950 <= start < 2030:
                decada = f"{int(start)//10}0s"
                filters["Decada"] = decada
                logger.debug(f"üï∞Ô∏è Convertido rango de a√±os {rango} ‚Üí D√©cada '{decada}'")
        filters.pop("A√±o", None)

    validated = result3.get("suggestions", [])
    if not validated:
        validated = local_tracks

    # Si elimin√≥ demasiadas, rellenar con las previas coherentes
    if len(validated) < limit:
        validated += [t for t in local_tracks if t not in validated][:limit - len(validated)]

    logger.debug(f"‚úÖ Fase 3 finalizada ‚Äî total {len(validated[:limit])} pistas validadas")
    logger.debug(f"üï∞Ô∏è Filtro temporal final aplicado: {filters.get('Decada')}")

    return finalize_response(user_prompt, filters, validated[:limit], 3, limit)



def search_tracks_in_mongo(suggestions, llm_filters, limit, tracks_col, user_prompt=None):
    """
    Busca sugerencias en Mongo combinando coincidencias flexibles (Titulo/Artista/Album)
    y los filtros normalizados del LLM.
    MEJORADO: Manejo robusto de filtros de d√©cada y pa√≠s.
    """
    results = []
    seen_rutas = set()
    normalized_filters = parse_filters_from_llm(llm_filters or {})
    
    logger.debug(f"üîç Buscando con {len(suggestions)} sugerencias y filtros: {normalized_filters}")

    # ‚úÖ ESTRATEGIA 1: B√∫squeda por sugerencias espec√≠ficas (si existen)
    if suggestions:
        for s in suggestions:
            if len(results) >= limit:
                break

            titulo = (s.get("titulo") or "").strip()
            artista = (s.get("artista") or "").strip()
            album = (s.get("album") or "").strip()

            # Construir query
            and_clauses = []
            or_clauses = []

            if titulo:
                or_clauses.append({"Titulo": {"$regex": re.escape(titulo), "$options": "i"}})
            if artista:
                or_clauses.append({"Artista": {"$regex": re.escape(artista), "$options": "i"}})
            if album:
                or_clauses.append({"Album": {"$regex": re.escape(album), "$options": "i"}})

            if or_clauses:
                and_clauses.append({"$or": or_clauses})

            # Inyectar filtros LLM normalizados
            if normalized_filters:
                and_clauses.append(normalized_filters)

            # Si no hay condiciones (ni suggestion ni filtros), saltar
            if not and_clauses:
                continue

            query = {"$and": and_clauses} if len(and_clauses) > 1 else and_clauses[0]

            try:
                found = list(tracks_col.find(query).limit(5))  # buscar hasta 5 coincidencias por suggestion
            except Exception:
                logger.exception("Mongo find error in search_tracks_in_mongo")
                found = []

            for f in found:
                ruta = f.get("Ruta")
                if ruta and ruta not in seen_rutas:
                    results.append(f)
                    seen_rutas.add(ruta)
                    if len(results) >= limit:
                        break

    # ‚úÖ ESTRATEGIA 2: B√∫squeda DIRECTA por filtros (si no hay suficientes resultados)
    if len(results) < limit and normalized_filters:
        logger.debug(f"üéØ Pocos resultados ({len(results)}), buscando DIRECTAMENTE con filtros")
        
        try:
            # Buscar directamente con los filtros, ordenando por popularidad
            direct_query = normalized_filters
            
            # Agregar ordenamiento por popularidad
            direct_results = list(tracks_col.find(direct_query).sort("PopularityScore", -1).limit(limit * 2))
            
            for f in direct_results:
                ruta = f.get("Ruta")
                if ruta and ruta not in seen_rutas:
                    results.append(f)
                    seen_rutas.add(ruta)
                    if len(results) >= limit:
                        break
                        
            logger.debug(f"üéØ B√∫squeda directa a√±adi√≥ {len(direct_results)} pistas candidatas")
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Error en b√∫squeda directa por filtros: {e}")

    # ‚úÖ ESTRATEGIA 3: B√∫squeda por d√©cada espec√≠fica si est√° en los filtros
    if len(results) < limit and "Decada" in normalized_filters:
        try:
            decade_query = {"Decada": normalized_filters["Decada"]}
            decade_results = list(tracks_col.find(decade_query).sort("PopularityScore", -1).limit(limit))
            
            for f in decade_results:
                ruta = f.get("Ruta")
                if ruta and ruta not in seen_rutas:
                    results.append(f)
                    seen_rutas.add(ruta)
                    if len(results) >= limit:
                        break
                        
            logger.debug(f"üï∞Ô∏è B√∫squeda por d√©cada a√±adi√≥ {len(decade_results)} pistas")
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Error en b√∫squeda por d√©cada: {e}")

    # ‚úÖ ESTRATEGIA 4: B√∫squeda por palabras clave del prompt (fallback)
    if len(results) < limit and not suggestions and not normalized_filters and user_prompt:
        logger.debug("üîÑ Usando b√∫squeda por palabras clave como fallback")
        
        # Extraer palabras clave del prompt
        words = [w for w in re.split(r"\W+", user_prompt) if len(w) > 3]
        if words:
            keyword_query = {
                "$or": [
                    {"Genero": {"$regex": w, "$options": "i"}} for w in words
                ] + [
                    {"Titulo": {"$regex": w, "$options": "i"}} for w in words
                ] + [
                    {"Artista": {"$regex": w, "$options": "i"}} for w in words
                ]
            }
            
            keyword_results = list(tracks_col.find(keyword_query).limit(limit))
            for f in keyword_results:
                ruta = f.get("Ruta")
                if ruta and ruta not in seen_rutas:
                    results.append(f)
                    seen_rutas.add(ruta)
                    if len(results) >= limit:
                        break

    logger.debug(f"üéØ search_tracks_in_mongo -> encontrados {len(results)} (limit {limit})")
    return results



def finalize_response(prompt, filters, tracks, iterations, limit):
    """
    Arma la respuesta final para el cliente.
    - Normaliza rutas locales a URLs accesibles desde el frontend.
    - Mantiene campos originales.
    """

    def convert_path_to_url(local_path: str) -> str:
        """Convierte ruta local (ej: F:\\Musica\\A\\Artist\\file.flac) a URL HTTP accesible."""
        if not local_path:
            return ""
        path_fixed = local_path.replace("\\", "/")
        if path_fixed.lower().startswith("f:/musica/"):
            rel_path = path_fixed[9:]  # quitar "F:/Musica/"
            rel_path = urllib.parse.quote(rel_path)
            return f"http://localhost:8000/media/{rel_path}"
        return local_path

    # Normalizar rutas de cada pista
    for t in tracks:
        ruta = t.get("Ruta")
        cover = t.get("CoverCarpeta")

        # Agregar URLs HTTP sin eliminar los originales
        if ruta:
            t["StreamURL"] = convert_path_to_url(ruta)
        if cover:
            t["CoverURL"] = convert_path_to_url(cover)

    return {
        "prompt": prompt,
        "filters": filters,
        "limit": limit,
        "iterations": iterations,
        "total_found": len(tracks),
        "from_local": len(tracks),
        "playlist": tracks
    }


def attempt_json_repair(raw: str) -> dict:
    """Intenta reparar una salida JSON da√±ada del modelo."""

    logger.debug("ü©π Reparando JSON da√±ado desde Ollama...")
    cleaned = raw.strip()

    # Elimina contenido antes/despu√©s del bloque JSON
    cleaned = re.sub(r"^[^\[{]*", "", cleaned)
    cleaned = re.sub(r"[^\]}]*$", "", cleaned)

    # Reemplaza comillas rotas o comas sobrantes
    cleaned = cleaned.replace("`", '"')
    cleaned = cleaned.replace("‚Äú", '"').replace("‚Äù", '"')
    cleaned = re.sub(r",\s*}", "}", cleaned)
    cleaned = re.sub(r",\s*]", "]", cleaned)

    try:
        return json.loads(cleaned)
    except Exception as e:
        logger.error(f"üí• Reparaci√≥n fallida: {e}")
        return {"filters": {}, "suggestions": []}


def build_mongo_only_response(prompt: str, limit: int) -> dict:
    """Fallback cuando Ollama no responde: intenta buscar algo √∫til solo con Mongo."""

    #client = MongoClient(MONGO_URI)
    #db = client[MONGO_DB]

    results = list(db.tracks.find({}, {"_id": 0}).limit(limit))
    return {
        "query": prompt,
        "filters": {},
        "limit": limit,
        "suggestions": results,
        "source": "mongo_only"
    }


def try_parse_json_from_text(text: str) -> Optional[Any]:
    """Try to extract a JSON object/array from messy text. Return Python object or None."""
    if not text or not isinstance(text, str):
        return None
    text = text.strip()
    # 1) direct json
    try:
        return json.loads(text)
    except Exception:
        pass
    # 2) find first {...} or [...] block
    m = re.search(r"(\{(?:.|\s)*\})", text)
    if m:
        try:
            return json.loads(m.group(1))
        except Exception:
            pass
    m = re.search(r"(\[(?:.|\s)*\])", text)
    if m:
        try:
            return json.loads(m.group(1))
        except Exception:
            pass
    # 3) attempt to extract a "suggestions" array using regex
    m = re.search(r"\"?suggestions\"?\s*[:=]\s*(\[(?:.|\s)*\])", text, re.I)
    if m:
        try:
            return json.loads(m.group(1))
        except Exception:
            pass
    # 4) fall back: extract quoted lines / bullet lines as list of strings
    items = []
    # split lines and try to parse "Title - Artist" or plain lines
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        # skip lines that are obviously part of prompt/instructions
        if len(line) > 400:
            continue
        # remove numbering like "1)" or "- "
        line = re.sub(r"^\s*[\d\-\.\)]+\s*", "", line)
        # remove leading bullets
        line = re.sub(r"^[\-\*\‚Ä¢\u2022]\s*", "", line)
        # if line contains " - " or " ‚Äî " or " ‚Äì ", keep as single suggestion
        if re.search(r"\w\s*[-‚Äì‚Äî]\s*\w", line):
            items.append(line)
        else:
            # if line short, likely a title or artist
            if 2 <= len(line.split()) <= 8:
                items.append(line)
    if items:
        return items
    return None



# ================================================================
# NUEVAS FUNCIONES DE CONTROL DE L√çMITE POR ARTISTA Y √ÅLBUM
# ================================================================
def limit_tracks_by_artist_album(
    tracks_list: List[Dict[str, Any]],
    max_per_artist: int = 20,
    max_per_album: int = 5
) -> List[Dict[str, Any]]:
    """Limita cantidad de pistas por artista y por √°lbum con logs detallados."""
    logger.debug(f"[LIMIT] Iniciando control de l√≠mite por artista ({max_per_artist}) y √°lbum ({max_per_album})")
    if not tracks_list:
        return []

    result = []
    artist_counts = {}
    album_counts = {}

    for t in sorted(tracks_list, key=lambda x: x.get("RelativePopularityScore", 0), reverse=True):
        artist = (t.get("Artista") or "").strip()
        album = (t.get("Album") or "").strip()
        artist_key = artist.lower()
        album_key = f"{artist.lower()}::{album.lower()}" if album else artist.lower()

        a_count = artist_counts.get(artist_key, 0)
        al_count = album_counts.get(album_key, 0)

        if a_count >= max_per_artist:
            #logger.debug(f"[FILTER] ‚ùå {artist} - {t.get('Titulo')} omitido: excede l√≠mite de {max_per_artist} por artista.")
            continue
        if al_count >= max_per_album:
            #logger.debug(f"[FILTER] ‚ùå {artist} - {t.get('Titulo')} omitido: excede l√≠mite de {max_per_album} por √°lbum ({album}).")
            continue

        result.append(t)
        artist_counts[artist_key] = a_count + 1
        album_counts[album_key] = al_count + 1
        #logger.debug(f"[INCLUDE] ‚úÖ {artist} - {t.get('Titulo')} agregado (Artista:{artist_counts[artist_key]}, √Ålbum:{album_counts[album_key]})")

    logger.debug(f"[LIMIT] Playlist reducida de {len(tracks_list)} ‚Üí {len(result)} tras aplicar l√≠mites.")
    return result

# ================================================================
# FALLBACK FLEXIBLE
# ================================================================
def flexible_fallback_selection(original_query: str, limit: int = 30) -> List[Dict[str, Any]]:
    """
    Si no hay resultados luego de aplicar filtros y l√≠mites, genera una
    b√∫squeda aproximada a partir de palabras clave del prompt.
    """
    logger.debug("[FALLBACK] Iniciando fallback flexible: b√∫squeda aproximada en la base local.")
    words = [w for w in re.split(r"\\W+", original_query.lower()) if len(w) > 3]
    regex_or = [{"Genero": {"$regex": w, "$options": "i"}} for w in words] + [{"Titulo": {"$regex": w, "$options": "i"}} for w in words]
    fallback_q = {"$or": regex_or}
    try:
        res = list(tracks_col.find(fallback_q).limit(limit))
        if res:
            logger.debug(f"[FALLBACK] {len(res)} resultados aproximados devueltos.")
        else:
            logger.debug("[FALLBACK] No se encontraron resultados en fallback.")
        return res
    except Exception as e:
        logger.exception(f"[FALLBACK] Error durante fallback flexible: {e}")
        return []

# ================================================================
# INTEGRACI√ìN CON QUERY PRINCIPAL
# ================================================================
def apply_limits_and_fallback(results: List[Dict[str, Any]], query_text: str, limit: int = 50) -> List[Dict[str, Any]]:
    """Aplica l√≠mites por artista/√°lbum y fallback flexible si queda vac√≠a."""
    logger.debug("[APPLY] Iniciando postprocesamiento final (l√≠mite + fallback)")
    limited = limit_tracks_by_artist_album(results)
    if not limited:
        logger.debug("[APPLY] Playlist vac√≠a tras l√≠mites ‚Üí aplicando fallback flexible.")
        limited = flexible_fallback_selection(query_text, limit=limit)
    return limited[:limit]


def parse_ai_suggestions(ai_resp_raw: Any) -> List[str]:
    """
    Normalize AI response into a list of suggestion strings.
    Accepts dicts, lists, or raw text.
    """
    suggestions: List[str] = []
    if isinstance(ai_resp_raw, dict):
        # common keys
        for k in ("suggestions", "items", "results", "titles", "tracks"):
            val = ai_resp_raw.get(k)
            if isinstance(val, list):
                suggestions = [str(x).strip() for x in val if isinstance(x, (str, int)) and str(x).strip()]
                if suggestions:
                    return suggestions
        # maybe ai_resp_raw has nested text
        # try to stringify and parse
        raw_text = json.dumps(ai_resp_raw, ensure_ascii=False)
        parsed = try_parse_json_from_text(raw_text)
        if isinstance(parsed, list):
            return [str(x).strip() for x in parsed if isinstance(x, (str, int)) and str(x).strip()]
        if isinstance(parsed, dict):
            # attempt to find list inside
            for v in parsed.values():
                if isinstance(v, list):
                    return [str(x).strip() for x in v if isinstance(x, (str, int)) and str(x).strip()]
        # fallback: look for 'text' or 'response' fields
        for k in ("text", "response", "raw"):
            if k in ai_resp_raw and isinstance(ai_resp_raw[k], str):
                parsed2 = try_parse_json_from_text(ai_resp_raw[k])
                if isinstance(parsed2, list):
                    return [str(x).strip() for x in parsed2 if isinstance(x, (str, int)) and str(x).strip()]
                # else extract lines
                li = try_parse_json_from_text(ai_resp_raw[k]) if isinstance(ai_resp_raw[k], str) else None
    # if it's a list
    if isinstance(ai_resp_raw, list):
        return [str(x).strip() for x in ai_resp_raw if isinstance(x, (str, int)) and str(x).strip()]
    # if raw string
    if isinstance(ai_resp_raw, str):
        parsed = try_parse_json_from_text(ai_resp_raw)
        if isinstance(parsed, list):
            return [str(x).strip() for x in parsed if isinstance(x, (str, int)) and str(x).strip()]
        if isinstance(parsed, dict):
            # extract possible lists
            for v in parsed.values():
                if isinstance(v, list):
                    return [str(x).strip() for x in v if isinstance(x, (str, int)) and str(x).strip()]
        # else extract lines/bullets heuristically
        parsed_lines = try_parse_json_from_text(ai_resp_raw)
        if isinstance(parsed_lines, list):
            return [str(x).strip() for x in parsed_lines if isinstance(x, (str, int)) and str(x).strip()]
        # fallback: split lines and return best candidates
        items = []
        for line in ai_resp_raw.splitlines():
            line = line.strip()
            if not line:
                continue
            # remove numbering/bullets
            line = re.sub(r"^\s*[\d\-\.\)]+\s*", "", line)
            line = re.sub(r"^[\-\*\‚Ä¢\u2022]\s*", "", line)
            # ignore bracketed instructions
            if len(line) > 400:
                continue
            if len(line.split()) <= 1:
                continue
            items.append(line)
        return [i for i in items]
    # if dict-like but not captured, attempt stringify keys
    if isinstance(ai_resp_raw, dict):
        return []
    return suggestions

def call_ollama(prompt: str, model: str = MODEL_NAME, timeout: int = 40, retries: int = 2) -> Dict[str, Any]:
    """
    Llama al modelo Ollama con reintentos y parsing seguro de JSON.
    Usa la misma l√≥gica robusta que call_ollama_safe.
    """
    # ‚úÖ REUTILIZAR LA L√ìGICA ROBUSTA DE call_ollama_safe
    result = call_ollama_safe(prompt, model, timeout)
    
    # Mantener compatibilidad con el formato de retorno original
    if "error" in result:
        return {"error": result["error"]}
    elif "raw_response" in result:
        return {"raw": result["raw_response"]}
    else:
        return result

def sanitize_filters(filters: Dict[str, Any]) -> Dict[str, Any]:
    safe = {}
    if not isinstance(filters, dict):
        return safe
    for k, v in filters.items():
        if k not in ALLOWED_FIELDS:
            continue
        if isinstance(v, dict):
            clean = {}
            for op, val in v.items():
                if op in ALLOWED_OPERATORS:
                    if isinstance(val, (str, int, float, list, bool, dict)):
                        clean[op] = val
            if clean:
                safe[k] = clean
        else:
            if isinstance(v, (str, int, float, list, bool)):
                safe[k] = v
    return safe

# -----------------------
# Popularidad: global y relativa por genero
# -----------------------
def get_global_max_values() -> Dict[str, float]:
    pipeline = [
        {"$group": {
            "_id": None,
            "max_playcount": {"$max": "$LastFMPlaycount"},
            "max_listeners": {"$max": "$LastFMListeners"},
            "max_views": {"$max": "$YouTubeViews"},
        }}
    ]
    try:
        res = list(tracks_col.aggregate(pipeline))
        if not res:
            return {"LastFMPlaycount": 1, "LastFMListeners": 1, "YouTubeViews": 1}
        r = res[0]
        return {
            "LastFMPlaycount": (r.get("max_playcount") or 1),
            "LastFMListeners": (r.get("max_listeners") or 1),
            "YouTubeViews": (r.get("max_views") or 1)
        }
    except Exception:
        return {"LastFMPlaycount": 1, "LastFMListeners": 1, "YouTubeViews": 1}

def normalize_field(value, max_value):
    try:
        return float(value) / float(max_value) if max_value else 0.0
    except Exception:
        return 0.0

def compute_popularity(track: Dict[str, Any], max_vals: Dict[str, float]) -> float:
    """
    Calcula un puntaje base de popularidad combinando m√©tricas absolutas.
    Usa normalizaci√≥n proporcional y pondera por importancia:
      - LastFMPlaycount: 50%
      - LastFMListeners: 30%
      - YouTubeViews:    20%
    Se aplica logaritmo suavizado para evitar que grandes diferencias dominen.
    """
    # Normaliza con protecci√≥n de divisi√≥n por cero
    def norm_safe(val, max_val):
        return (math.log1p(val) / math.log1p(max_val)) if max_val > 0 else 0.0

    playcount = norm_safe(track.get("LastFMPlaycount", 0), max_vals.get("LastFMPlaycount", 1))
    listeners = norm_safe(track.get("LastFMListeners", 0), max_vals.get("LastFMListeners", 1))
    views = norm_safe(track.get("YouTubeViews", 0), max_vals.get("YouTubeViews", 1))

    score = playcount * 0.5 + listeners * 0.3 + views * 0.2

    # refuerzo para temas con alto bitrate (calidad percibida)
    bitrate = track.get("Bitrate", 0) or 0
    if bitrate > 0:
        score *= 1 + min(0.1, math.log1p(bitrate / 1_000_000) / 20)  # hasta +10% de peso

    return round(score, 6)


def compute_relative_popularity_by_genre(tracks_list: List[Dict[str, Any]]) -> None:
    """
    Normaliza los puntajes de popularidad de una lista de canciones:
      - Aplica logaritmo para evitar compresi√≥n de valores altos.
      - Ajusta dentro de cada g√©nero (si hay suficientes muestras).
      - Evita penalizar canciones con alto valor absoluto aunque sean m√≠nimas locales.
      - Aplica curva perceptiva (sqrt) y piso perceptivo (0.2).
    """
    if not tracks_list:
        return

    # üìä Agrupar por g√©nero
    genre_buckets: Dict[str, List[float]] = {}
    for t in tracks_list:
        genres = t.get("Genero")
        if isinstance(genres, list) and genres:
            g = str(genres[0]).lower()
        elif isinstance(genres, str) and genres:
            g = genres.lower()
        else:
            g = "unknown"
        genre_buckets.setdefault(g, [])
        genre_buckets[g].append(t.get("PopularityScore", 0.0))

    # üìà Estad√≠sticas por g√©nero
    genre_stats: Dict[str, Dict[str, float]] = {}
    for g, scores in genre_buckets.items():
        if not scores:
            continue
        genre_stats[g] = {"count": len(scores), "min": min(scores), "max": max(scores)}

    # üåç Normalizaci√≥n global (log)
    all_scores = [max(0.0, t.get("PopularityScore", 0.0)) for t in tracks_list]
    log_scores = [math.log1p(s) for s in all_scores]
    global_min = min(log_scores) if log_scores else 0.0
    global_max = max(log_scores) if log_scores else 1.0
    if math.isclose(global_max, global_min):
        global_max = global_min + 1.0

    logger.debug(f"üéöÔ∏è Normalizaci√≥n global (log): min={global_min:.3f}, max={global_max:.3f}, total={len(all_scores)} tracks")

    # üßÆ Calcular puntuaci√≥n relativa combinada
    for t in tracks_list:
        genres = t.get("Genero")
        if isinstance(genres, list) and genres:
            g = str(genres[0]).lower()
        elif isinstance(genres, str) and genres:
            g = genres.lower()
        else:
            g = "unknown"

        stats = genre_stats.get(g, {"count": 0, "min": 0.0, "max": 1.0})
        cnt = stats["count"]
        gmin, gmax = stats["min"], stats["max"]
        raw = max(0.0, t.get("PopularityScore", 0.0))
        raw_log = math.log1p(raw)

        # üîπ Normalizaci√≥n global (logar√≠tmica)
        norm_global = (raw_log - global_min) / (global_max - global_min)

        # üîπ Normalizaci√≥n por g√©nero
        if math.isclose(gmax, gmin):
            norm_genre = 1.0
        else:
            norm_genre = (raw - gmin) / (gmax - gmin)

        # ü©π Correcci√≥n: no castigar canciones con raw alto pero norm_genre bajo
        if norm_genre < 0.1 and raw > 0.6:
            norm_genre = 0.25 + 0.5 * norm_global  # se eleva seg√∫n su peso global

        # üß† Peso adaptativo seg√∫n tama√±o del g√©nero
        alpha = min(0.95, 0.2 + 0.75 * (cnt / (cnt + 30)))
        combined = alpha * norm_genre + (1 - alpha) * norm_global

        # üéöÔ∏è Curva perceptiva y piso m√≠nimo
        combined = math.sqrt(combined)
        combined = 0.2 + 0.8 * combined

        t["RelativePopularityScore"] = round(combined, 6)
        '''
        logger.debug(
            f"   ‚Ü≥ [{t.get('Artista','?')} - {t.get('Titulo','?')}] "
            f"raw={raw:.3f}, log={raw_log:.3f}, norm_genre={norm_genre:.3f}, "
            f"norm_global={norm_global:.3f}, combined={combined:.3f}"
        )
        '''

# -----------------------
# Heur√≠sticas ac√∫sticas y EMO (con aplicaci√≥n condicional)
# -----------------------
def enrich_filters_with_acoustics(text: str, filters: Dict[str, Any]) -> Dict[str, Any]:
    """
    Convierte t√©rminos emocionales del prompt en filtros ac√∫sticos/emocionales espec√≠ficos
    usando los valores exactos de tu sistema de an√°lisis.
    """
    text_low = (text or "").lower()
    f = dict(filters)  # shallow copy

    # üî• MAPEO EXACTO usando tus valores reales
    emotional_acoustic_profiles = {
        # M√öSICA ALEGRE/FELIZ - usa "Joy / Happy" y "Energetic / Uplifting"
        "alegre": {
            "TempoBPM": {"$gte": 110, "$lte": 140},
            "EnergyRMS": {"$gte": 0.20},
            "EMO_Lyrics": "Joy / Happy",
            "EMO_Sound": "Energetic / Uplifting"
        },
        "feliz": {
            "TempoBPM": {"$gte": 100, "$lte": 135},
            "EnergyRMS": {"$gte": 0.18},
            "EMO_Lyrics": "Joy / Happy", 
            "EMO_Sound": "Energetic / Uplifting"
        },
        "contento": {
            "TempoBPM": {"$gte": 95, "$lte": 130},
            "EnergyRMS": {"$gte": 0.16},
            "EMO_Lyrics": "Joy / Happy",
            "EMO_Sound": "Groovy / Positive"
        },
        
        # M√öSICA BAILABLE/FIESTA - usa "Celebraci√≥n y vida social"
        "bailable": {
            "TempoBPM": {"$gte": 115, "$lte": 130},
            "EnergyRMS": {"$gte": 0.22},
            "EMO_Sound": "Energetic / Uplifting",
            "EMO_Context1": "Celebraci√≥n y vida social"
        },
        "fiesta": {
            "TempoBPM": {"$gte": 120, "$lte": 140},
            "EnergyRMS": {"$gte": 0.25},
            "EMO_Sound": "Energetic / Uplifting", 
            "EMO_Context1": "Celebraci√≥n y vida social"
        },
        "baile": {
            "TempoBPM": {"$gte": 110, "$lte": 135},
            "EnergyRMS": {"$gte": 0.20},
            "EMO_Context1": "Celebraci√≥n y vida social"
        },
        
        # M√öSICA ENERG√âTICA/INTENSA
        "energ√©tico": {
            "TempoBPM": {"$gte": 130},
            "EnergyRMS": {"$gte": 0.28},
            "EMO_Sound": "Energetic / Uplifting"
        },
        "intenso": {
            "TempoBPM": {"$gte": 140},
            "EnergyRMS": {"$gte": 0.30},
            "EMO_Sound": "Energetic / Uplifting"
        },
        "potente": {
            "TempoBPM": {"$gte": 125},
            "EnergyRMS": {"$gte": 0.26},
            "EMO_Sound": "Energetic / Uplifting"
        },
        
        # M√öSICA TRANQUILA/RELAJANTE - usa "Calm / Neutral"
        "tranquilo": {
            "TempoBPM": {"$lte": 100},
            "EnergyRMS": {"$lte": 0.15},
            "EMO_Sound": "Calm / Neutral"
        },
        "relajante": {
            "TempoBPM": {"$lte": 90},
            "EnergyRMS": {"$lte": 0.12},
            "EMO_Sound": "Calm / Neutral"
        },
        "calma": {
            "TempoBPM": {"$lte": 85},
            "EnergyRMS": {"$lte": 0.10},
            "EMO_Sound": "Calm / Neutral"
        },
        "suave": {
            "TempoBPM": {"$lte": 95},
            "EnergyRMS": {"$lte": 0.14},
            "EMO_Sound": "Calm / Neutral"
        },
        
        # M√öSICA TRISTE/MELANC√ìLICA - usa "Sadness" y "Sad / Melancholic"
        "triste": {
            "TempoBPM": {"$lte": 80},
            "EnergyRMS": {"$lte": 0.12},
            "EMO_Lyrics": "Sadness",
            "EMO_Sound": "Sad / Melancholic"
        },
        "melanc√≥lico": {
            "TempoBPM": {"$lte": 75},
            "EnergyRMS": {"$lte": 0.10},
            "EMO_Lyrics": "Sadness",
            "EMO_Sound": "Sad / Melancholic"
        },
        "nostalgia": {
            "TempoBPM": {"$lte": 95},
            "EnergyRMS": {"$lte": 0.18},
            "EMO_Lyrics": "Sadness",
            "EMO_Context1": "Dolor y p√©rdida"
        },
        
        # M√öSICA ROM√ÅNTICA/AMOR - usa "Love / Romantic"
        "rom√°ntico": {
            "TempoBPM": {"$lte": 100},
            "EnergyRMS": {"$lte": 0.16},
            "EMO_Lyrics": "Love / Romantic",
            "EMO_Context1": "Amor y deseo"
        },
        "amor": {
            "TempoBPM": {"$lte": 110},
            "EnergyRMS": {"$lte": 0.20},
            "EMO_Lyrics": "Love / Romantic",
            "EMO_Context1": "Amor y deseo"
        },
        "pasi√≥n": {
            "TempoBPM": {"$lte": 105},
            "EnergyRMS": {"$lte": 0.22},
            "EMO_Lyrics": "Love / Romantic",
            "EMO_Context1": "Amor y deseo"
        },
        
        # M√öSICA CON ENFADO/CONFLICTO - usa "Anger"
        "enojo": {
            "TempoBPM": {"$gte": 120},
            "EnergyRMS": {"$gte": 0.24},
            "EMO_Lyrics": "Anger",
            "EMO_Context1": "Conflicto y traici√≥n"
        },
        "ira": {
            "TempoBPM": {"$gte": 130},
            "EnergyRMS": {"$gte": 0.28},
            "EMO_Lyrics": "Anger", 
            "EMO_Context1": "Conflicto y traici√≥n"
        },
        
        # M√öSICA DE SUPERACI√ìN - usa "Superaci√≥n y resiliencia"
        "superaci√≥n": {
            "TempoBPM": {"$gte": 100, "$lte": 130},
            "EnergyRMS": {"$gte": 0.18},
            "EMO_Context1": "Superaci√≥n y resiliencia"
        },
        "motivaci√≥n": {
            "TempoBPM": {"$gte": 105, "$lte": 135},
            "EnergyRMS": {"$gte": 0.20},
            "EMO_Context1": "Superaci√≥n y resiliencia"
        },
        
        # M√öSICA ESPIRITUAL/EXISTENCIAL
        "espiritual": {
            "TempoBPM": {"$lte": 95},
            "EnergyRMS": {"$lte": 0.16},
            "EMO_Context1": "Existencial / espiritual"
        },
        "existencial": {
            "TempoBPM": {"$lte": 90},
            "EnergyRMS": {"$lte": 0.14},
            "EMO_Context1": "Existencial / espiritual"
        }
    }

    # üîç DETECTAR Y APLICAR PERFIL EMOCIONAL
    applied_profile = None
    for emotion, profile in emotional_acoustic_profiles.items():
        if emotion in text_low:
            applied_profile = emotion
            logger.debug(f"üé≠ Perfil emocional detectado: '{emotion}'")
            
            # Aplicar filtros del perfil (sin sobrescribir existentes)
            for field, value in profile.items():
                if field not in f:
                    f[field] = value
                    logger.debug(f"   üéµ {field} = {value}")
            break

    # üéµ DETECCI√ìN DE T√âRMINOS AC√öSTICOS ESPEC√çFICOS
    # Rango de tempo expl√≠cito
    tempo_ranges = {
        "r√°pido": {"$gte": 130},
        "lento": {"$lte": 80},
        "medio": {"$gte": 90, "$lte": 120}
    }
    
    for tempo_term, tempo_range in tempo_ranges.items():
        if tempo_term in text_low and "TempoBPM" not in f:
            f["TempoBPM"] = tempo_range
            logger.debug(f"üéµ Rango de tempo '{tempo_term}' aplicado")

    # Niveles de energ√≠a
    if "alta energ√≠a" in text_low and "EnergyRMS" not in f:
        f["EnergyRMS"] = {"$gte": 0.25}
        logger.debug("‚ö° Filtro de alta energ√≠a aplicado")
    elif "baja energ√≠a" in text_low and "EnergyRMS" not in f:
        f["EnergyRMS"] = {"$lte": 0.12}
        logger.debug("üåø Filtro de baja energ√≠a aplicado")

    # üî• ESTRATEGIA INTELIGENTE: Si hay t√©rminos emocionales pero no perfil espec√≠fico
    if not applied_profile and contains_emotion_indicator(text):
        logger.debug("üé® Aplicando filtros emocionales b√°sicos (fallback inteligente)")
        
        # Determinar direcci√≥n emocional general
        if any(w in text_low for w in ["alegre", "feliz", "fiesta", "baile", "celebraci√≥n"]):
            # Direcci√≥n positiva/energ√©tica
            if "TempoBPM" not in f:
                f["TempoBPM"] = {"$gte": 100, "$lte": 135}
            if "EnergyRMS" not in f:
                f["EnergyRMS"] = {"$gte": 0.18}
            if "EMO_Sound" not in f:
                f["EMO_Sound"] = {"$in": ["Energetic / Uplifting", "Groovy / Positive"]}
                
        elif any(w in text_low for w in ["triste", "melancol√≠a", "nostalgia", "dolor"]):
            # Direcci√≥n triste/calmada
            if "TempoBPM" not in f:
                f["TempoBPM"] = {"$lte": 95}
            if "EnergyRMS" not in f:
                f["EnergyRMS"] = {"$lte": 0.15}
            if "EMO_Sound" not in f:
                f["EMO_Sound"] = {"$in": ["Sad / Melancholic", "Calm / Neutral"]}
                
        elif any(w in text_low for w in ["amor", "rom√°ntico", "pasi√≥n"]):
            # Direcci√≥n rom√°ntica
            if "TempoBPM" not in f:
                f["TempoBPM"] = {"$lte": 110}
            if "EnergyRMS" not in f:
                f["EnergyRMS"] = {"$lte": 0.20}
            if "EMO_Lyrics" not in f:
                f["EMO_Lyrics"] = "Love / Romantic"

    return f

def contains_emotion_indicator(text: str) -> bool:
    """
    Detecta si el texto contiene indicadores emocionales usando tus categor√≠as exactas.
    """
    if not text:
        return False
    
    text_low = text.lower()
    
    # T√©rminos que mapean a tus categor√≠as emocionales exactas
    emotion_indicators = [
        # Joy / Happy
        "alegre", "feliz", "contento", "alegr√≠a", "felicidad", "optimismo",
        # Love / Romantic  
        "amor", "rom√°ntico", "romance", "pasi√≥n", "coraz√≥n", "enamorado",
        # Sadness
        "triste", "tristeza", "melancol√≠a", "melanc√≥lico", "dolor", "pena",
        # Anger
        "enojo", "ira", "enfado", "rabia", "furia", 
        # Fear / Anxiety
        "miedo", "temor", "ansiedad", "p√°nico",
        # Celebration
        "fiesta", "celebraci√≥n", "baile", "juerga", "diversi√≥n",
        # Superaci√≥n
        "superaci√≥n", "motivaci√≥n", "inspiraci√≥n", "esperanza",
        # Spiritual
        "espiritual", "existencial", "fe", "religi√≥n", "destino"
    ]
    
    return any(term in text_low for term in emotion_indicators)
    
def search_tracks_with_emotional_filters(llm_filters, limit, tracks_col):
    """
    B√∫squeda especializada para filtros emocionales usando valores exactos.
    Estrategia de fallback inteligente para m√°xima recuperaci√≥n.
    """
    results = []
    seen_rutas = set()
    normalized_filters = parse_filters_from_llm(llm_filters or {})
    
    logger.debug(f"üé≠ Buscando con filtros emocionales: {list(normalized_filters.keys())}")

    # ESTRATEGIA 1: B√∫squeda exacta con todos los filtros (incluyendo emocionales)
    if normalized_filters:
        try:
            exact_query = normalized_filters
            exact_results = list(tracks_col.find(exact_query).sort("PopularityScore", -1).limit(limit * 3))
            
            for f in exact_results:
                ruta = f.get("Ruta")
                if ruta and ruta not in seen_rutas:
                    results.append(f)
                    seen_rutas.add(ruta)
                    if len(results) >= limit:
                        break
            logger.debug(f"üéØ Estrategia 1 (exacta): {len(results)} resultados")
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Error en b√∫squeda exacta: {e}")

    # ESTRATEGIA 2: Relajar EMO_Context si hay pocos resultados
    emotional_context_fields = ["EMO_Context1", "EMO_Context2", "EMO_Context3"]
    if len(results) < limit and any(k in emotional_context_fields for k in normalized_filters.keys()):
        relaxed_filters = {k: v for k, v in normalized_filters.items() 
                          if k not in emotional_context_fields}
        
        if relaxed_filters:
            try:
                relaxed_results = list(tracks_col.find(relaxed_filters).sort("PopularityScore", -1).limit(limit * 2))
                for f in relaxed_results:
                    ruta = f.get("Ruta")
                    if ruta and ruta not in seen_rutas:
                        results.append(f)
                        seen_rutas.add(ruta)
                        if len(results) >= limit:
                            break
                logger.debug(f"üéØ Estrategia 2 (sin contextos): +{len(relaxed_results)} resultados")
            except Exception as e:
                logger.debug(f"‚ö†Ô∏è Error en b√∫squeda sin contextos: {e}")

    # ESTRATEGIA 3: Mantener solo EMO_Sound y EMO_Lyrics (m√°s importantes)
    core_emotional_fields = ["EMO_Sound", "EMO_Lyrics"]
    if len(results) < limit and any(k in core_emotional_fields for k in normalized_filters.keys()):
        core_filters = {k: v for k, v in normalized_filters.items() 
                       if k in core_emotional_fields or k not in emotional_context_fields}
        
        # A√±adir filtros ac√∫sticos si existen
        acoustic_fields = ["TempoBPM", "EnergyRMS", "LoudnessLUFS"]
        for field in acoustic_fields:
            if field in normalized_filters:
                core_filters[field] = normalized_filters[field]
        
        if core_filters:
            try:
                core_results = list(tracks_col.find(core_filters).sort("PopularityScore", -1).limit(limit * 2))
                for f in core_results:
                    ruta = f.get("Ruta")
                    if ruta and ruta not in seen_rutas:
                        results.append(f)
                        seen_rutas.add(ruta)
                        if len(results) >= limit:
                            break
                logger.debug(f"üéØ Estrategia 3 (solo emociones core): +{len(core_results)} resultados")
            except Exception as e:
                logger.debug(f"‚ö†Ô∏è Error en b√∫squeda core emocional: {e}")

    # ESTRATEGIA 4: Solo filtros ac√∫sticos (TempoBPM + EnergyRMS)
    if len(results) < limit and any(k in ["TempoBPM", "EnergyRMS"] for k in normalized_filters.keys()):
        acoustic_only = {}
        if "TempoBPM" in normalized_filters:
            acoustic_only["TempoBPM"] = normalized_filters["TempoBPM"]
        if "EnergyRMS" in normalized_filters:
            acoustic_only["EnergyRMS"] = normalized_filters["EnergyRMS"]
        
        if acoustic_only:
            try:
                acoustic_results = list(tracks_col.find(acoustic_only).sort("PopularityScore", -1).limit(limit * 2))
                for f in acoustic_results:
                    ruta = f.get("Ruta")
                    if ruta and ruta not in seen_rutas:
                        results.append(f)
                        seen_rutas.add(ruta)
                        if len(results) >= limit:
                            break
                logger.debug(f"üéØ Estrategia 4 (solo ac√∫sticos): +{len(acoustic_results)} resultados")
            except Exception as e:
                logger.debug(f"‚ö†Ô∏è Error en b√∫squeda ac√∫stica: {e}")

    # ESTRATEGIA 5: Solo por d√©cada + ordenar por popularidad
    if len(results) < limit and "Decada" in normalized_filters:
        try:
            decade_only = {"Decada": normalized_filters["Decada"]}
            decade_results = list(tracks_col.find(decade_only).sort("PopularityScore", -1).limit(limit))
            for f in decade_results:
                ruta = f.get("Ruta")
                if ruta and ruta not in seen_rutas:
                    results.append(f)
                    seen_rutas.add(ruta)
                    if len(results) >= limit:
                        break
            logger.debug(f"üéØ Estrategia 5 (solo d√©cada): +{len(decade_results)} resultados")
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Error en b√∫squeda por d√©cada: {e}")

    logger.debug(f"üé≠ B√∫squeda emocional final: {len(results)} resultados")
    return results
    
    
# -----------------------
# Dedup + prefer best bitrate then popularity
# -----------------------
def normalize_title_for_dedupe(s: str) -> str:
    if not s:
        return ""
    s = re.sub(r"\s*\(.*?(remaster|remixed|live|album version|version|explicit|feat\.|ft\.).*?\)", "", s, flags=re.I)
    s = re.sub(r"\s*\[.*?\]", "", s)
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s)
    return s.strip().lower()

def deduplicate_tracks_by_title_keep_best(tracks_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    best = {}
    for t in tracks_list:
        key = normalize_title_for_dedupe(t.get("Titulo", "") or "")
        if not key:
            key = (t.get("Ruta") or "")[:200]
        cur_pop = t.get("PopularityScore", 0.0)
        bitrate = t.get("Bitrate") or 0
        if key not in best:
            best[key] = t
        else:
            prev = best[key]
            prev_bitrate = prev.get("Bitrate") or 0
            prev_pop = prev.get("PopularityScore", 0.0)
            if bitrate > prev_bitrate or (bitrate == prev_bitrate and cur_pop > prev_pop):
                best[key] = t
    return list(best.values())

# -----------------------
# Similarity: find reference track & build filters
# -----------------------
def find_reference_track(term: str) -> Optional[Dict[str, Any]]:
    if not term:
        return None
    try:
        doc = tracks_col.find_one({"Titulo": {"$regex": re.escape(term), "$options": "i"}}) or \
              tracks_col.find_one({"Artista": {"$regex": re.escape(term), "$options": "i"}})
        return doc
    except Exception:
        return None

def build_similarity_filters_from_track(t: Dict[str, Any], tolerances: Dict[str, float] = None) -> Dict[str, Any]:
    tolerances = tolerances or {"TempoBPM": 8, "EnergyRMS": 0.06, "LoudnessLUFS": 3}
    f = {}
    tempo = t.get("TempoBPM")
    if tempo:
        f["TempoBPM"] = {"$gte": max(0, tempo - tolerances["TempoBPM"]), "$lte": tempo + tolerances["TempoBPM"]}
    energy = t.get("EnergyRMS")
    if energy is not None:
        f["EnergyRMS"] = {"$gte": max(0.0, energy - tolerances["EnergyRMS"]), "$lte": min(1.0, energy + tolerances["EnergyRMS"])}
    loud = t.get("LoudnessLUFS")
    if loud is not None:
        f["LoudnessLUFS"] = {"$gte": loud - tolerances["LoudnessLUFS"], "$lte": loud + tolerances["LoudnessLUFS"]}
    key = t.get("EstimatedKey")
    if key:
        f["EstimatedKey"] = {"$in": [key]}
    genre = t.get("Genero")
    if genre:
        if isinstance(genre, list) and genre:
            sample = genre[0]
        else:
            sample = genre
        f["Genero"] = {"$regex": re.escape(sample), "$options": "i"}
    return f

# -----------------------
# Weighted rank
# -----------------------
def compute_weighted_rank(track: Dict[str, Any], acoustic_boost: bool = False) -> float:
    pop = track.get("RelativePopularityScore", track.get("PopularityScore", 0)) or 0
    if acoustic_boost:
        energy = float(track.get("EnergyRMS", 0) or 0)
        loudness = track.get("LoudnessLUFS", None)
        loud_norm = 0.0
        if loudness is not None:
            try:
                loud_norm = min(max((-float(loudness)) / 40.0, 0.0), 1.0)
            except Exception:
                loud_norm = 0.0
        acoustic_score = energy * 0.6 + loud_norm * 0.4
        return pop * 0.65 + acoustic_score * 0.35
    return pop

# -----------------------
# M3U generator
# -----------------------
def save_m3u(playlist_items: List[Dict[str, Any]], base_filename: str) -> Tuple[str, str]:
    uid = str(uuid.uuid4())
    safe_name = re.sub(r"[^a-z0-9_-]", "_", base_filename.lower())[:60]
    filename = f"{safe_name}_{uid}.m3u8"
    path = os.path.join(GENERATED_DIR, filename)
    with open(path, "w", encoding="utf-8") as fh:
        fh.write("#EXTM3U\n")
        if not playlist_items:
            fh.write("# Playlist generated but no items matched filters. Try relaxing filters.\n")
        for t in playlist_items:
            dur = t.get("Duracion_mmss", "")
            seconds = -1
            try:
                if dur and ":" in str(dur):
                    mm, ss = map(int, str(dur).split(":")[:2])
                    seconds = mm * 60 + ss
            except Exception:
                seconds = -1
            fh.write(f"#EXTINF:{seconds},{t.get('Artista','')} - {t.get('Titulo','')}\n")
            fh.write(f"{t.get('Ruta','')}\n")
    return path, uid

# -----------------------
# Input models
# -----------------------
class QueryIn(BaseModel):
    query: str
    regenerate: bool = False  # ‚úÖ Nuevo campo
    previous_playlist_id: Optional[str] = None  # ‚úÖ Nuevo campo

class FeedbackIn(BaseModel):
    playlist_id: str
    rating: int  # 1..10
    comment: Optional[str] = None

# -----------------------
# Hybrid AI augmentation (when few results) + DB-assisted interaction
# -----------------------
def append_hybrid_log(entry: Dict[str, Any]) -> None:
    try:
        if os.path.exists(HYBRID_LOG_PATH):
            with open(HYBRID_LOG_PATH, "r", encoding="utf-8") as fh:
                data = json.load(fh)
        else:
            data = []
    except Exception:
        data = []
    entry["logged_at"] = datetime.utcnow().isoformat()
    data.append(entry)
    try:
        with open(HYBRID_LOG_PATH, "w", encoding="utf-8") as fh:
            json.dump(data, fh, ensure_ascii=False, indent=2)
    except Exception:
        logger.exception("Could not persist hybrid log")

def hybrid_augment_and_validate(original_query: str, existing_filters: Dict[str, Any], max_suggestions: int = 8) -> Dict[str, Any]:
    """
    Ask Ollama for suggestions (track titles / artists / genres) for the query,
    then validate those suggestions against Mongo (do they exist?). Return validated suggestions and log.
    Robust parsing of AI responses included.
    """
    prompt = (
        f"Provee hasta {max_suggestions} sugerencias de canciones, artistas o g√©neros que encajen con la siguiente petici√≥n "
        f"de usuario. Devuelve EXCLUSIVAMENTE JSON con formato: {{\"suggestions\": [\"text1\",\"text2\",...]}}.\n\n"
        f"Petici√≥n: \"{original_query}\"\n\n"
        "Las sugerencias deben priorizar canciones/artistas que probablemente existan y sean representativos del estilo.\n"
        "Si no puedes sugerir, devuelve {\"suggestions\": []}."
    )
    ai_resp = call_ollama(prompt)
    raw_ai = ai_resp.copy() if isinstance(ai_resp, dict) else {"raw": ai_resp}
    # Use our parser to extract suggestions
    suggestions = []
    if isinstance(ai_resp, dict):
        # try common keys
        suggestions = ai_resp.get("suggestions", []) or ai_resp.get("items", []) or ai_resp.get("results", []) or []
        if not suggestions:
            # try parsing raw text fields if present
            for k in ("raw", "text", "response"):
                if k in ai_resp and isinstance(ai_resp[k], str):
                    suggestions = parse_ai_suggestions(ai_resp[k])
                    if suggestions:
                        break
    elif isinstance(ai_resp, str):
        suggestions = parse_ai_suggestions(ai_resp)

    # final normalization
    suggestions = [str(s).strip() for s in suggestions if isinstance(s, (str, int)) and str(s).strip()]
    validated = []
    validated_texts = []
    for s in suggestions:
        doc = None
        try:
            doc = tracks_col.find_one({"$or": [{"Titulo": {"$regex": re.escape(s), "$options": "i"}}, {"Artista": {"$regex": re.escape(s), "$options": "i"}}]})
        except Exception:
            doc = None
        if doc:
            validated.append({"suggestion": s, "found": True, "sample_track": {"Titulo": doc.get("Titulo"), "Artista": doc.get("Artista"), "Ruta": doc.get("Ruta")}})
            validated_texts.append(s)
        else:
            validated.append({"suggestion": s, "found": False})

    entry = {
        "query": original_query,
        "filters_before": existing_filters,
        "ai_raw_response": raw_ai,
        "ai_suggestions": suggestions,
        "validated": validated
    }
    append_hybrid_log(entry)
    return {"validated": validated_texts, "raw": raw_ai, "validated_full": validated}

def gather_top_artists_from_mongo(filters: Dict[str, Any], top_n: int = 50) -> List[str]:
    """
    Return a list of top artists matching the current filters, ordered by frequency/popularity.
    """
    pipeline = []
    if filters:
        pipeline.append({"$match": filters})
    pipeline.extend([
        {"$group": {"_id": "$Artista", "count": {"$sum": 1}, "max_pop": {"$max": "$LastFMPlaycount"}}},
        {"$sort": {"count": -1, "max_pop": -1}},
        {"$limit": top_n}
    ])
    try:
        res = list(tracks_col.aggregate(pipeline))
        artists = [r["_id"] for r in res if r and r.get("_id")]
        return artists
    except Exception:
        logger.exception("Error gathering top artists from mongo")
        return []

def hybrid_db_assisted_cycle(original_query: str, existing_filters: Dict[str, Any], min_validated_threshold: int = 10) -> Dict[str, Any]:
    """
    Hybrid flow:
      1) Ask model for suggestions, validate.
      2) If not enough, gather top local artists and ask model to prioritize among them.
      3) If still not enough, fallback: use local artists directly (return artist names as validated)
    Returns validated suggestion strings and detailed log.
    """
    # First attempt
    ai_first = hybrid_augment_and_validate(original_query, existing_filters, max_suggestions=12)
    validated_first = ai_first.get("validated", []) or []
    log = {"stage": "initial_suggestions", "validated_first": validated_first, "raw_first": ai_first.get("raw")}

    if len(validated_first) >= min_validated_threshold:
        log["succeeded"] = True
        return {"validated": validated_first, "raw": ai_first.get("raw"), "log": log}

    # Gather local artists to help focus the model
    local_artists = gather_top_artists_from_mongo(existing_filters, top_n=80)
    log["local_artists_sample"] = local_artists[:30] if local_artists else []
    if not local_artists:
        log["succeeded"] = False
        log["reason"] = "no_local_artists"
        return {"validated": validated_first, "raw": {"first": ai_first.get("raw")}, "log": log}

    # Build prompt including local artists (shortened)
    sample_artists = local_artists[:60]
    # üß© PROMPT 1 ‚Äî Recomendaciones iniciales
    prompt = (
        f"El usuario pidi√≥: \"{original_query}\".\n"
        "Tu tarea es sugerir canciones o artistas que coincidan con la intenci√≥n completa de esa petici√≥n, "
        "manteniendo su g√©nero, √©poca, energ√≠a, emoci√≥n y estilo.\n\n"
        "A continuaci√≥n hay una lista de artistas disponibles localmente en la base de datos:\n"
        + ", ".join(sample_artists[:30]) + ("\n..." if len(sample_artists) > 30 else "\n")
        + "\nUsa esta lista como referencia prioritaria para sugerir artistas o canciones coherentes con el pedido del usuario.\n"
        "Devuelve como m√°ximo 20 sugerencias en formato JSON v√°lido:\n"
        "{\"suggestions\": [{\"titulo\": \"...\", \"artista\": \"...\", \"album\": \"...\"}]}\n"
        "Aseg√∫rate de conservar el contexto del prompt original (por ejemplo: si menciona 'rock de los 80s', "
        "no incluyas artistas de pop moderno ni fuera de esa √©poca)."
    )
        
    
    ai_second = call_ollama(prompt)
    raw_second = ai_second.copy() if isinstance(ai_second, dict) else {"raw": ai_second}
    suggestions2 = []
    if isinstance(ai_second, dict):
        suggestions2 = ai_second.get("suggestions", []) or ai_second.get("items", []) or []
        if not suggestions2:
            # try parsing raw text in response
            for k in ("raw", "text", "response"):
                if k in ai_second and isinstance(ai_second[k], str):
                    suggestions2 = parse_ai_suggestions(ai_second[k])
                    if suggestions2:
                        break
    elif isinstance(ai_second, str):
        suggestions2 = parse_ai_suggestions(ai_second)

    suggestions2 = [s for s in suggestions2 if isinstance(s, str) and s.strip()]
    validated2 = []
    validated_texts2 = []
    for s in suggestions2:
        try:
            doc = tracks_col.find_one({"$or": [{"Titulo": {"$regex": re.escape(s), "$options": "i"}}, {"Artista": {"$regex": re.escape(s), "$options": "i"}}]})
        except Exception:
            doc = None
        if doc:
            validated2.append({"suggestion": s, "found": True, "sample_track": {"Titulo": doc.get("Titulo"), "Artista": doc.get("Artista"), "Ruta": doc.get("Ruta")}})
            validated_texts2.append(s)
        else:
            validated2.append({"suggestion": s, "found": False})

    # If model didn't return useful suggestions but we have local artists, fallback: use artist names directly
    if not validated_texts2:
        # query mongo for tracks from top local artists (guaranteed to exist locally) and return their artist-title combos
        fallback_validated = []
        try:
            # take top N artists and pull 3 tracks each (if available)
            sample_for_query = local_artists[:30]
            q = {"Artista": {"$in": sample_for_query}}
            cursor = tracks_col.find(q).limit(200)
            found = list(cursor)
            for doc in found:
                tstr = f"{doc.get('Titulo')}" if doc.get("Titulo") else None
                if tstr:
                    fallback_validated.append({"suggestion": tstr, "found": True, "sample_track": {"Titulo": doc.get("Titulo"), "Artista": doc.get("Artista"), "Ruta": doc.get("Ruta")}})
            # dedupe suggestion texts preserving order
            texts = []
            for v in fallback_validated:
                txt = v.get("suggestion")
                if txt and txt not in texts:
                    texts.append(txt)
            validated_texts2 = texts[:min(60, len(texts))]
        except Exception:
            logger.exception("Error during local-artist fallback extraction")
            validated_texts2 = []

    entry = {
        "query": original_query,
        "filters_before": existing_filters,
        "stage": "db_assisted",
        "local_artists_sample": sample_artists[:30],
        "ai_raw_response_first": ai_first.get("raw"),
        "ai_raw_response_second": raw_second,
        "ai_suggestions_second": suggestions2,
        "validated_second": validated2,
        "fallback_validated_from_local": len(validated_texts2) > 0
    }
    append_hybrid_log(entry)

    combined_validated = list(dict.fromkeys((validated_first or []) + validated_texts2))
    log["succeeded"] = len(combined_validated) >= min_validated_threshold
    log["final_count"] = len(combined_validated)
    return {"validated": combined_validated, "raw": {"first": ai_first.get("raw"), "second": raw_second}, "log": log}

# -----------------------
# Relax filters one-shot fallback
# -----------------------
def relax_filters(filters: Dict[str, Any]) -> Dict[str, Any]:
    newf = {}
    for k, v in filters.items():
        if isinstance(v, dict):
            nv = dict(v)
            nv.pop("$gt", None)
            nv.pop("$lt", None)
            if "$gte" in nv and isinstance(nv["$gte"], (int, float)):
                nv["$gte"] = max(0, int(nv["$gte"] * 0.7))
            if "$lte" in nv and isinstance(nv["$lte"], (int, float)):
                nv["$lte"] = int(nv["$lte"] * 1.3)
            if nv:
                newf[k] = nv
        else:
            newf[k] = v
    newf.pop("EstimatedKey", None)
    if "EnergyRMS" in newf:
        try:
            g = newf["EnergyRMS"].get("$gt")
            if g:
                newf["EnergyRMS"]["$gt"] = max(0.0, g - 0.08)
        except Exception:
            pass
    return newf

# -----------------------
# Final inspection: limpiar incongruencias groseras
# -----------------------
def filter_gross_incongruities(tracks_list: List[Dict[str, Any]], query_text: str) -> List[Dict[str, Any]]:
    """
    Remove tracks that clearly contradict the user's intent.
    Heuristics:
      - If user asked 'bailable' require tempo >= 100 OR genre matches dance list OR EMO_Sound groovy/energetic.
      - If user asked 'pesado' require heavy genre OR EnergyRMS > 0.22 OR loudness and genre match.
      - If user asked 'tranquilo' require EnergyRMS < 0.18 or EMO_Sound calm.
      - 'similar a' special cases are not filtered aggressively.
    """
    if not tracks_list:
        return tracks_list
    text = (query_text or "").lower()
    filtered = []
    for t in tracks_list:
        keep = True
        tempo = t.get("TempoBPM") or 0
        energy = t.get("EnergyRMS") or 0.0
        genre = t.get("Genero") or ""
        emo_sound = (t.get("EMO_Sound") or "").lower()

        # Bailables
        if any(w in text for w in ["bail", "dance", "bailable", "fiesta", "party", "groovy", "movido", "ritmo"]):
            genre_text = " ".join(genre) if isinstance(genre, list) else str(genre)
            if tempo < 100 and not DANCE_GENRE_REGEX.search(genre_text) and "groovy" not in emo_sound and energy < 0.18:
                keep = False

        # Pesado/agresivo
        if any(w in text for w in ["pesado", "agresivo", "heavy", "metal", "hard", "brutal", "intenso"]):
            genre_text = " ".join(genre) if isinstance(genre, list) else str(genre)
            if not HEAVY_GENRE_REGEX.search(genre_text) and energy < 0.2 and tempo < 100:
                keep = False

        # Tranquilo / baladas
        if any(w in text for w in ["tranquil", "relaj", "calm", "melancol", "lento", "soft", "balada", "romant"]):
            if energy > 0.24 and tempo > 110:
                keep = False

        # If user explicitly included an artist/title, don't be too aggressive
        if re.search(r"por\s+\w+|de\s+\w+|similar a", text):
            # relax rules
            pass

        if keep:
            filtered.append(t)
        else:
            logger.debug(f"Removed for incongruity: {t.get('Artista')} - {t.get('Titulo')} (tempo={tempo}, energy={energy}, genero={genre})")

    return filtered

# -----------------------
# Endpoint: /query (V15 con guardado por usuario) - MEJORADO PARA PA√çSES
# -----------------------
@app.post("/query")
def query_playlists(body: QueryIn, request: Request):
    query_text = body.query.strip()
    start_ts = datetime.utcnow()
    
    # ‚úÖ OBTENER USUARIO AUTENTICADO
    try:
        auth_header = request.headers.get("Authorization")
        user_email = "anonymous"
        if auth_header and "Bearer" in auth_header:
            token = auth_header.replace("Bearer ", "").strip()
            user = db_auth.users.find_one({"session_token": token})
            if user:
                user_email = user.get("email", "anonymous")
                logger.debug(f"üë§ Usuario autenticado: {user_email}")
            else:
                logger.debug("üë§ Usuario no autenticado, usando 'anonymous'")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Error obteniendo usuario: {e}")
        user_email = "anonymous"

    # ‚úÖ USAR DIRECTAMENTE EL MODELO PYDANTIC
    regenerate = body.regenerate
    previous_playlist_id = body.previous_playlist_id
    
    logger.debug(f"üîé Query received: {query_text}")
    logger.debug(f"üÜï Regenerate flag recibido: {regenerate}")
    logger.debug(f"üìÄ previous_playlist_id recibido: {previous_playlist_id}")
    logger.debug(f"üë§ Usuario: {user_email}")

    # --- üîß Asegurar que el flag regenerate se interprete correctamente ---
    if isinstance(regenerate, str):
        regenerate = regenerate.strip().lower() in ("true", "1", "yes", "on")
    elif isinstance(regenerate, (int, float)):
        regenerate = bool(regenerate)

    logger.debug(f"üÜï Regenerate flag recibido (raw={getattr(body, 'regenerate', None)}) ‚Üí interpretado como {regenerate}")
    logger.debug(f"üìÄ previous_playlist_id recibido: {previous_playlist_id}")

    # Contenedores para exclusiones (t√≠tulos en min√∫scula y rutas)
    excluded_titles = set()
    excluded_paths = set()

    # Intentamos cargar la playlist previa s√≥lo si se pidi√≥ regenerar y se entreg√≥ id
    if regenerate:
        logger.debug("üÜï Regeneraci√≥n solicitada por el cliente.")
        if previous_playlist_id:
            try:
                # Intentar convertir a ObjectId si es necesario (si usas pymongo)
                try:
                    prev_doc = playlists_col.find_one({"_id": ObjectId(previous_playlist_id), "user_email": user_email})
                except Exception:
                    # si la colecci√≥n guarda id como string, intentar fallback
                    prev_doc = playlists_col.find_one({"playlist_uuid": previous_playlist_id, "user_email": user_email}) or playlists_col.find_one({"_id": previous_playlist_id, "user_email": user_email})
                
                if prev_doc and isinstance(prev_doc.get("items", None), list):
                    for it in prev_doc.get("items", []):
                        title = (it.get("Titulo") or it.get("title") or "").strip().lower()
                        path = it.get("Ruta") or it.get("ruta") or it.get("stream_url") or None
                        if title:
                            excluded_titles.add(title)
                        if path:
                            excluded_paths.add(path)
                    logger.debug(f"üÜï Cargada playlist previa: excluyendo {len(excluded_titles)} t√≠tulos y {len(excluded_paths)} rutas.")
                else:
                    logger.debug("üÜï No se encontr√≥ playlist previa o no tiene 'items' v√°lidos; ignorando exclusiones.")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error al cargar playlist previa para regeneraci√≥n: {e}")
        else:
            logger.debug("üÜï Regenerar=true pero no se entreg√≥ previous_playlist_id; no habr√° exclusiones.")
    else:
        logger.debug("üÜï No se solicit√≥ regeneraci√≥n (regenerate=false).")

    # 1Ô∏è‚É£ Limpieza inicial de texto (quita prefijos comunes)
    query_clean = re.sub(r"^(lo|la|el|los|las)\s+", "", query_text, flags=re.I).strip()
    logger.debug(f"üßº Query normalizada: {query_clean}")

    # 2Ô∏è‚É£ An√°lisis sem√°ntico del prompt con interpretaci√≥n robusta
    llm_analysis = analyze_query_intent(query_clean)
    llm_analysis = enhance_region_detection(llm_analysis, query_text)
    
    # ‚úÖ CASO ESPECIAL: Regi√≥n + G√©nero
    detected_region = llm_analysis.get("region")
    user_genre = llm_analysis.get("genre")
    
    if detected_region and detected_region in REGION_DEFINITIONS:
        logger.debug(f"üó∫Ô∏è Modo REGI√ìN activado: {detected_region}, g√©nero: {user_genre}")
        
        # B√∫squeda especializada por regi√≥n
        region_tracks = search_tracks_by_region(
            region_id=detected_region,
            user_genre=user_genre,  # Puede ser None
            limit=llm_analysis["detected_limit"]
        )
        
        if region_tracks:
            # Procesar y devolver resultados
            region_filters = {
                "region": detected_region,
                "genre": user_genre,
                "countries": REGION_DEFINITIONS[detected_region]["countries"]
            }
            
            # ... guardar playlist con nombre inteligente ...
            return create_region_playlist_response(
                query_text, region_tracks, region_filters, llm_analysis, user_email
            )
    
    # ‚úÖ NUEVO: Manejo espec√≠fico para solicitudes de pa√≠s
    if llm_analysis.get("type") == "country_request" and llm_analysis.get("country"):
        logger.debug(f"üá®üá± Modo pa√≠s activado: {llm_analysis.get('country')} ({llm_analysis.get('country_type')})")
        
        # ‚úÖ B√öSQUEDA DIRECTA DE EMERGENCIA con prioridad jer√°rquica en TopCountry
        emergency_tracks = emergency_country_search(
            llm_analysis["country"], 
            llm_analysis.get("country_type", "origin"),
            llm_analysis.get("detected_limit", 30)  # ‚úÖ Siempre 30 por defecto
        )
        
        if emergency_tracks:
            # üÜï Excluir pistas previas si estamos regenerando
            if regenerate:
                logger.debug("üÜï Aplicando exclusi√≥n de pistas previas en modo PA√çS.")
                emergency_tracks = exclude_previous_tracks(emergency_tracks, excluded_titles, excluded_paths)
                logger.debug(f"üÜï Tras exclusi√≥n, quedan {len(emergency_tracks)} pistas candidatas.")

            # ‚úÖ Asegurar que tenemos exactamente el l√≠mite solicitado
            target_limit = llm_analysis.get("detected_limit", 30)
            if len(emergency_tracks) > target_limit:
                # Si tenemos m√°s resultados que el l√≠mite, tomar los mejores
                emergency_tracks = emergency_tracks[:target_limit]
                logger.debug(f"üéØ Limit√© resultados de {len(emergency_tracks)} a {target_limit} pistas")
            
            # Procesar los resultados de emergencia
            global_max = get_global_max_values()
            for t in emergency_tracks:
                t["PopularityScore"] = compute_popularity(t, global_max)
            
            compute_relative_popularity_by_genre(emergency_tracks)
            
            # ‚úÖ Ordenar por RelativePopularityScore (ya viene ordenado por PopularityScore de la b√∫squeda)
            emergency_tracks.sort(key=lambda x: x.get("RelativePopularityScore", 0), reverse=True)
            
            # ‚úÖ Tomar exactamente el l√≠mite solicitado
            final_tracks = emergency_tracks[:target_limit]

            # Generar salida simplificada
            simplified = [{
                "Ruta": t.get("Ruta"),
                "Titulo": t.get("Titulo"),
                "Artista": t.get("Artista"),
                "Album": t.get("Album"),
                "A√±o": t.get("A√±o"),
                "Genero": t.get("Genero"),
                "Duracion_mmss": t.get("Duracion_mmss"),
                "Bitrate": t.get("Bitrate"),
                "Calidad": t.get("Calidad"),
                "CoverCarpeta": t.get("CoverCarpeta"),
                "RelativePopularityScore": round(t.get("RelativePopularityScore", 0.0), 3),
                "PopularityDisplay": popularity_display(t.get("RelativePopularityScore", 0.0)),
            } for t in final_tracks]

            # Guardar M3U y registro CON USUARIO
            country_name = llm_analysis["country"]
            country_type = llm_analysis.get("country_type", "origin")
            base_filename = f"musica_{country_name.lower()}_{country_type}"
            m3u_path, playlist_uuid = save_m3u(simplified, base_filename)

            # ‚úÖ GENERAR NOMBRE AMIGABLE PARA LA PLAYLIST
            if country_type == "origin":
                playlist_name = f"M√∫sica de {country_name}"
            else:
                playlist_name = f"Lo m√°s escuchado en {country_name}"
                
            if len(simplified) < 5:
                playlist_name = f"{country_name} - Selecci√≥n musical"

            # Construir filtros para el documento
            country_filters = {}
            if country_type == "origin":
                country_filters = {"ArtistArea": country_name}
            else:
                country_filters = {
                    "$or": [
                        {"TopCountry1": country_name},
                        {"TopCountry2": country_name},
                        {"TopCountry3": country_name}
                    ]
                }

            # ‚úÖ Obtener estad√≠sticas de distribuci√≥n TopCountry
            topcountry_stats = get_topcountry_distribution(final_tracks, country_name) if country_type != "origin" else {}

            playlist_doc = {
                "query_original": query_text,
                "name": playlist_name,
                "filters": country_filters,
                "sort_by": "RelativePopularityScore",
                "limit": len(simplified),
                "created_at": start_ts,
                "m3u_path": m3u_path,
                "playlist_uuid": playlist_uuid,
                "items": simplified,
                "stats": {
                    "total": len(simplified), 
                    "country_mode": True,
                    "country": country_name,
                    "country_type": country_type,
                    "regenerated": regenerate,
                    "topcountry_distribution": topcountry_stats  # ‚úÖ NUEVO: Estad√≠sticas
                },
                "feedback_pending": True,
                "user_email": user_email,
                "type": "country"
            }

            try:
                res = playlists_col.insert_one(playlist_doc)
                playlist_id = str(res.inserted_id)
                logger.debug(f"üíæ Playlist PA√çS guardada con id {playlist_id} para usuario {user_email}")
            except Exception as e:
                logger.exception(f"Error inserting playlist doc (country mode): {e}")
                playlist_id = None

            # Respuesta final para modo pa√≠s
            return {
                "query_original": query_text,
                "playlist_name": playlist_name,
                "filtros": country_filters,
                "criterio_orden": "RelativePopularityScore",
                "total": len(simplified),
                "playlist": simplified,
                "archivo_m3u": m3u_path,
                "playlist_id": playlist_id,
                "playlist_uuid": playlist_uuid,
                "user_email": user_email,
                "debug_summary": {
                    "country_mode": True,
                    "country": country_name,
                    "country_type": country_type,
                    "llm_analysis": llm_analysis,
                    "normalization_applied": True,
                    "excluded_count": len(excluded_titles),
                    "topcountry_distribution": topcountry_stats  # ‚úÖ NUEVO
                },
            }
        
    qtype = llm_analysis.get("type", "")
    artist_name = llm_analysis.get("artist") or None
    album_name = llm_analysis.get("album") or None
    track_name = llm_analysis.get("track") or None
    logger.debug(f"üß† An√°lisis de intenci√≥n (v√≠a modelo local): {json.dumps(llm_analysis, ensure_ascii=False)}")
    
    # ‚úÖ USAR L√çMITE DETECTADO
    detected_limit = llm_analysis.get("detected_limit", 30)
    logger.debug(f"üî¢ L√≠mite a usar: {detected_limit} (detectado del prompt)")

    logger.debug(f"üß† An√°lisis sem√°ntico: {llm_analysis}")

    qtype = llm_analysis.get("type", "")
    artist_name = llm_analysis.get("artist") or None
    album_name = llm_analysis.get("album") or None
    track_name = llm_analysis.get("track") or None

    # 3Ô∏è‚É£ Detecci√≥n directa de entidad en base local
    detected = detect_artist_album_track(query_clean, tracks_col)
    entity_type, entity_name = detected["tipo"], detected["nombre"]
    logger.debug(f"üéØ Entidad detectada: {entity_type} -> {entity_name}")

    # Si no hay artista claro desde LLM, usa el detectado localmente
    if not artist_name and entity_type == "artista":
        artist_name = entity_name
        logger.debug(f"üîÅ Artist fallback: usando entidad local detectada ‚Üí {artist_name}")

    # ============================================================
    # üèÜ 4Ô∏è‚É£ Caso: "Lo mejor de X" o petici√≥n de artista
    # ============================================================
    intent_type = llm_analysis.get("type", "").strip()
    artist_name = llm_analysis.get("artist", "").strip()
    album_name = llm_analysis.get("album", "").strip()
    track_name = llm_analysis.get("track", "").strip()

    genre_value = llm_analysis.get("genre", "")
    if isinstance(genre_value, list):
        genre = ", ".join(map(str, genre_value))
    else:
        genre = str(genre_value).strip()
    
    decade_value = llm_analysis.get("decade", "")
    if isinstance(decade_value, list):
        decade = ", ".join(map(str, decade_value))
    else:
        decade = str(decade_value).strip()
    
    mood = llm_analysis.get("mood", "").strip()

    logger.debug(f"üéØ Tipo de solicitud detectado por LLM: {intent_type}")

    # Fallback por regex si el modelo no clasific√≥ bien
    if not intent_type and re.search(r"(mejor de|best of|top de|grandes √©xitos)", query_clean, re.I):
        intent_type = "artist_request"
        logger.debug("üîé Fallback regex: Identificado como artist_request")
    elif not intent_type and re.search(r"(similares a|parecidas a|similar to)", query_clean, re.I):
        intent_type = "similar_to_request"
        logger.debug("üîé Fallback regex: Identificado como similar_to_request")
    elif not intent_type:
        intent_type = "genre_or_mood_request"
        logger.debug("üîé Fallback regex: Identificado como genre_or_mood_request")

    logger.debug(f"üß≠ Modo elegido: {intent_type} | Artista='{artist_name}' | √Ålbum='{album_name}' | Track='{track_name}' | G√©nero='{genre}' | D√©cada='{decade}' | Mood='{mood}'")

    # ============================================================
    # üèÜ 5Ô∏è‚É£ MODO ARTISTA: "Lo mejor de X"
    # ============================================================
    if intent_type == "artist_request" and artist_name:
        target_artist = artist_name
        logger.debug(f"üé∏ Modo artista activado ‚Üí '{target_artist}'")
        
        artist_limit = min(detected_limit, 50)  # M√°ximo 50 por seguridad
        # 1Ô∏è‚É£ Obtener mejores pistas
        best_tracks = get_best_of_artist(target_artist, tracks_col, limit=artist_limit, llm=run_local_llm)
        if not best_tracks:
            logger.debug(f"‚ö†Ô∏è Sin resultados directos para '{target_artist}', buscando similares...")
            best_tracks = get_best_of_artist(target_artist, tracks_col, limit=artist_limit, llm=run_local_llm)
        if not best_tracks:
            logger.debug(f"‚ö†Ô∏è A√∫n no hay pistas para '{target_artist}' tras busqueda de similares.")
            return {
                "query_original": query_text,
                "filtros": {"Artista": target_artist},
                "criterio_orden": "RelativePopularityScore",
                "total": 0,
                "playlist": [],
                "archivo_m3u": "",
                "debug_summary": {"artist_mode": True, "llm_analysis": llm_analysis},
            }

        # üÜï Excluir pistas previas (si aplica regeneraci√≥n)
        if regenerate:
            logger.debug("üÜï Aplicando exclusi√≥n de pistas previas en modo ARTISTA.")
            best_tracks = exclude_previous_tracks(best_tracks, excluded_titles, excluded_paths)
            logger.debug(f"üÜï Tras exclusi√≥n, quedan {len(best_tracks)} pistas candidatas para ordenar.")

        # 2Ô∏è‚É£ Calcular PopularityScore basado en playcount / views
        global_max = get_global_max_values()
        for t in best_tracks:
            t["PopularityScore"] = compute_popularity(t, global_max)
            if not t.get("PopularityScore"):
                base_score = t.get("LastFMPlaycount") or t.get("YouTubeViews") or 0
                t["PopularityScore"] = min(1.0, math.log1p(base_score) / 20.0)

        # 3Ô∏è‚É£ Normalizar relativa por g√©nero
        compute_relative_popularity_by_genre(best_tracks)

        # 4Ô∏è‚É£ Ordenar por mayor popularidad relativa
        best_tracks.sort(key=lambda x: x.get("RelativePopularityScore", 0), reverse=True)
        logger.debug(f"‚úÖ Ordenadas {len(best_tracks)} pistas por RelativePopularityScore (desc).")

        # 5Ô∏è‚É£ Generar salida simplificada
        simplified = [{
            "Ruta": t.get("Ruta"),
            "Titulo": t.get("Titulo"),
            "Artista": t.get("Artista"),
            "Album": t.get("Album"),
            "A√±o": t.get("A√±o"),
            "Genero": t.get("Genero"),
            "Duracion_mmss": t.get("Duracion_mmss"),
            "Bitrate": t.get("Bitrate"),
            "Calidad": t.get("Calidad"),
            "CoverCarpeta": t.get("CoverCarpeta"),
            "RelativePopularityScore": round(t.get("RelativePopularityScore", 0.0), 3),
            "PopularityDisplay": popularity_display(t.get("RelativePopularityScore", 0.0)),
        } for t in best_tracks]

        # 6Ô∏è‚É£ Guardar M3U y registro CON USUARIO
        base_filename = re.sub(r"\s+", "_", target_artist.lower())[:60]
        m3u_path, playlist_uuid = save_m3u(simplified, base_filename)

        # ‚úÖ GENERAR NOMBRE AMIGABLE PARA LA PLAYLIST
        playlist_name = f"Lo mejor de {target_artist}"
        if len(simplified) < 5:
            playlist_name = f"{target_artist} - Selecci√≥n"

        playlist_doc = {
            "query_original": query_text,
            "name": playlist_name,  # ‚úÖ NOMBRE PARA MOSTRAR AL USUARIO
            "filters": {"Artista": target_artist},
            "sort_by": "RelativePopularityScore",
            "limit": len(simplified),
            "created_at": start_ts,
            "m3u_path": m3u_path,
            "playlist_uuid": playlist_uuid,
            "items": simplified,
            "stats": {
                "total": len(simplified), 
                "artist_mode": True, 
                "regenerated": regenerate
            },
            "feedback_pending": True,
            "user_email": user_email,  # ‚úÖ ASOCIADO AL USUARIO
            "type": "artist"  # ‚úÖ TIPO DE PLAYLIST
        }

        try:
            res = playlists_col.insert_one(playlist_doc)
            playlist_id = str(res.inserted_id)
            logger.debug(f"üíæ Playlist ARTISTA guardada con id {playlist_id} para usuario {user_email}")
        except Exception as e:
            logger.exception(f"Error inserting playlist doc (artist mode): {e}")
            playlist_id = None

        # 7Ô∏è‚É£ Respuesta final
        return {
            "query_original": query_text,
            "playlist_name": playlist_name,  # ‚úÖ NOMBRE PARA EL FRONTEND
            "filtros": {"Artista": target_artist},
            "criterio_orden": "RelativePopularityScore",
            "total": len(simplified),
            "playlist": simplified,
            "archivo_m3u": m3u_path,
            "playlist_id": playlist_id,
            "playlist_uuid": playlist_uuid,
            "user_email": user_email,  # ‚úÖ INCLUIR EMAIL EN RESPUESTA
            "debug_summary": {
                "artist_mode": True,
                "llm_analysis": llm_analysis,
                "normalization_applied": True,
                "excluded_count": len(excluded_titles),
            },
        }

    # ============================================================
    # üéß 6Ô∏è‚É£ Caso: "Similares a X"
    # ============================================================
    if intent_type == "similar_to_request":
        ref_name = artist_name or track_name or re.sub(
            r"(similares a|parecidas a|similar to)\s+", "", query_clean, flags=re.I
        ).strip()

        logger.debug(f"üîÅ Modo similitud activado para: {ref_name}")

        # 1Ô∏è‚É£ Buscar artistas o temas similares
        similar_limit = min(detected_limit * 2, 60)  # Buscar m√°s para tener opciones
        similar_tracks = find_similar_artists(ref_name, tracks_col, llm=run_local_llm, limit=similar_limit)

        if not similar_tracks:
            logger.debug(f"‚ö†Ô∏è No se encontraron pistas similares para '{ref_name}'")
            return {
                "query_original": query_text,
                "filtros": {"similar_a": ref_name},
                "criterio_orden": "RelativePopularityScore",
                "total": 0,
                "playlist": [],
                "archivo_m3u": "",
                "debug_summary": {"similarity_mode": True, "llm_analysis": llm_analysis},
            }

        # üÜï Excluir pistas previas si estamos regenerando
        if regenerate:
            logger.debug("üÜï Aplicando exclusi√≥n de pistas previas en modo SIMILARES.")
            similar_tracks = exclude_previous_tracks(similar_tracks, excluded_titles, excluded_paths)
            logger.debug(f"üÜï Tras exclusi√≥n, quedan {len(similar_tracks)} pistas similares candidatas.")

        # 2Ô∏è‚É£ Calcular PopularityScore
        global_max = get_global_max_values()
        for t in similar_tracks:
            t["PopularityScore"] = compute_popularity(t, global_max)
            if not t.get("PopularityScore"):
                base_score = t.get("LastFMPlaycount") or t.get("YouTubeViews") or 0
                t["PopularityScore"] = min(1.0, math.log1p(base_score) / 20.0)

        # 3Ô∏è‚É£ Deduplicar versiones
        deduped_tracks = deduplicate_tracks_by_title_keep_best(similar_tracks)

        # 4Ô∏è‚É£ Aplicar normalizaci√≥n relativa por g√©nero
        compute_relative_popularity_by_genre(deduped_tracks)

        # 5Ô∏è‚É£ Ordenar y filtrar seg√∫n filtros sem√°nticos del prompt (g√©nero/d√©cada/mood)
        if genre or decade or mood:
            deduped_tracks = [
                t for t in deduped_tracks
                if (not genre or genre.lower() in str(t.get("Genero", "")).lower())
                and (not decade or decade in str(t.get("Decada", "")))
            ]
            logger.debug(f"üîé Aplicados filtros sem√°nticos sobre tracks similares: quedan {len(deduped_tracks)} items.")

        deduped_tracks.sort(key=lambda x: x.get("RelativePopularityScore", 0), reverse=True)
        logger.debug(f"‚úÖ Ordenadas {len(deduped_tracks)} pistas similares por RelativePopularityScore (desc).")

        # 6Ô∏è‚É£ Generar salida simplificada
        simplified = [{
            "Ruta": t.get("Ruta"),
            "Titulo": t.get("Titulo"),
            "Artista": t.get("Artista"),
            "Album": t.get("Album"),
            "A√±o": t.get("A√±o"),
            "Genero": t.get("Genero"),
            "Duracion_mmss": t.get("Duracion_mmss"),
            "Bitrate": t.get("Bitrate"),
            "Calidad": t.get("Calidad"),
            "CoverCarpeta": t.get("CoverCarpeta"),
            "RelativePopularityScore": round(t.get("RelativePopularityScore", 0.0), 3),
            "PopularityDisplay": popularity_display(t.get("RelativePopularityScore", 0.0)),
        } for t in deduped_tracks[:20]]

        # 7Ô∏è‚É£ Guardar y responder CON USUARIO
        m3u_path, playlist_uuid = save_m3u(simplified, ref_name)

        # ‚úÖ GENERAR NOMBRE AMIGABLE
        playlist_name = f"Similares a {ref_name}"
        if len(simplified) < 5:
            playlist_name = f"Recomendaciones como {ref_name}"

        playlist_doc = {
            "query_original": query_text,
            "name": playlist_name,  # ‚úÖ NOMBRE PARA MOSTRAR
            "filters": {"similar_a": ref_name, "Genero": genre, "Decada": decade},
            "sort_by": "RelativePopularityScore",
            "limit": len(simplified),
            "created_at": start_ts,
            "m3u_path": m3u_path,
            "playlist_uuid": playlist_uuid,
            "items": simplified,
            "stats": {
                "total": len(simplified), 
                "similarity_mode": True, 
                "regenerated": regenerate
            },
            "feedback_pending": True,
            "user_email": user_email,  # ‚úÖ ASOCIADO AL USUARIO
            "type": "similar"  # ‚úÖ TIPO DE PLAYLIST
        }

        try:
            res = playlists_col.insert_one(playlist_doc)
            playlist_id = str(res.inserted_id)
            logger.debug(f"üíæ Playlist SIMILARES guardada con id {playlist_id} para usuario {user_email}")
        except Exception as e:
            logger.exception(f"Error inserting playlist doc (similarity mode): {e}")
            playlist_id = None

        return {
            "query_original": query_text,
            "playlist_name": playlist_name,  # ‚úÖ NOMBRE PARA EL FRONTEND
            "filtros": {"similar_a": ref_name, "Genero": genre, "Decada": decade},
            "criterio_orden": "RelativePopularityScore",
            "total": len(simplified),
            "playlist": simplified,
            "archivo_m3u": m3u_path,
            "playlist_id": playlist_id,
            "playlist_uuid": playlist_uuid,
            "user_email": user_email,  # ‚úÖ INCLUIR EMAIL EN RESPUESTA
            "debug_summary": {
                "similarity_mode": True,
                "llm_analysis": llm_analysis,
                "normalization_applied": True,
                "excluded_count": len(excluded_titles),
            },
        }

    # ============================================================
    # üåà 7Ô∏è‚É£ Flujo est√°ndar (g√©nero, mood, √©poca, etc.) - MEJORADO CON PA√çS
    # ============================================================
    logger.debug("üéº Ejecutando flujo est√°ndar (g√©nero/estado de √°nimo).")

    # ‚úÖ NUEVO: Inyectar filtros de pa√≠s en el flujo h√≠brido si est√°n presentes
    llm_analysis_for_hybrid = llm_analysis.copy()
    
    # 1Ô∏è‚É£ Procesamiento base h√≠brido (LLM + heur√≠sticas locales) con pa√≠s
    llm_raw = hybrid_playlist_cycle_enhanced(query_clean, llm_analysis=llm_analysis_for_hybrid) or {}
    filters_raw = llm_raw.get("filters", {}) or {}
    suggestions = llm_raw.get("suggestions", [])
    sort_by = llm_raw.get("sort_by")
    order = int(llm_raw.get("order", -1)) if llm_raw.get("order") in (1, -1, None) else -1
    limit = min(detected_limit, 100)
    logger.debug(f"üî¢ L√≠mite final aplicado: {limit}")
    
    # 2Ô∏è‚É£ Combinar filtros sem√°nticos con los del modelo h√≠brido
    filters_combined = dict(filters_raw)  # copia base
    
    # ‚úÖ NUEVO: A√±adir filtros de pa√≠s del an√°lisis sem√°ntico
    country = llm_analysis.get("country")
    country_type = llm_analysis.get("country_type")
    if country and country_type:
        country_filters = parse_filters_from_llm({
            "country": country,
            "country_type": country_type
        })
        filters_combined.update(country_filters)
        logger.debug(f"üá®üá± Filtros de pa√≠s a√±adidos al flujo est√°ndar: {country} ({country_type})")
    
    # 3Ô∏è‚É£ Tomar filtros inferidos del an√°lisis sem√°ntico previo (llm_analysis)
    genre = llm_analysis.get("genre")
    decade = llm_analysis.get("decade")
    if decade:
        # Aplicar filtro de d√©cada resuelta
        filters_combined["Decada"] = decade
        logger.debug(f"üï∞Ô∏è Aplicando filtro de d√©cada: {decade}")
    mood = llm_analysis.get("mood")
    energy = llm_analysis.get("energy")
    intent = llm_analysis.get("intent")

    logger.debug(f"üé® Enriqueciendo filtros est√°ndar con an√°lisis sem√°ntico ‚Üí genre={genre}, decade={decade}, mood={mood}, energy={energy}, country={country}")

    # ‚ûï A√±adir g√©nero
    if genre and "Genero" not in filters_combined:
        filters_combined["Genero"] = {"$regex": genre, "$options": "i"}

    # ‚ûï A√±adir d√©cada o a√±o - CON SOPORTE PARA M√öLTIPLES D√âCADAS
    if decade and "Decada" not in filters_combined and "A√±o" not in filters_combined:
        if isinstance(decade, list):
            # ‚úÖ M√∫ltiples d√©cadas: ["1980s", "1990s"]
            decade_ranges = []
            for d in decade:
                if d == "1980s":
                    decade_ranges.append({"$gte": 1980, "$lt": 1990})
                elif d == "1990s":
                    decade_ranges.append({"$gte": 1990, "$lt": 2000})
                elif d == "2000s":
                    decade_ranges.append({"$gte": 2000, "$lt": 2010})
                elif d == "2010s":
                    decade_ranges.append({"$gte": 2010, "$lt": 2020})
                elif d == "2020s":
                    decade_ranges.append({"$gte": 2020, "$lt": 2030})
            
            if decade_ranges:
                filters_combined["A√±o"] = {"$or": decade_ranges}
                filters_combined["Decada"] = {"$in": decade}
        elif isinstance(decade, str):
            # ‚úÖ D√©cada √∫nica
            filters_combined["Decada"] = decade
            # Tambi√©n a√±adir rango de a√±os para compatibilidad
            if decade == "1980s":
                filters_combined["A√±o"] = {"$gte": 1980, "$lt": 1990}
            elif decade == "1990s":
                filters_combined["A√±o"] = {"$gte": 1990, "$lt": 2000}
            elif decade == "2000s":
                filters_combined["A√±o"] = {"$gte": 2000, "$lt": 2010}
            elif decade == "2010s":
                filters_combined["A√±o"] = {"$gte": 2010, "$lt": 2020}
            elif decade == "2020s":
                filters_combined["A√±o"] = {"$gte": 2020, "$lt": 2030}

    # ‚ûï A√±adir mood si corresponde (usa campos emocionales)
    if mood and not any(k.startswith("EMO_") for k in filters_combined.keys()):
        filters_combined["EMO_Sound"] = {"$regex": mood, "$options": "i"}

    # 4Ô∏è‚É£ Enriquecer con filtros ac√∫sticos y sanitizar
    filters_enriched = enrich_filters_with_acoustics(query_clean, filters_combined)
    filters_safe = sanitize_filters(filters_enriched)
    mongo_filters = dict(filters_safe)

    # ‚úÖ DEBUG DETALLADO DE FILTROS
    logger.debug(f"üß© Filtros combinados: {json.dumps(filters_combined, ensure_ascii=False)}")
    logger.debug(f"üß© Filtros enriquecidos: {json.dumps(filters_enriched, ensure_ascii=False)}")
    logger.debug(f"üß© Filtros finales aplicados ‚Üí {json.dumps(mongo_filters, ensure_ascii=False)}")

    # 5Ô∏è‚É£ Consulta principal a la base de datos
    results = list(tracks_col.find(mongo_filters))
    logger.debug(f"üìä Resultados encontrados con filtros: {len(results)}")

    # üÜï Excluir pistas previas si estamos regenerando en flujo est√°ndar
    if regenerate:
        logger.debug("üÜï Aplicando exclusi√≥n de pistas previas en modo EST√ÅNDAR.")
        results = exclude_previous_tracks(results, excluded_titles, excluded_paths)
        logger.debug(f"üÜï Tras exclusi√≥n, quedaron {len(results)} resultados en la b√∫squeda est√°ndar.")

    if not results:
        logger.debug(f"‚ö†Ô∏è Sin resultados directos con filtros {mongo_filters}, intentando expansi√≥n...")
        
        # ‚úÖ NUEVO: Expansi√≥n espec√≠fica para pa√≠ses con b√∫squeda jer√°rquica
        if country and "ArtistArea" in mongo_filters:
            logger.debug(f"üîÅ Expandiendo b√∫squeda de pa√≠s {country} con prioridad jer√°rquica...")
            expanded_results = []
            
            # 1. Primero TopCountry1
            query_tc1 = {"TopCountry1": {"$regex": country, "$options": "i"}}
            results_tc1 = list(tracks_col.find(query_tc1).sort("PopularityScore", -1).limit(limit))
            expanded_results.extend(results_tc1)
            
            # 2. Si no alcanzamos, TopCountry2
            if len(expanded_results) < limit:
                remaining = limit - len(expanded_results)
                query_tc2 = {
                    "TopCountry2": {"$regex": country, "$options": "i"},
                    "_id": {"$nin": [r["_id"] for r in expanded_results]}
                }
                results_tc2 = list(tracks_col.find(query_tc2).sort("PopularityScore", -1).limit(remaining))
                expanded_results.extend(results_tc2)
            
            # 3. Si a√∫n no alcanzamos, TopCountry3
            if len(expanded_results) < limit:
                remaining = limit - len(expanded_results)
                query_tc3 = {
                    "TopCountry3": {"$regex": country, "$options": "i"},
                    "_id": {"$nin": [r["_id"] for r in expanded_results]}
                }
                results_tc3 = list(tracks_col.find(query_tc3).sort("PopularityScore", -1).limit(remaining))
                expanded_results.extend(results_tc3)
            
            results = expanded_results
            logger.debug(f"üîÅ B√∫squeda expandida jer√°rquica de pa√≠s, resultados obtenidos: {len(results)}")
        
        # Intentar primero sin g√©nero
        if not results and "Genero" in mongo_filters:
            fallback_filters = dict(mongo_filters)
            del fallback_filters["Genero"]
            results = list(tracks_col.find(fallback_filters))
            logger.debug(f"üîÅ B√∫squeda expandida sin 'Genero', resultados obtenidos: {len(results)}")
        
        # Si a√∫n no hay resultados, intentar sin d√©cada
        if not results and "Decada" in mongo_filters:
            fallback_filters2 = dict(mongo_filters)
            del fallback_filters2["Decada"]
            # Tambi√©n quitar A√±o si existe
            fallback_filters2.pop("A√±o", None)
            results = list(tracks_col.find(fallback_filters2))
            logger.debug(f"üîÅ B√∫squeda expandida sin 'Decada', resultados obtenidos: {len(results)}")

    # 6Ô∏è‚É£ Calcular m√©tricas y ordenar
    global_max = get_global_max_values()
    for t in results:
        t["PopularityScore"] = compute_popularity(t, global_max)

    results = deduplicate_tracks_by_title_keep_best(results)
    compute_relative_popularity_by_genre(results)
    cleaned_results = filter_gross_incongruities(results, query_clean)
    cleaned_results = apply_limits_and_fallback(cleaned_results, query_clean, limit)

    cleaned_results.sort(key=lambda x: x.get(sort_by or "RelativePopularityScore", 0), reverse=True)
    final_results = cleaned_results[:limit]

    # 7Ô∏è‚É£ Estructura simplificada
    simplified = [{
        "Ruta": t.get("Ruta"),
        "Titulo": t.get("Titulo"),
        "Artista": t.get("Artista"),
        "Album": t.get("Album"),
        "A√±o": t.get("A√±o"),
        "Genero": t.get("Genero"),
        "Duracion_mmss": t.get("Duracion_mmss"),
        "Bitrate": t.get("Bitrate"),
        "Calidad": t.get("Calidad"),
        "CoverCarpeta": t.get("CoverCarpeta"),
        "RelativePopularityScore": t.get("RelativePopularityScore"),
        "PopularityDisplay": popularity_display(t.get("RelativePopularityScore")),
    } for t in final_results]

    # 8Ô∏è‚É£ Guardar resultados y registro CON USUARIO
    m3u_path, playlist_uuid = save_m3u(simplified, re.sub(r"[^\w\s-]", "", query_clean)[:60])
    
    # ‚úÖ GENERAR NOMBRE AMIGABLE
    playlist_name = query_text[:80]  # Usar el query como nombre, truncado
    if len(simplified) > 0:
        # Intentar crear nombre m√°s descriptivo
        main_genre = simplified[0].get("Genero", "")
        if isinstance(main_genre, list) and main_genre:
            main_genre = main_genre[0]
        country_part = f" de {country}" if country else ""
        playlist_name = f"{country_part} - {query_text[:40]}..." if main_genre else f"{query_text[:60]}{country_part}"

    # ‚úÖ Obtener estad√≠sticas de distribuci√≥n TopCountry si es pa√≠s
    topcountry_stats = {}
    if country and country_type != "origin":
        topcountry_stats = get_topcountry_distribution(final_results, country)

    playlist_doc = {
        "query_original": query_text,
        "name": playlist_name,  # ‚úÖ NOMBRE PARA MOSTRAR
        "filters": mongo_filters,
        "limit": limit,
        "created_at": start_ts,
        "m3u_path": m3u_path,
        "playlist_uuid": playlist_uuid,
        "items": simplified,
        "stats": {
            "total": len(simplified), 
            "standard_mode": True, 
            "country": country if country else None,
            "country_type": country_type if country else None,
            "regenerated": regenerate,
            "topcountry_distribution": topcountry_stats  # ‚úÖ NUEVO: Estad√≠sticas
        },
        "feedback_pending": True,
        "user_email": user_email,  # ‚úÖ ASOCIADO AL USUARIO
        "type": "country" if country else "standard"  # ‚úÖ TIPO DE PLAYLIST
    }
    
    try:
        res = playlists_col.insert_one(playlist_doc)
        playlist_id = str(res.inserted_id)
        logger.debug(f"üíæ Playlist {'PA√çS' if country else 'EST√ÅNDAR'} guardada con id {playlist_id} para usuario {user_email}")
    except Exception as e:
        logger.exception(f"Error inserting playlist doc ({'country' if country else 'standard'} mode): {e}")
        playlist_id = None

    # 9Ô∏è‚É£ Respuesta final
    debug_summary = {
        "standard_mode": True,
        "llm_analysis": llm_analysis,
        "filters_applied": mongo_filters,
        "excluded_count": len(excluded_titles),
    }
    
    # ‚úÖ A√±adir informaci√≥n de pa√≠s al debug summary si est√° presente
    if country:
        debug_summary["country_mode"] = True
        debug_summary["country"] = country
        debug_summary["country_type"] = country_type
        debug_summary["topcountry_distribution"] = topcountry_stats  # ‚úÖ NUEVO

    return {
        "query_original": query_text,
        "playlist_name": playlist_name,  # ‚úÖ NOMBRE PARA EL FRONTEND
        "filtros": mongo_filters,
        "criterio_orden": sort_by or "RelativePopularityScore",
        "total": len(simplified),
        "playlist": simplified,
        "archivo_m3u": m3u_path,
        "playlist_id": playlist_id,
        "playlist_uuid": playlist_uuid,
        "user_email": user_email,  # ‚úÖ INCLUIR EMAIL EN RESPUESTA
        "debug_summary": debug_summary,
    }

# -----------------------
# Helper: popularity display (based on relative score)
# -----------------------
def popularity_display(score: Optional[float]) -> str:
    if score is None:
        return "N/A"
    value_10 = round(score * 10, 1)
    stars_count = int(round(score * 5))
    stars = "‚òÖ" * stars_count + "‚òÜ" * (5 - stars_count)
    if score >= 0.9:
        label = "√çcono"
    elif score >= 0.7:
        label = "Estrella"
    elif score >= 0.45:
        label = "Popular"
    elif score >= 0.25:
        label = "Conocido"
    else:
        label = "Emergente"
    return f"{value_10}/10 {stars} ({label})"

# -----------------------
# feedback endpoint
# -----------------------
@app.post("/feedback")
def feedback(body: FeedbackIn):
    if body.rating < 1 or body.rating > 10:
        raise HTTPException(status_code=400, detail="rating must be 1..10")
    try:
        pid = ObjectId(body.playlist_id)
    except Exception:
        raise HTTPException(status_code=400, detail="invalid playlist_id")
    pl = playlists_col.find_one({"_id": pid})
    if not pl:
        raise HTTPException(status_code=404, detail="playlist not found")
    doc = {
        "playlist_id": body.playlist_id,
        "rating": int(body.rating),
        "comment": body.comment or "",
        "created_at": datetime.utcnow()
    }
    feedback_col.insert_one(doc)
    playlists_col.update_one({"_id": pid}, {"$set": {"user_rating": int(body.rating), "feedback_pending": False}})
    return {"ok": True, "msg": "feedback registrado"}

# -----------------------
# get playlist by id (MEJORADO con opci√≥n de seguridad)
# -----------------------
@app.get("/playlist/{pid}")
def get_playlist(pid: str, request: Request = None, user_check: bool = False):
    """
    Obtiene una playlist por ID.
    Si user_check=True, verifica que pertenezca al usuario autenticado.
    """
    try:
        oid = ObjectId(pid)
    except Exception:
        raise HTTPException(status_code=400, detail="invalid id")
    
    # Construir query base
    query = {"_id": oid}
    
    # Si se solicita verificaci√≥n de usuario
    if user_check and request:
        try:
            auth_header = request.headers.get("Authorization")
            if auth_header and "Bearer" in auth_header:
                token = auth_header.replace("Bearer ", "").strip()
                user = db_auth.users.find_one({"session_token": token})
                if user:
                    query["user_email"] = user.get("email")
        except Exception as e:
            logger.warning(f"Error en verificaci√≥n de usuario: {e}")
    
    p = playlists_col.find_one(query)
    if not p:
        raise HTTPException(status_code=404, detail="playlist not found")
    
    # Convertir ObjectId a string
    p["id"] = str(p["_id"])
    p.pop("_id", None)
    
    # ‚úÖ Asegurar URLs de streaming
    if "items" in p and isinstance(p["items"], list):
        for item in p["items"]:
            if item.get("Ruta"):
                item["StreamURL"] = convert_path_to_url(item["Ruta"])
            if item.get("CoverCarpeta"):
                item["CoverURL"] = convert_path_to_url(item.get("CoverCarpeta"))
    
    return p

# -----------------------
# Root
# -----------------------
@app.get("/")
def root():
    return {"msg": "NeoPlaylist API (V15 h√≠brida) operativa üöÄ"}

# -----------------------
# Main (run with uvicorn)
# -----------------------
if __name__ == "__main__":
    uvicorn.run("playlist_api_refinedV15enchanced:app", host="0.0.0.0", port=8000, reload=True)


def call_ollama_safe(prompt_text: str, model: str = "neoplaylist-agent", timeout: int = 40):
    """
    Invoca el modelo Ollama de manera segura y tolerante a errores.
    - Maneja respuestas JSON mal formadas de forma robusta
    - Extrae y repara JSON de texto mixto
    - Devuelve SIEMPRE un dict v√°lido
    """
    OLLAMA_URL = "http://localhost:11434/api/generate"
    payload = {"model": model, "prompt": prompt_text, "stream": False}
    logging.info(f"üß† Llamando a Ollama ({model}) con timeout={timeout}s")

    try:
        response = requests.post(OLLAMA_URL, json=payload, timeout=timeout)
        response.raise_for_status()
        data = response.json()

        # üîç Extraer texto de respuesta de forma robusta
        raw_text = ""
        if isinstance(data, dict):
            raw_text = (
                data.get("response", "")
                or data.get("output", "")
                or data.get("text", "")
                or (data.get("message", {}).get("content") if isinstance(data.get("message"), dict) else "")
                or str(data)
            )
        elif isinstance(data, str):
            raw_text = data
        else:
            raw_text = str(data)

        if not raw_text.strip():
            logging.warning("‚ö†Ô∏è Ollama devolvi√≥ respuesta vac√≠a.")
            return {}

        # ‚úÖ INTENTAR PARSEAR DIRECTAMENTE PRIMERO
        try:
            parsed = json.loads(raw_text.strip())
            logging.info("‚úÖ JSON parseado directamente sin reparaci√≥n")
            return parsed
        except json.JSONDecodeError:
            pass  # Proceder con reparaci√≥n

        # üõ†Ô∏è REPARACI√ìN ROBUSTA DE JSON
        repaired_json = _repair_json_response(raw_text)
        if repaired_json:
            logging.info("‚úÖ JSON reparado exitosamente")
            return repaired_json

        # üîç SI LA REPARACI√ìN FALLA, intentar extraer objeto JSON con m√©todos m√°s agresivos
        json_candidates = _extract_json_candidates(raw_text)
        for candidate in json_candidates:
            try:
                parsed = json.loads(candidate)
                logging.info("‚úÖ JSON extra√≠do con m√©todo agresivo")
                return parsed
            except json.JSONDecodeError:
                continue

        # üìù SI TODO FALLA, crear respuesta b√°sica con el texto
        logging.warning("‚ö†Ô∏è No se pudo extraer JSON v√°lido, devolviendo estructura b√°sica")
        return {"raw_response": raw_text[:500], "error": "no_se_pudo_parsear_json"}

    except requests.Timeout:
        logging.warning(f"‚è∞ Timeout al consultar Ollama ({timeout}s)")
        return {"error": "timeout"}
    except requests.RequestException as e:
        logging.error(f"‚ùå Error HTTP al consultar Ollama: {e}")
        return {"error": f"http_error: {str(e)}"}
    except Exception as e:
        logging.error(f"‚ùå Error inesperado en call_ollama_safe: {e}")
        return {"error": f"unexpected_error: {str(e)}"}


def _repair_json_response(raw_text: str) -> Optional[Dict]:
    """
    Repara respuestas JSON mal formadas del modelo.
    Maneja m√∫ltiples escenarios comunes de errores.
    """
    if not raw_text:
        return None

    text = raw_text.strip()
    
    # 1Ô∏è‚É£ ELIMINAR BLOQUES MARKDOWN
    text = re.sub(r'^```[a-zA-Z]*\n', '', text)  # Inicio de c√≥digo
    text = re.sub(r'\n```$', '', text)           # Fin de c√≥digo
    text = re.sub(r'^`|`$', '', text)            # Backticks sueltos
    
    # 2Ô∏è‚É£ CORREGIR COMILLAS
    text = text.replace('‚Äú', '"').replace('‚Äù', '"').replace("'", '"')
    text = text.replace('\\"', '"')  # Unescape comillas
    text = re.sub(r'(?<!\\)"', '"', text)  # Normalizar comillas
    
    # 3Ô∏è‚É£ CORREGIR COMILLAS SIMPLES EN STRINGS (pero mantener en JSON v√°lido)
    # Reemplazar 'texto' por "texto" pero NO afectar comillas simples v√°lidas en JSON
    text = re.sub(r"'(.*?)'(?=\s*[:,\]}])", r'"\1"', text)  # Solo en contexto de clave/valor
    
    # 4Ô∏è‚É£ ELIMINAR COMENTARIOS Y TEXTO EXTRA
    lines = text.split('\n')
    cleaned_lines = []
    for line in lines:
        line = line.strip()
        # Eliminar l√≠neas que son claramente comentarios o instrucciones
        if line.startswith('//') or line.startswith('/*') or line.startswith('*') or line.startswith('#') or 'aqu√≠' in line.lower():
            continue
        # Eliminar l√≠neas que no contienen estructura JSON
        if not any(char in line for char in ['{', '}', '[', ']', ':', '"']):
            continue
        cleaned_lines.append(line)
    
    text = ' '.join(cleaned_lines)
    
    # 5Ô∏è‚É£ CORREGIR PROBLEMAS DE SINTAXIS COMUNES
    # Comas sobrantes antes de } o ]
    text = re.sub(r',\s*([}\]])', r'\1', text)
    # Puntos y comas en lugar de comas
    text = text.replace(';', ',')
    # Claves sin comillas
    text = re.sub(r'(\w+)\s*:', r'"\1":', text)
    # Valores booleanos mal escritos
    text = re.sub(r':\s*True\b', ':true', text, flags=re.IGNORECASE)
    text = re.sub(r':\s*False\b', ':false', text, flags=re.IGNORECASE)
    text = re.sub(r':\s*None\b', ':null', text, flags=re.IGNORECASE)
    
    # 6Ô∏è‚É£ EXTRAER SOLO EL BLOQUE JSON M√ÅS PROBABLE
    json_blocks = re.findall(r'\{[^{}]*\{[^{}]*\}[^{}]*\}|\{[^{}]*\}', text)
    if json_blocks:
        # Tomar el bloque m√°s largo (m√°s probable que sea completo)
        text = max(json_blocks, key=len)
    
    # 7Ô∏è‚É£ INTENTAR PARSEAR
    try:
        return json.loads(text)
    except json.JSONDecodeError as e:
        logging.debug(f"üîß Intento de reparaci√≥n fall√≥: {e}")
        logging.debug(f"üîß Texto reparado: {text[:200]}...")
        return None


def _extract_json_candidates(raw_text: str) -> List[str]:
    """
    Extrae candidatos a JSON del texto usando m√©todos m√°s agresivos.
    """
    candidates = []
    
    # M√©todo 1: Buscar entre llaves m√°s externas
    brace_matches = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', raw_text)
    candidates.extend(brace_matches)
    
    # M√©todo 2: Buscar entre corchetes (para arrays)
    bracket_matches = re.findall(r'\[[^\[\]]*(?:\[[^\[\]]*\][^\[\]]*)*\]', raw_text)
    candidates.extend(bracket_matches)
    
    # M√©todo 3: Buscar desde el primer { hasta el √∫ltimo }
    start_idx = raw_text.find('{')
    end_idx = raw_text.rfind('}')
    if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
        candidates.append(raw_text[start_idx:end_idx+1])
    
    # M√©todo 4: Buscar desde el primer [ hasta el √∫ltimo ]
    start_idx = raw_text.find('[')
    end_idx = raw_text.rfind(']')
    if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
        candidates.append(raw_text[start_idx:end_idx+1])
    
    # Filtrar y ordenar por longitud (los m√°s largos suelen ser m√°s completos)
    candidates = [c for c in candidates if 10 <= len(c) <= 10000]  # Longitudes razonables
    candidates.sort(key=len, reverse=True)
    
    return candidates



# =========================================================
# üîç 1. Detecci√≥n de tipo de entidad desde el prompt
# =========================================================
def detect_artist_album_track(prompt, tracks_col):
    """
    Detecta si el prompt menciona un artista, √°lbum o pista existente.
    Devuelve {'tipo': 'artista'|'album'|'track'|None, 'nombre': '...'}
    """
    prompt_norm = prompt.strip().lower()

    patterns = [
        ("artista", "Artista"),
        ("album", "Album"),
        ("track", "Titulo")
    ]

    # Coincidencia exacta primero
    for tipo, campo in patterns:
        result = tracks_col.find_one(
            {campo: {"$regex": f"^{re.escape(prompt_norm)}$", "$options": "i"}},
            {campo: 1}
        )
        if result:
            return {"tipo": tipo, "nombre": result[campo]}

    # Luego coincidencias parciales
    for tipo, campo in patterns:
        result = tracks_col.find_one(
            {campo: {"$regex": prompt_norm, "$options": "i"}},
            {campo: 1}
        )
        if result:
            return {"tipo": tipo, "nombre": result[campo]}

    return {"tipo": None, "nombre": None}


# =========================================================
# üéµ 2. Resumen local de caracter√≠sticas del artista
# =========================================================
def summarize_artist_features(artist_name, tracks_col):
    """
    Resume las caracter√≠sticas promedio o dominantes de un artista.
    Devuelve un dict con Genero, TempoBPM, EMO_Sound, EMO_Lyrics.
    """
    tracks = list(tracks_col.find(
        {"Artista": {"$regex": f"^{re.escape(artist_name)}$", "$options": "i"}},
        {"Genero": 1, "TempoBPM": 1, "EMO_Sound": 1, "EMO_Lyrics": 1}
    ))

    if not tracks:
        logger.debug(f"No se encontraron pistas para el artista '{artist_name}'")
        return None

    generos = [t.get("Genero") for t in tracks if t.get("Genero")]
    emos_sound = [t.get("EMO_Sound") for t in tracks if t.get("EMO_Sound")]
    emos_lyrics = [t.get("EMO_Lyrics") for t in tracks if t.get("EMO_Lyrics")]
    tempos = [t.get("TempoBPM") for t in tracks if isinstance(t.get("TempoBPM"), (int, float))]

    def most_common(lst):
        return Counter(lst).most_common(1)[0][0] if lst else None

    resumen = {
        "Genero": most_common(generos),
        "TempoBPM": round(mean(tempos), 1) if tempos else None,
        "EMO_Sound": most_common(emos_sound),
        "EMO_Lyrics": most_common(emos_lyrics)
    }

    logger.debug(f"üéß Perfil promedio de '{artist_name}': {resumen}")
    return resumen


# =========================================================
# ü§ñ 3. Fallback con LLM (solo si hay pocos datos)
# =========================================================
def summarize_artist_features_ai(artist_name, sample_tracks, llm=None):
    """
    Si hay pocas pistas, obtiene un resumen estimado de caracter√≠sticas usando un modelo LLM.
    """
    if not sample_tracks:
        return None

    if llm is None:
        logger.debug("‚ö†Ô∏è summarize_artist_features_ai fue llamado sin LLM disponible.")
        return None

    context = "\n".join([
        f"- {t.get('Titulo', 'Sin t√≠tulo')} ({t.get('Genero', '?')}, {t.get('TempoBPM', '?')} BPM, {t.get('EMO_Sound', '?')})"
        for t in sample_tracks[:10]
    ])

    prompt = f"""
Analiza las siguientes pistas del artista {artist_name} y devuelve un JSON con los valores predominantes:
{context}

Formato JSON de salida:
{{
  "Genero": "...",
  "TempoBPM": <aproximado>,
  "EMO_Sound": "...",
  "EMO_Lyrics": "..."
}}
    """

    try:
        result = llm(prompt)
        if isinstance(result, dict):
            resumen = result
        else:
            resumen = json.loads(result)
        logger.debug(f"ü§ñ Resumen AI de '{artist_name}': {resumen}")
        return resumen
    except Exception as e:
        logger.exception(f"Error en summarize_artist_features_ai: {e}")
        return None


# =========================================================
# üß© 4. B√∫squeda de artistas similares
# =========================================================
def find_similar_artists(artist_name, tracks_col, llm=None, limit=5):
    """
    Busca artistas similares bas√°ndose en las caracter√≠sticas promedio del artista dado.
    """
    base_tracks = list(tracks_col.find(
        {"Artista": {"$regex": f"^{re.escape(artist_name)}$", "$options": "i"}},
        {"Titulo": 1, "Genero": 1, "TempoBPM": 1, "EMO_Sound": 1, "EMO_Lyrics": 1}
    ))

    if not base_tracks:
        logger.debug(f"‚ö†Ô∏è No se encontraron pistas para el artista '{artist_name}' en base local.")
        return []

    if len(base_tracks) >= 3:
        resumen = summarize_artist_features(artist_name, tracks_col)
    else:
        resumen = summarize_artist_features_ai(artist_name, base_tracks, llm)

    if not resumen:
        logger.debug(f"‚ö†Ô∏è No se pudo generar resumen de '{artist_name}' para similitud.")
        return []

    query = {
        "Genero": {"$regex": resumen.get("Genero") or "", "$options": "i"},
        "TempoBPM": {
            "$gte": max((resumen.get("TempoBPM") or 0) - 10, 0),
            "$lte": (resumen.get("TempoBPM") or 0) + 10
        },
        "EMO_Sound": {"$regex": resumen.get("EMO_Sound") or "", "$options": "i"},
        "Artista": {"$ne": artist_name},
    }

    similars = list(tracks_col.find(query).sort("RelativePopularityScore", -1).limit(limit))
    logger.debug(f"üéØ Artistas similares a '{artist_name}': encontrados {len(similars)} resultados")
    return similars


# =========================================================
# üèÜ 5. Fallback principal cuando se pide ‚ÄúLo mejor de X‚Äù
# =========================================================
def get_best_of_artist(artist_name, tracks_col, limit=15, llm=None):
    """
    Devuelve las canciones m√°s populares de un artista basadas en:
    1. LastFMPlaycount (prioritario)
    2. YouTubeViews (fallback)
    3. Mejor bitrate entre versiones duplicadas
    ‚úÖ RESPETA EL L√çMITE SOLICITADO
    """
    
    logger.debug(f"üé∏ Buscando TOP {limit} canciones de '{artist_name}'")

    # 1Ô∏è‚É£ Buscar pistas del artista (match flexible) con L√çMITE
    query = {"Artista": {"$regex": artist_name, "$options": "i"}}
    
    # Obtener TODAS las pistas primero para poder ordenar por popularidad
    all_tracks = list(tracks_col.find(query))
    
    if not all_tracks:
        logger.debug(f"‚ö†Ô∏è No se encontraron canciones de '{artist_name}', buscando similares...")
        return find_similar_artists(artist_name, tracks_col, llm, limit=min(limit, 5))

    logger.debug(f"üéß {len(all_tracks)} pistas encontradas para '{artist_name}'")

    # 2Ô∏è‚É£ Normalizar nombre de pista (quita sufijos: versiones, remasters, etc.)
    def normalize_title(title: str):
        if not title:
            return ""
        title_clean = re.sub(r"\(.*?\)", "", title, flags=re.I)  # quita par√©ntesis
        title_clean = re.sub(r"[-_]", " ", title_clean).strip().lower()
        title_clean = re.sub(r"\s+", " ", title_clean)
        return title_clean

    # 3Ô∏è‚É£ Agrupar versiones del mismo tema
    grouped = {}
    for t in all_tracks:
        norm_title = normalize_title(t.get("Titulo", ""))
        if not norm_title:
            continue
        playcount = t.get("LastFMPlaycount") or 0
        ytviews = t.get("YouTubeViews") or 0
        bitrate = t.get("Bitrate") or 0
        score = playcount if playcount > 0 else ytviews
        current_best = grouped.get(norm_title)
        if not current_best or (score > (current_best.get("score") or 0)) or (
            score == (current_best.get("score") or 0) and bitrate > (current_best.get("Bitrate") or 0)
        ):
            grouped[norm_title] = {**t, "score": score}

    # 4Ô∏è‚É£ Filtrar y ordenar por score descendente
    deduped = list(grouped.values())
    deduped.sort(key=lambda x: (x.get("score", 0), x.get("Bitrate", 0)), reverse=True)

    logger.debug(f"üèÜ {len(deduped)} pistas √∫nicas tras deduplicaci√≥n y ranking")

    # 5Ô∏è‚É£ ‚úÖ APLICAR EL L√çMITE SOLICITADO (no el l√≠mite hardcodeado)
    best_tracks = deduped[:limit]

    logger.debug(f"üéØ Devolviendo TOP {len(best_tracks)} canciones de '{artist_name}' (l√≠mite solicitado: {limit})")

    # 6Ô∏è‚É£ Log de diagn√≥stico (opcional)
    for i, t in enumerate(best_tracks[:5]):  # Solo log primeras 5 para no saturar
        logger.debug(
            f"üéµ #{i+1}: {t.get('Titulo')} | {t.get('Album')} | "
            f"LastFMPlaycount={t.get('LastFMPlaycount', 0)} | "
            f"YouTubeViews={t.get('YouTubeViews', 0)} | "
            f"Bitrate={t.get('Bitrate', 0)}"
        )

    return best_tracks




# =========================================================
# üß† 6. An√°lisis sem√°ntico del prompt (LLM vUnified)
# =========================================================
def llm_prompt_intent_analysis(prompt: str, llm=None) -> dict:
    """
    Usa el modelo local NeoPlaylist (Ollama) para analizar la intenci√≥n del prompt musical.
    Devuelve un JSON estructurado con los campos:
    - type: tipo de petici√≥n (artist_request, genre_or_mood_request, etc.)
    - artist, album, track, genre, mood, decade, intent
    """
    try:
        system_prompt = """
Analiza este prompt musical y determina qu√© tipo de petici√≥n es.
Devuelve **EXCLUSIVAMENTE JSON v√°lido**, sin texto adicional.

Tipos posibles:
- "artist_request": cuando el usuario pide algo sobre un artista (ej. "lo mejor de Metallica")
- "album_request": cuando pide un √°lbum espec√≠fico
- "track_request": cuando pide una canci√≥n puntual
- "similar_to_request": cuando menciona "similares a", "parecidas a", "similar to"
- "genre_or_mood_request": cuando menciona g√©neros, emociones, d√©cadas o estilos (ej. "lo mejor del rock de los 80s", "m√∫sica para relajarse")

Estructura esperada:
{
  "type": "...",
  "artist": "...",
  "album": "...",
  "track": "...",
  "genre": "...",
  "mood": "...",
  "decade": "...",
  "intent": "..."
}
"""

        if llm is None:
            logger.debug("‚ö†Ô∏è LLM no disponible, devolviendo tipo gen√©rico.")
            return {"type": "genre_or_mood_request", "intent": "an√°lisis b√°sico sin LLM"}

        # üîπ Solicitud directa al modelo local sin argumentos no soportados
        response = llm(prompt=prompt, system=system_prompt)

        # Si el modelo devuelve texto, intenta extraer el JSON limpio
        if isinstance(response, str):
            json_start = response.find("{")
            json_end = response.rfind("}")
            if json_start != -1 and json_end != -1:
                response = response[json_start:json_end + 1]
            try:
                result = json.loads(response)
            except json.JSONDecodeError:
                logger.warning(f"‚ö†Ô∏è LLM devolvi√≥ JSON inv√°lido: {response}")
                result = {"type": "genre_or_mood_request", "intent": "fallback por error JSON"}
        else:
            result = response

        # Validaci√≥n m√≠nima de claves
        if "type" not in result:
            result["type"] = "genre_or_mood_request"
        result.setdefault("intent", f"Interpretar '{prompt}'")

        logger.debug(f"üß© Intent analysis result: {result}")
        return result

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Intent analysis failed: {e}")
        return {"type": "genre_or_mood_request", "intent": f"error: {str(e)}"}



# =========================================================
# üß† Funci√≥n auxiliar: Ejecutar modelo LLM local (Ollama)
# =========================================================
def run_local_llm(prompt: str) -> str:
    """
    Env√≠a un prompt al modelo local con manejo robusto de errores.
    """
    OLLAMA_URL = "http://localhost:11434/api/generate"
    model = "neoplaylist-agent"

    payload = {"model": model, "prompt": prompt, "stream": False}
    
    try:
        res = requests.post(OLLAMA_URL, json=payload, timeout=40)
        res.raise_for_status()
        data = res.json()
        
        raw_text = data.get("response") or data.get("output") or data.get("text") or ""
        
        # Limpieza b√°sica
        if raw_text:
            # Eliminar instrucciones de formato comunes
            cleaned = re.sub(r'^```json\s*', '', raw_text)
            cleaned = re.sub(r'```\s*$', '', cleaned)
            return cleaned.strip()
        
        return "{}"
        
    except Exception as e:
        logger.error(f"‚ùå Error en run_local_llm: {e}")
        return "{}"
        
        
def analyze_query_intent(query_text: str) -> Dict[str, Any]:
    """
    Clasifica la intenci√≥n de una solicitud musical con mejor detecci√≥n de pa√≠ses y a√±os.
    """
    
    # Primero hacer an√°lisis de pa√≠s
    country_analysis = detect_country_intent(query_text)
    
    prompt = f"""
    Analiza la siguiente consulta musical y extrae:
    1. El tipo de petici√≥n
    2. El l√≠mite num√©rico expl√≠cito
    3. Las entidades musicales (artista, g√©nero, d√©cada, a√±o espec√≠fico, pa√≠s)
    4. Si menciona un pa√≠s, determina si es ORIGEN del artista o POPULARIDAD en ese pa√≠s

    Consulta: "{query_text}"

    üîç **DETECCI√ìN DE PA√çSES:**
    - "m√∫sica chilena" ‚Üí pa√≠s: "Chile", tipo: "origin"  
    - "artistas de Chile" ‚Üí pa√≠s: "Chile", tipo: "origin"
    - "lo m√°s escuchado en Chile" ‚Üí pa√≠s: "Chile", tipo: "popular_in"
    - "popular en Argentina" ‚Üí pa√≠s: "Argentina", tipo: "popular_in"

    üîç **DETECCI√ìN DE TIEMPO:**
    - "a√±os 80" o "d√©cada de los 80" ‚Üí d√©cada: "1980s"
    - "los 80s y 90s" ‚Üí d√©cada: ["1980s", "1990s"]  
    - "2015" o "del 2015" ‚Üí a√±o: 2015 (NO d√©cada)
    - "entre 2010 y 2015" ‚Üí year_range: {{"from": 2010, "to": 2015}}

    üîç **DETECCI√ìN DE L√çMITES:**
    - "top 10" ‚Üí limit: 10
    - "10 canciones" ‚Üí limit: 10

    Devuelve EXCLUSIVAMENTE JSON v√°lido con este formato:

    {{
      "type": "artist_request|similar_to_request|genre_or_mood_request|country_request",
      "artist": "",
      "track": "", 
      "album": "",
      "genre": "",
      "mood": "",
      "decade": "", // para d√©cadas: "1980s", "1990s" o ["1980s", "1990s"]
      "year": null, // para a√±o espec√≠fico: 2015
      "year_range": {{"from": 2010, "to": 2015}}, // para rangos de a√±os
      "country": "", // pa√≠s detectado
      "country_type": "origin|popular_in", // tipo de filtro por pa√≠s
      "limit": 10,
      "intent": "descripci√≥n de la intenci√≥n"
    }}

    Ejemplos:
    - "m√∫sica chilena" ‚Üí "country": "Chile", "country_type": "origin", "type": "country_request"
    - "lo m√°s escuchado en Chile" ‚Üí "country": "Chile", "country_type": "popular_in", "type": "country_request"  
    - "rock de los 80s" ‚Üí "decade": "1980s", "genre": "rock"
    - "lo mejor del 2015" ‚Üí "year": 2015
    - "m√∫sica entre 2010 y 2015" ‚Üí "year_range": {{"from": 2010, "to": 2015}}
    """
    
    try:
        raw_response = run_local_llm(prompt)
        logger.debug(f"üîç Raw response from Ollama: {raw_response}")
        
        analysis = parse_ollama_json_response(raw_response)
        
        # ‚úÖ MEJORA: Combinar con an√°lisis de pa√≠s autom√°tico
        if country_analysis["has_country_intent"]:
            analysis["country"] = country_analysis["country"]
            analysis["country_type"] = country_analysis["country_type"] 
            analysis["type"] = "country_request"
            logger.debug(f"üá®üá± Detecci√≥n de pa√≠s autom√°tica: {country_analysis}")
        
        # ‚úÖ DETECCI√ìN DIRECTA DE "top X" como fallback
        if analysis.get("limit") is None:
            direct_limit = extract_limit_directly(query_text)
            if direct_limit:
                analysis["limit"] = direct_limit
                logger.debug(f"üî¢ L√≠mite detectado directamente: {direct_limit}")

        # Validar y normalizar el l√≠mite
        detected_limit = validate_and_normalize_limit(analysis.get("limit"), query_text)
        analysis["detected_limit"] = detected_limit

        logger.debug(f"üß© Intent analysis result: {analysis}")
        return analysis

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Intent analysis failed: {e}")
        return get_improved_fallback_analysis(query_text)

def extract_limit_directly(query_text: str) -> Optional[int]:
    """
    Detecci√≥n directa y robusta de l√≠mites en el texto.
    """
    text_lower = query_text.lower()
    
    # Patrones m√°s espec√≠ficos para "top X"
    patterns = [
        r'\btop\s+(\d+)\b',                    # "top 10"
        r'\b(\d+)\s+canciones?\b',             # "10 canciones"  
        r'\b(\d+)\s+temas?\b',                 # "5 temas"
        r'\b(\d+)\s+pistas?\b',                # "8 pistas"
        r'\bprimer[oa]s?\s+(\d+)\b',           # "primeras 5"
        r'\b(\d+)\s+mejores\b',                # "10 mejores"
        r'\blas\s+(\d+)\s+mejores\b',          # "las 20 mejores"
        r'\b(\d+)\s+grandes\s+√©xitos\b',       # "15 grandes √©xitos"
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text_lower)
        if matches:
            try:
                limit = int(matches[0])
                # Validar que sea un l√≠mite razonable, no un a√±o
                if 1 <= limit <= 50 and not is_likely_year_in_context(limit, query_text):
                    logger.debug(f"üéØ L√≠mite detectado por patr√≥n '{pattern}': {limit}")
                    return limit
            except (ValueError, IndexError):
                continue
    
    return None
    
def parse_ollama_json_response(raw_response: str) -> Dict[str, Any]:
    """
    Parsea de forma robusta la respuesta JSON de Ollama.
    Maneja comillas simples, JSON mal formado, y texto extra.
    """
    if not raw_response:
        return get_default_analysis()
    
    logger.debug(f"üîß Raw response para parsing: {raw_response[:500]}...")
    
    # ‚úÖ INTENTAR PARSING DIRECTO PRIMERO
    try:
        parsed = json.loads(raw_response)
        logger.debug("‚úÖ JSON parseado directamente")
        return parsed
    except json.JSONDecodeError:
        logger.debug("‚ö†Ô∏è JSON directo fall√≥, intentando limpieza...")
    
    # ‚úÖ LIMPIAR Y REPARAR LA RESPUESTA - M√ÅS AGRESIVO
    cleaned_response = clean_ollama_response(raw_response)
    
    # ‚úÖ INTENTAR PARSING CON LA RESPUESTA LIMPIA
    try:
        parsed = json.loads(cleaned_response)
        logger.debug("‚úÖ JSON parseado despu√©s de limpieza")
        return parsed
    except json.JSONDecodeError as e:
        logger.debug(f"‚ö†Ô∏è JSON limpio tambi√©n fall√≥: {e}")
    
    # ‚úÖ EXTRAER JSON CON M√âTODOS M√ÅS AGRESIVOS
    json_candidates = extract_json_candidates(cleaned_response)
    
    for candidate in json_candidates:
        try:
            parsed = json.loads(candidate)
            logger.debug(f"‚úÖ JSON extra√≠do con m√©todo agresivo: {candidate[:100]}...")
            return parsed
        except json.JSONDecodeError:
            continue
    
    # ‚úÖ SI TODO FALLA, BUSCAR PATRONES ESPEC√çFICOS EN EL TEXTO
    analysis = extract_analysis_from_text(raw_response)
    if analysis:
        logger.debug("‚úÖ An√°lisis extra√≠do del texto")
        return analysis
    
    # ‚úÖ √öLTIMO RECURSO: USAR AN√ÅLISIS POR DEFECTO
    logger.warning("‚ö†Ô∏è No se pudo parsear JSON de Ollama, usando an√°lisis por defecto")
    return get_default_analysis()

def extract_analysis_from_text(text: str) -> Dict[str, Any]:
    """
    Extrae an√°lisis de intenci√≥n directamente del texto cuando el JSON falla - MEJORADA.
    """
    analysis = get_default_analysis()
    text_lower = text.lower()
    
    # Buscar pa√≠s en el texto
    country_patterns = {
        "chile": "Chile", "chilena": "Chile", "chileno": "Chile",
        "argentina": "Argentina", "mexico": "Mexico", "m√©xico": "Mexico",
        "espa√±a": "Spain", "colombia": "Colombia", "brasil": "Brazil",
        "per√∫": "Peru", "eeuu": "United States", "estados unidos": "United States"
    }
    
    for term, country in country_patterns.items():
        if term in text_lower:
            analysis["country"] = country
            
            # Determinar tipo de pa√≠s basado en contexto
            if any(pop_term in text_lower for pop_term in ["popular en", "escuchado en", "m√°s sonado", "√©xitos en"]):
                analysis["country_type"] = "popular_in"
            else:
                analysis["country_type"] = "origin"
                
            analysis["type"] = "country_request"
            logger.debug(f"üá®üá± Pa√≠s detectado en texto: {country} ({analysis['country_type']})")
            break
    
    # Buscar l√≠mites en el texto
    limit_match = re.search(r'"limit":\s*(\d+)', text)
    if limit_match:
        try:
            limit = int(limit_match.group(1))
            if 1 <= limit <= 50:
                analysis["limit"] = limit
                analysis["detected_limit"] = limit
                logger.debug(f"üî¢ L√≠mite detectado en texto: {limit}")
        except (ValueError, TypeError):
            pass
    
    # Buscar tipo de solicitud
    if "country_request" in text_lower or "pa√≠s" in text_lower or "country" in text_lower:
        analysis["type"] = "country_request"
    elif "artist_request" in text_lower:
        analysis["type"] = "artist_request"
    elif "similar" in text_lower:
        analysis["type"] = "similar_to_request"
    
    return analysis
    
def clean_ollama_response(response: str) -> str:
    """
    Limpia la respuesta de Ollama para hacerla JSON v√°lido - MEJORADA.
    """
    if not response:
        return "{}"
    
    # Eliminar markdown code blocks
    cleaned = re.sub(r'```json\s*', '', response)
    cleaned = re.sub(r'```\s*', '', cleaned)
    
    # Eliminar comentarios de una l√≠nea (// comentario)
    cleaned = re.sub(r'//[^\n]*', '', cleaned)
    
    # Eliminar comentarios multi-l√≠nea (/* comentario */)
    cleaned = re.sub(r'/\*.*?\*/', '', cleaned, flags=re.DOTALL)
    
    # Reemplazar comillas simples por dobles (solo en claves y valores string)
    cleaned = re.sub(r"'([^']*)'", r'"\1"', cleaned)
    
    # Corregir problemas comunes de formato
    cleaned = re.sub(r',\s*}', '}', cleaned)  # Comas sobrantes antes de }
    cleaned = re.sub(r',\s*]', ']', cleaned)  # Comas sobrantes antes de ]
    cleaned = re.sub(r'(\w+):', r'"\1":', cleaned)  # Claves sin comillas
    
    # Normalizar valores booleanos y null
    cleaned = re.sub(r':\s*true\b', ':true', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r':\s*false\b', ':false', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r':\s*null\b', ':null', cleaned, flags=re.IGNORECASE)
    cleaned = re.sub(r':\s*None\b', ':null', cleaned, flags=re.IGNORECASE)
    
    # Extraer solo el bloque JSON m√°s probable
    json_match = re.search(r'\{[^{}]*\{[^{}]*\}[^{}]*\}|\{[^{}]*\}', cleaned)
    if json_match:
        cleaned = json_match.group(0)
    
    return cleaned.strip()


def extract_json_candidates(text: str) -> List[str]:
    """
    Extrae candidatos a JSON del texto.
    """
    candidates = []
    
    # Buscar entre llaves
    brace_matches = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', text)
    candidates.extend(brace_matches)
    
    # Buscar desde el primer { hasta el √∫ltimo }
    start_idx = text.find('{')
    end_idx = text.rfind('}')
    if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
        candidates.append(text[start_idx:end_idx+1])
    
    # Filtrar por longitud razonable
    candidates = [c for c in candidates if 20 <= len(c) <= 5000]
    candidates.sort(key=len, reverse=True)  # Los m√°s largos primero
    
    return candidates


def get_default_analysis() -> Dict[str, Any]:
    """
    Retorna un an√°lisis por defecto cuando falla el parsing.
    """
    return {
        "type": "genre_or_mood_request", 
        "artist": "", 
        "track": "", 
        "album": "", 
        "genre": "", 
        "mood": "", 
        "decade": "",
        "limit": None,
        "intent": "An√°lisis por defecto",
        "detected_limit": 30
    }


def get_improved_fallback_analysis(query_text: str) -> Dict[str, Any]:
    """
    An√°lisis de fallback mejorado con detecci√≥n b√°sica.
    """
    text_lower = query_text.lower()
    
    # Detecci√≥n b√°sica de tipo
    if re.search(r"(similares a|parecidas a|similar to)", text_lower, re.I):
        ptype = "similar_to_request"
    elif re.search(r"(mejor de|best of|grandes √©xitos|top de)", text_lower, re.I):
        ptype = "artist_request"
    else:
        ptype = "genre_or_mood_request"
    
    # Detecci√≥n b√°sica de d√©cada
    decade = None
    if "80" in text_lower or "ochenta" in text_lower:
        decade = "1980s"
    elif "90" in text_lower or "noventa" in text_lower:
        decade = "1990s"
    elif "2000" in text_lower or "dos mil" in text_lower:
        decade = "2000s"
    elif "70" in text_lower or "setenta" in text_lower:
        decade = "1970s"
    
    return {
        "type": ptype, 
        "artist": "", 
        "track": "", 
        "album": "", 
        "genre": "", 
        "mood": "", 
        "decade": decade,
        "limit": None,
        "detected_limit": 30,
        "intent": f"Fallback: {query_text}"
    }


def resolve_temporal_references(analysis: Dict[str, Any], current_year: int, current_decade: int, previous_decade: int) -> Dict[str, Any]:
    """
    Resuelve referencias temporales relativas en el an√°lisis.
    """
    decade = analysis.get("decade", "")
    year_range = analysis.get("year_range", "")
    intent = analysis.get("intent", "").lower()
    
    # Mapeo de referencias relativas a d√©cadas concretas
    temporal_mappings = {
        "anterior d√©cada": f"{previous_decade}s",
        "√∫ltima d√©cada": f"{previous_decade}s", 
        "pasada d√©cada": f"{previous_decade}s",
        "d√©cada pasada": f"{previous_decade}s",
        "d√©cada anterior": f"{previous_decade}s",
        "d√©cada actual": f"{current_decade}s",
        "esta d√©cada": f"{current_decade}s",
        "hace 10 a√±os": f"{(current_year - 10) // 10 * 10}s",
        "√∫ltimos 10 a√±os": f"{(current_year - 10) // 10 * 10}s-{current_decade}s",
    }
    
    # Verificar en el intent/decade si hay referencias relativas
    for ref, resolved in temporal_mappings.items():
        if ref in intent.lower() or ref in str(decade).lower():
            analysis["decade"] = resolved
            analysis["resolved_temporal_reference"] = f"{ref} ‚Üí {resolved}"
            logger.debug(f"üï∞Ô∏è Resuelta referencia temporal: {ref} ‚Üí {resolved}")
            break
    
    # Manejar casos espec√≠ficos de "lo mejor de la anterior d√©cada"
    if "anterior d√©cada" in intent.lower() and not decade:
        analysis["decade"] = f"{previous_decade}s"
        analysis["resolved_temporal_reference"] = f"anterior d√©cada ‚Üí {previous_decade}s"
    
    return analysis


def get_improved_fallback_analysis(query_text: str) -> Dict[str, Any]:
    """
    An√°lisis de fallback mejorado con detecci√≥n robusta de pa√≠ses, a√±os espec√≠ficos y d√©cadas.
    Usado cuando el an√°lisis principal con Ollama falla.
    """
    text_lower = query_text.lower()
    default_limit = 30
    
    # ‚úÖ DETECCI√ìN DE PA√çSES en fallback
    country_analysis = detect_country_intent(query_text)
    
    # ‚úÖ DETECCI√ìN DE TIEMPO - Prioridad: a√±o espec√≠fico > rango > d√©cada
    time_analysis = detect_time_intent(query_text)
    
    # ‚úÖ DETECCI√ìN MUY CONSERVADORA DE L√çMITES
    conservative_limit = extract_conservative_limit(query_text)
    
    # ‚úÖ DETECCI√ìN DE TIPO DE SOLICITUD
    ptype = detect_query_type(text_lower, country_analysis, time_analysis)
    
    # ‚úÖ DETECCI√ìN DE G√âNERO (solo si es expl√≠cito)
    genre = detect_explicit_genre(query_text)
    
    # ‚úÖ DETECCI√ìN DE MOOD/EMOCI√ìN
    mood = detect_mood_intent(query_text)
    
    # Construir intent descriptivo
    intent_parts = []
    if country_analysis["has_country_intent"]:
        intent_parts.append(f"pa√≠s: {country_analysis['country']}({country_analysis['country_type']})")
    if time_analysis["has_time_intent"]:
        if time_analysis["year"]:
            intent_parts.append(f"a√±o: {time_analysis['year']}")
        elif time_analysis["year_range"]:
            intent_parts.append(f"rango: {time_analysis['year_range']['from']}-{time_analysis['year_range']['to']}")
        elif time_analysis["decade"]:
            intent_parts.append(f"d√©cada: {time_analysis['decade']}")
    if genre:
        intent_parts.append(f"g√©nero: {genre}")
    if mood:
        intent_parts.append(f"mood: {mood}")
    if conservative_limit:
        intent_parts.append(f"l√≠mite: {conservative_limit}")
    
    intent_description = f"Fallback: {query_text}"
    if intent_parts:
        intent_description += f" [{' | '.join(intent_parts)}]"

    return {
        "type": ptype, 
        "artist": "", 
        "track": "", 
        "album": "", 
        "genre": genre,
        "mood": mood,
        "decade": time_analysis["decade"],
        "year": time_analysis["year"],
        "year_range": time_analysis["year_range"],
        "country": country_analysis["country"],
        "country_type": country_analysis["country_type"],
        "limit": conservative_limit,
        "detected_limit": conservative_limit or default_limit,
        "intent": intent_description
    }

# ============================================================
# üé∏ Funci√≥n auxiliar para manejar exclusiones
# ============================================================
def exclude_previous_tracks(tracks: list, excluded_titles: set, excluded_paths: set):
    """Elimina de la lista las pistas que ya estaban en una playlist previa."""
    if not excluded_titles and not excluded_paths:
        return tracks

    filtered = [
        t for t in tracks
        if (t.get("Titulo", "").strip().lower() not in excluded_titles)
        and (t.get("Ruta") not in excluded_paths)
    ]
    logger.debug(f"üßπ Filtradas {len(tracks) - len(filtered)} pistas repetidas de {len(tracks)}.")
    return filtered


# ============================================================
# üéß Ejemplo de integraci√≥n dentro de handle_standard_request
# ============================================================
def handle_standard_request(query_text, llm_analysis, excluded_titles=None, excluded_paths=None):
    """
    Maneja consultas gen√©ricas (g√©nero, mood, √©poca, etc.) con soporte de regeneraci√≥n.
    """
    excluded_titles = excluded_titles or set()
    excluded_paths = excluded_paths or set()
    query_clean = normalize_text(query_text)

    logger.debug("üéº Ejecutando flujo est√°ndar (g√©nero/estado de √°nimo).")

    llm_raw = hybrid_playlist_cycle_enhanced(query_clean) or {}
    filters_raw = llm_raw.get("filters", {})
    limit = int(llm_raw.get("limit", 50) or 50)

    filters_enriched = enrich_filters_with_acoustics(query_clean, filters_raw)
    filters_safe = sanitize_filters(filters_enriched)
    mongo_filters = dict(filters_safe)

    results = list(tracks_col.find(mongo_filters))
    results = exclude_previous_tracks(results, excluded_titles, excluded_paths)

    global_max = get_global_max_values()
    for t in results:
        t["PopularityScore"] = compute_popularity(t, global_max)

    results = deduplicate_tracks_by_title_keep_best(results)
    compute_relative_popularity_by_genre(results)
    results.sort(key=lambda x: x.get("RelativePopularityScore", 0), reverse=True)
    final_results = results[:limit]

    simplified = [{
        "Ruta": t.get("Ruta"),
        "Titulo": t.get("Titulo"),
        "Artista": t.get("Artista"),
        "Album": t.get("Album"),
        "A√±o": t.get("A√±o"),
        "Genero": t.get("Genero"),
        "Duracion_mmss": t.get("Duracion_mmss"),
        "Bitrate": t.get("Bitrate"),
        "Calidad": t.get("Calidad"),
        "CoverCarpeta": t.get("CoverCarpeta"),
        "RelativePopularityScore": t.get("RelativePopularityScore"),
        "PopularityDisplay": popularity_display(t.get("RelativePopularityScore")),
    } for t in final_results]

    m3u_path, playlist_uuid = save_m3u(simplified, re.sub(r"[^\w\s-]", "", query_clean)[:60])
    playlist_doc = {
        "query_original": query_text,
        "filters": mongo_filters,
        "limit": limit,
        "created_at": datetime.now(),
        "m3u_path": m3u_path,
        "playlist_uuid": playlist_uuid,
        "items": simplified,
        "stats": {"total": len(simplified), "regenerated": bool(excluded_titles)},
        "feedback_pending": True,
        "user_email": user_email,
    }

    res = playlists_col.insert_one(playlist_doc)
    playlist_id = str(res.inserted_id)

    return {
        "query_original": query_text,
        "filtros": mongo_filters,
        "criterio_orden": "RelativePopularityScore",
        "total": len(simplified),
        "playlist": simplified,
        "archivo_m3u": m3u_path,
        "playlist_id": playlist_id,
        "playlist_uuid": playlist_uuid,
        "debug_summary": {
            "standard_mode": True,
            "llm_analysis": llm_analysis,
            "excluded_count": len(excluded_titles),
        },
    }

# =========================================================
# üî¢ Funci√≥n para detectar l√≠mites num√©ricos en prompts
# =========================================================
def extract_limit_from_prompt(prompt_text: str, default_limit: int = 30) -> int:
    """
    Funci√≥n mantenida para compatibilidad.
    Ahora delega la detecci√≥n a analyze_query_intent para mayor precisi√≥n.
    """
    try:
        analysis = analyze_query_intent(prompt_text)
        return analysis.get("detected_limit", default_limit)
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Error en extract_limit_from_prompt: {e}")
        return default_limit

def _looks_like_year(number: int, text: str) -> bool:
    """
    Mantenida para compatibilidad, ahora usa la funci√≥n mejorada.
    """
    return is_likely_year_in_context(number, text)


# -----------------------
# get user's playlists
# -----------------------
@app.get("/user/playlists")
def get_user_playlists(request: Request):
    """Obtiene todas las playlists generadas por el usuario actual"""
    try:
        # Obtener el token de autorizaci√≥n
        auth_header = request.headers.get("Authorization")
        if not auth_header:
            raise HTTPException(status_code=401, detail="Authorization header missing")
        
        token = auth_header.replace("Bearer ", "")
        
        # Buscar el usuario por token
        user = db_auth.users.find_one({"session_token": token})
        if not user:
            raise HTTPException(status_code=401, detail="Invalid token")
        
        user_email = user.get("email")
        
        # Buscar playlists del usuario (asumiendo que guardamos el email del usuario)
        playlists = list(playlists_col.find({"user_email": user_email}).sort("created_at", -1))
        
        # Convertir ObjectId a string
        for playlist in playlists:
            playlist["_id"] = str(playlist["_id"])
        
        return {
            "user": user_email,
            "playlists": playlists,
            "total": len(playlists)
        }
        
    except Exception as e:
        logger.error(f"Error getting user playlists: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

# -----------------------
# update playlist name
# -----------------------
@app.put("/playlist/{pid}/name")
def update_playlist_name(pid: str, request: Request):
    """Actualiza el nombre de una playlist"""
    try:
        # Verificar autenticaci√≥n
        auth_header = request.headers.get("Authorization")
        if not auth_header:
            raise HTTPException(status_code=401, detail="Authorization header missing")
        
        token = auth_header.replace("Bearer ", "")
        user = db_auth.users.find_one({"session_token": token})
        if not user:
            raise HTTPException(status_code=401, detail="Invalid token")
        
        # Obtener datos del body
        body = request.json()
        new_name = body.get("name")
        
        if not new_name:
            raise HTTPException(status_code=400, detail="Name is required")
        
        # Actualizar playlist
        result = playlists_col.update_one(
            {"_id": ObjectId(pid), "user_email": user.get("email")},
            {"$set": {"name": new_name}}
        )
        
        if result.modified_count == 0:
            raise HTTPException(status_code=404, detail="Playlist not found or access denied")
        
        return {"message": "Playlist name updated successfully"}
        
    except Exception as e:
        logger.error(f"Error updating playlist name: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")    
        
        
# -----------------------
# delete playlist
# -----------------------
@app.delete("/playlist/{pid}")
def delete_playlist(pid: str, request: Request):
    """Elimina una playlist del usuario"""
    try:
        # Verificar autenticaci√≥n
        auth_header = request.headers.get("Authorization")
        if not auth_header:
            raise HTTPException(status_code=401, detail="Authorization header missing")
        
        token = auth_header.replace("Bearer ", "")
        user = db_auth.users.find_one({"session_token": token})
        if not user:
            raise HTTPException(status_code=401, detail="Invalid token")
        
        # Eliminar playlist
        result = playlists_col.delete_one({
            "_id": ObjectId(pid), 
            "user_email": user.get("email")
        })
        
        if result.deleted_count == 0:
            raise HTTPException(status_code=404, detail="Playlist not found or access denied")
        
        return {"message": "Playlist deleted successfully"}
        
    except Exception as e:
        logger.error(f"Error deleting playlist: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")        
        
# -----------------------
# get user's specific playlist (with security)
# -----------------------
@app.get("/user/playlist/{pid}")
def get_user_playlist(pid: str, request: Request):
    """Obtiene una playlist espec√≠fica del usuario actual"""
    try:
        # Verificar autenticaci√≥n
        auth_header = request.headers.get("Authorization")
        if not auth_header:
            raise HTTPException(status_code=401, detail="Authorization header missing")
        
        token = auth_header.replace("Bearer ", "")
        user = db_auth.users.find_one({"session_token": token})
        if not user:
            raise HTTPException(status_code=401, detail="Invalid token")
        
        user_email = user.get("email")
        
        # Buscar playlist espec√≠fica del usuario
        try:
            oid = ObjectId(pid)
        except Exception:
            raise HTTPException(status_code=400, detail="Invalid playlist ID")
        
        playlist = playlists_col.find_one({
            "_id": oid, 
            "user_email": user_email  # ‚úÖ Solo playlists del usuario
        })
        
        if not playlist:
            raise HTTPException(status_code=404, detail="Playlist not found or access denied")
        
        # Convertir ObjectId a string y limpiar respuesta
        playlist["id"] = str(playlist["_id"])
        playlist.pop("_id", None)
        
        # ‚úÖ Asegurar que las URLs de streaming est√©n presentes
        if "items" in playlist and isinstance(playlist["items"], list):
            for item in playlist["items"]:
                if item.get("Ruta"):
                    item["StreamURL"] = convert_path_to_url(item["Ruta"])
                if item.get("CoverCarpeta"):
                    item["CoverURL"] = convert_path_to_url(item.get("CoverCarpeta"))
        
        return {
            "playlist": playlist,
            "user": user_email
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting user playlist: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

# -----------------------
# Helper function para convertir rutas a URLs (si no existe)
# -----------------------
def convert_path_to_url(local_path: str) -> str:
    """Convierte ruta local a URL HTTP accesible."""
    if not local_path:
        return ""
    path_fixed = local_path.replace("\\", "/")
    if path_fixed.lower().startswith("f:/musica/"):
        rel_path = path_fixed[9:]  # quitar "F:/Musica/"
        rel_path = urllib.parse.quote(rel_path)
        return f"http://192.168.100.169:8000/media/{rel_path}"
    return local_path        
    
def validate_and_normalize_limit(limit_candidate: Any, original_query: str) -> int:
    """
    Valida y normaliza el l√≠mite detectado, con verificaciones contextuales.
    """
    default_limit = 30
    
    # Caso 1: L√≠mite es None o vac√≠o
    if limit_candidate is None:
        return default_limit
    
    # Caso 2: L√≠mite es string - extraer n√∫meros
    if isinstance(limit_candidate, str):
        numbers = re.findall(r'\d+', limit_candidate)
        if not numbers:
            return default_limit
        try:
            limit_candidate = int(numbers[0])
        except (ValueError, TypeError):
            return default_limit
    
    # Caso 3: L√≠mite es n√∫mero - validar
    if isinstance(limit_candidate, (int, float)):
        limit_value = int(limit_candidate)
        
        # ‚úÖ Verificar rangos razonables
        if not (1 <= limit_value <= 100):
            logger.debug(f"üî¢ L√≠mite {limit_value} fuera de rango, usando default")
            return default_limit
        
        # ‚úÖ VERIFICACI√ìN CONTEXTUAL CR√çTICA: ¬øEs realmente un l√≠mite o un a√±o?
        if is_likely_year_in_context(limit_value, original_query):
            logger.debug(f"üî¢ N√∫mero {limit_value} parece ser a√±o/d√©cada, ignorando como l√≠mite")
            return default_limit
        
        # ‚úÖ Verificar contexto de palabras clave alrededor del n√∫mero
        if not has_limit_context(limit_value, original_query):
            logger.debug(f"üî¢ N√∫mero {limit_value} sin contexto de l√≠mite, ignorando")
            return default_limit
        
        logger.debug(f"üî¢ L√≠mite validado: {limit_value}")
        return limit_value
    
    return default_limit
    
def is_likely_year_in_context(number: int, query: str) -> bool:
    """
    Determina si un n√∫mero probablemente se refiere a un a√±o/d√©cada.
    Versi√≥n mejorada para fallback.
    """
    query_lower = query.lower()
    
    # Si el n√∫mero est√° en rango de a√±os
    if 1950 <= number <= 2030:
        # Contextos que indican a√±o/d√©cada
        year_indicators = [
            'a√±o', 'a√±os', 'decada', 'd√©cada', 'year', 'years', 'decade',
            'del', 'de los', 'de las', 'en', 'del a√±o', 'los', 'las'
        ]
        
        # Patrones espec√≠ficos de d√©cada/a√±o
        decade_patterns = [
            f"{number}s",
            f"{number}'s", 
            f"a√±o {number}",
            f"a√±os {number}",
            f"decada {number}",
            f"d√©cada {number}",
            f"del {number}",
            f"los {number}",
            f"las {number}"
        ]
        
        # Verificar si hay indicadores temporales cerca del n√∫mero
        has_temporal_context = any(indicator in query_lower for indicator in year_indicators)
        has_decade_pattern = any(pattern in query_lower for pattern in decade_patterns)
        
        # Si el n√∫mero est√° junto a palabras temporales, es probablemente un a√±o
        words = query_lower.split()
        try:
            number_index = words.index(str(number))
            # Verificar palabras cercanas
            start = max(0, number_index - 2)
            end = min(len(words), number_index + 3)
            context_words = words[start:end]
            
            has_nearby_temporal = any(word in year_indicators for word in context_words)
            
            return has_temporal_context or has_decade_pattern or has_nearby_temporal
            
        except ValueError:
            return has_temporal_context or has_decade_pattern
    
    return False

def has_limit_context(number: int, query: str) -> bool:
    """
    Verifica si el n√∫mero aparece en un contexto que sugiere l√≠mite de cantidad.
    """
    query_lower = query.lower()
    
    # Palabras clave que indican contexto de l√≠mite/cantidad
    limit_indicators = [
        'top', 'primeros', 'primeras', 'mejores', 'mejor', 
        'canciones', 'temas', 'pistas', 'tracks', 'songs',
        'lista', 'list', 'solo', 'solamente', '√∫nicamente',
        'las', 'los', 'primer', 'primera'
    ]
    
    # Buscar el n√∫mero en el texto y verificar palabras cercanas
    number_pattern = fr'\b{number}\b'
    match = re.search(number_pattern, query_lower)
    
    if not match:
        return False
    
    number_pos = match.start()
    
    # Extraer contexto alrededor del n√∫mero (10 palabras antes/despu√©s)
    words = query_lower.split()
    try:
        number_index = words.index(str(number))
        start = max(0, number_index - 5)
        end = min(len(words), number_index + 6)
        context_words = words[start:end]
        
        # Verificar si hay indicadores de l√≠mite en el contexto
        context_has_indicators = any(indicator in ' '.join(context_words) for indicator in limit_indicators)
        return context_has_indicators
        
    except ValueError:
        return False

def get_conservative_fallback_analysis(query_text: str) -> Dict[str, Any]:
    """
    An√°lisis de fallback ultra-conservador para cuando Ollama falla.
    Solo detecta l√≠mites en casos muy expl√≠citos y evita a√±os/d√©cadas.
    """
    text_lower = query_text.lower()
    default_limit = 30
    
    # ‚úÖ DETECCI√ìN MUY CONSERVADORA DE L√çMITES
    conservative_limit = None
    
    # Solo patrones muy expl√≠citos de l√≠mites
    explicit_limit_patterns = [
        r'\b(?:top|primer[oa]s?)\s+(\d+)\s+(?:canciones|temas|pistas)\b',
        r'\b(\d+)\s+(?:canciones|temas|pistas)\s+(?:de|para)\b',
        r'\b(?:las|los)\s+(\d+)\s+mejores\s+(?:canciones|temas)\b',
    ]
    
    for pattern in explicit_limit_patterns:
        match = re.search(pattern, text_lower)
        if match:
            try:
                candidate = int(match.group(1))
                # Verificaci√≥n extra conservadora
                if (1 <= candidate <= 50) and not is_likely_year_in_context(candidate, query_text):
                    conservative_limit = candidate
                    break
            except (ValueError, IndexError):
                continue
    
    # Determinar tipo
    if re.search(r"(similares a|parecidas a|similar to)", text_lower, re.I):
        ptype = "similar_to_request"
    elif re.search(r"(mejor de|best of|grandes √©xitos|top de)", text_lower, re.I):
        ptype = "artist_request"
    else:
        ptype = "genre_or_mood_request"
    
    return {
        "type": ptype, 
        "artist": "", "track": "", "album": "", 
        "genre": "", "mood": "", "decade": "",
        "limit": conservative_limit,
        "detected_limit": conservative_limit or default_limit,
        "intent": f"Fallback: {query_text}"
    }    
    
def collect_enriched_context(max_artists: int = 80, max_genres: int = 50, max_decades: int = 10) -> Dict[str, Any]:
    """
    Recolecta contexto enriquecido de la base de datos para el modelo.
    Incluye estad√≠sticas, patrones y relaciones entre artistas/g√©neros/√©pocas.
    """
    try:
        # üìä ARTISTAS M√ÅS POPULARES por g√©nero
        pipeline_artists = [
            {"$group": {
                "_id": "$Artista", 
                "count": {"$sum": 1},
                "avg_popularity": {"$avg": "$PopularityScore"},
                "genres": {"$addToSet": "$Genero"},
                "decades": {"$addToSet": "$Decada"}
            }},
            {"$sort": {"avg_popularity": -1, "count": -1}},
            {"$limit": max_artists}
        ]
        top_artists = list(tracks_col.aggregate(pipeline_artists))
        
        # üéµ G√âNEROS M√ÅS COMUNES con ejemplos de artistas
        pipeline_genres = [
            {"$unwind": "$Genero"},
            {"$group": {
                "_id": "$Genero",
                "count": {"$sum": 1},
                "artist_sample": {"$addToSet": "$Artista"},
                "avg_tempo": {"$avg": "$TempoBPM"},
                "avg_energy": {"$avg": "$EnergyRMS"}
            }},
            {"$sort": {"count": -1}},
            {"$limit": max_genres}
        ]
        top_genres = list(tracks_col.aggregate(pipeline_genres))
        
        # üï∞Ô∏è D√âCADAS DISPONIBLES con distribuci√≥n
        pipeline_decades = [
            {"$group": {
                "_id": "$Decada",
                "count": {"$sum": 1},
                "top_genres": {"$push": "$Genero"}
            }},
            {"$sort": {"count": -1}},
            {"$limit": max_decades}
        ]
        decades_info = list(tracks_col.aggregate(pipeline_decades))
        
        # üé≠ PATRONES EMOCIONALES por g√©nero
        emotional_patterns = {}
        for genre_doc in top_genres[:15]:  # Solo los 15 g√©neros m√°s comunes
            genre = genre_doc["_id"]
            emotion_stats = tracks_col.aggregate([
                {"$match": {"Genero": genre}},
                {"$group": {
                    "_id": "$EMO_Sound",
                    "count": {"$sum": 1},
                    "avg_tempo": {"$avg": "$TempoBPM"},
                    "avg_energy": {"$avg": "$EnergyRMS"}
                }},
                {"$sort": {"count": -1}},
                {"$limit": 3}
            ])
            emotional_patterns[genre] = list(emotion_stats)
        
        # üèÜ ARTISTAS POR D√âCADA (para contexto temporal)
        artists_by_decade = {}
        for decade_doc in decades_info:
            decade = decade_doc["_id"]
            decade_artists = tracks_col.distinct("Artista", {"Decada": decade})
            # Tomar los m√°s populares de esa d√©cada
            artists_by_decade[decade] = decade_artists[:10]  # Top 10 por d√©cada
        
        context = {
            "artists": [artist["_id"] for artist in top_artists],
            "artists_detailed": top_artists[:20],  # Info detallada de top 20
            "genres": [genre["_id"] for genre in top_genres],
            "genres_detailed": top_genres[:15],    # Info detallada de top 15 g√©neros
            "decades": [decade["_id"] for decade in decades_info],
            "decades_detailed": decades_info,
            "emotional_patterns": emotional_patterns,
            "artists_by_decade": artists_by_decade,
            "stats": {
                "total_artists": len(top_artists),
                "total_genres": len(top_genres),
                "total_decades": len(decades_info)
            }
        }
        
        logger.debug(f"üéØ Contexto enriquecido: {len(context['artists'])} artistas, {len(context['genres'])} g√©neros, {len(context['decades'])} d√©cadas")
        return context
        
    except Exception as e:
        logger.debug(f"Error obteniendo contexto enriquecido: {e}")
        return {"artists": [], "genres": [], "decades": []}    

def hybrid_playlist_cycle_enhanced(user_prompt: str, model="neoplaylist-agent", default_limit=30, llm_analysis=None):
    """
    Ciclo h√≠brido mejorado que prioriza filtros de pa√≠s cuando est√°n presentes.
    MEJORAS:
    - Manejo robusto de errores en cada fase
    - Cache de an√°lisis sem√°ntico
    - L√≠mites din√°micos basados en complejidad
    - M√©tricas de rendimiento
    - Fallbacks inteligentes
    """
    start_time = time.time()
    logger.debug(f"üß† Nueva consulta h√≠brida MEJORADA: '{user_prompt}'")
    
    try:
        # üéØ CONTEXTO ENRIQUECIDO desde el inicio
        enriched_context = collect_enriched_context()
        
        # ‚úÖ AN√ÅLISIS SEM√ÅNTICO MEJORADO (con cache opcional)
        if llm_analysis is None:
            llm_analysis = analyze_query_intent(user_prompt)
        
        # üî¢ AJUSTAR L√çMITE BASADO EN COMPLEJIDAD
        adjusted_limit = adjust_limit_based_on_complexity(user_prompt, default_limit, llm_analysis)
        logger.debug(f"üéØ L√≠mite ajustado: {default_limit} ‚Üí {adjusted_limit}")
        
        # üìù PROMPT MEJORADO para la FASE 1 - INCLUIR FILTROS DE PA√çS EXPL√çCITAMENTE
        phase1_prompt = build_enhanced_prompt_with_country(user_prompt, enriched_context, llm_analysis)
        
        logger.debug(f"üì§ PROMPT FASE 1 ENVIADO A OLLAMA:")
        logger.debug(phase1_prompt[:500] + "..." if len(phase1_prompt) > 500 else phase1_prompt)
        
        # FASE 1: Recomendaciones iniciales con contexto completo
        result = call_ollama_safe(phase1_prompt, model) or {}
        logger.debug(f"üì• RESPUESTA OLLAMA FASE 1: {len(result.get('suggestions', []))} sugerencias")
        
        # ‚úÖ COMBINAR FILTROS: Pa√≠s del an√°lisis + respuesta de Ollama
        llm_filters = result.get("filters", {}) if isinstance(result, dict) else {}
        suggestions = result.get("suggestions", []) if isinstance(result, dict) else []
        
        # ‚úÖ FORZAR FILTROS DE PA√çS SI EST√ÅN EN EL AN√ÅLISIS
        if llm_analysis.get("country"):
            if not llm_filters:
                llm_filters = {}
            llm_filters["country"] = llm_analysis["country"]
            llm_filters["country_type"] = llm_analysis.get("country_type", "origin")
            logger.debug(f"üá®üá± FORZANDO filtro de pa√≠s: {llm_analysis['country']} ({llm_analysis['country_type']})")
        
        # Procesar filtros y b√∫squeda
        filters = parse_filters_from_llm(llm_filters)
        filters = enrich_filters_with_acoustics(user_prompt, filters)
        
        # ‚úÖ DEBUG DETALLADO DE FILTROS
        logger.debug(f"üéØ FILTROS PARA B√öSQUEDA: {list(filters.keys())}")
        
        # üéµ B√öSQUEDA CON M√âTRICAS
        search_start = time.time()
        local_tracks = search_tracks_in_mongo(suggestions, filters, adjusted_limit, tracks_col, user_prompt)
        search_time = time.time() - search_start
        
        logger.debug(f"üéØ Fase 1: {len(local_tracks)} pistas en {search_time:.2f}s / objetivo {adjusted_limit}")
        
        if len(local_tracks) >= adjusted_limit:
            return finalize_enhanced_response(user_prompt, filters, local_tracks, 1, adjusted_limit, start_time, llm_analysis)
        
        # üîÑ FASE 2: Completitud con contexto ESPEC√çFICO del problema
        missing = adjusted_limit - len(local_tracks)
        logger.debug(f"üîÑ Fase 2: Necesitamos {missing} pistas m√°s")
        
        phase2_prompt = build_completion_prompt_with_country(user_prompt, filters, local_tracks, enriched_context, missing, llm_analysis)
        
        result2 = call_ollama_safe(phase2_prompt, model) or {}
        
        # ‚úÖ MANTENER FILTROS DE PA√çS EN FASE 2
        suggestions2 = []
        if isinstance(result2, dict):
            suggestions2 = result2.get("suggestions", [])
            new_filters = result2.get("filters")
            if new_filters and isinstance(new_filters, dict):
                filters = new_filters
        
        # ‚úÖ ASEGURAR que los filtros de pa√≠s se mantengan
        if llm_analysis.get("country") and not has_country_filters(filters):
            country_filters = parse_filters_from_llm({
                "country": llm_analysis["country"],
                "country_type": llm_analysis.get("country_type", "origin")
            })
            filters.update(country_filters)
            logger.debug(f"üá®üá± REAPLICANDO filtros de pa√≠s en Fase 2")
        
        local_tracks2 = search_tracks_in_mongo(suggestions2, filters, missing, tracks_col, user_prompt)
        local_tracks.extend(local_tracks2)
        logger.debug(f"üéØ Fase 2: +{len(local_tracks2)} nuevas pistas ‚Üí total {len(local_tracks)}")
        
        if len(local_tracks) >= adjusted_limit:
            return finalize_enhanced_response(user_prompt, filters, local_tracks, 2, adjusted_limit, start_time, llm_analysis)
        
        # ‚úÖ FASE 3: Validaci√≥n manteniendo contexto de pa√≠s
        phase3_prompt = build_validation_prompt_with_country(user_prompt, filters, local_tracks, enriched_context, llm_analysis)
        
        result3 = call_ollama_safe(phase3_prompt, model) or {}
        
        validated = extract_validated_tracks(result3, local_tracks, adjusted_limit)
        
        # üéØ APLICAR POST-PROCESAMIENTO INTELIGENTE
        final_tracks = apply_intelligent_postprocessing(validated, user_prompt, llm_analysis, adjusted_limit)
        
        logger.debug(f"‚úÖ Fase 3 finalizada ‚Äî {len(final_tracks)} pistas validadas")
        
        return finalize_enhanced_response(user_prompt, filters, final_tracks, 3, adjusted_limit, start_time, llm_analysis)
        
    except Exception as e:
        logger.error(f"üí• ERROR en ciclo h√≠brido: {e}")
        # üÜò FALLBACK DE EMERGENCIA
        return emergency_fallback(user_prompt, default_limit, start_time, str(e))

def build_validation_prompt_with_country(user_prompt: str, filters: dict, current_tracks: list, 
                                       context: Dict[str, Any], analysis: Dict[str, Any]) -> str:
    """
    Construye prompt para Fase 3 (validaci√≥n) manteniendo contexto.
    """
    country_info = ""
    if analysis.get("country"):
        country_info = f"CRITERIO PA√çS: {analysis['country']} ({analysis.get('country_type', 'origin')})"
    
    decade_info = ""
    if analysis.get("decade"):
        decade_info = f"CRITERIO D√âCADA: {analysis['decade']}"
    
    # Analizar distribuci√≥n actual
    artists_count = {}
    for t in current_tracks:
        artist = t.get("Artista")
        if artist:
            artists_count[artist] = artists_count.get(artist, 0) + 1
    
    problem_artists = [artist for artist, count in artists_count.items() if count > 3]
    
    prompt = f"""
VALIDA y DEPURA esta playlist seg√∫n la petici√≥n original.

Petici√≥n: "{user_prompt}"
{country_info}
{decade_info}

Lista actual ({len(current_tracks)} pistas):
{chr(10).join([f"- {t.get('Artista', '?')} - {t.get('Titulo', '?')} ({t.get('Genero', '?')}, {t.get('A√±o', '?')})" for t in current_tracks[:15]])}

PROBLEMAS DETECTADOS:
- Artistas con muchas canciones: {', '.join(problem_artists) if problem_artists else 'Ninguno'}

INSTRUCCIONES DE VALIDACI√ìN:
1. ELIMINA canciones que NO coincidan con pa√≠s/d√©cada/g√©nero solicitado
2. LIMITA a m√°ximo 3 canciones por artista
3. MANT√âN la diversidad musical
4. CONSERVA las canciones m√°s populares y representativas

Devuelve EXCLUSIVAMENTE JSON con las pistas validadas:
{{
  "suggestions": [
    {{"titulo": "...", "artista": "...", "album": "..."}}
  ]
}}
"""
    return prompt
    
def build_completion_prompt_with_country(user_prompt: str, filters: dict, current_tracks: list, 
                                       context: Dict[str, Any], missing: int, analysis: Dict[str, Any]) -> str:
    """
    Construye prompt para Fase 2 (completitud) manteniendo contexto de pa√≠s/d√©cada.
    """
    country_info = ""
    if analysis.get("country"):
        country_info = f"Pa√≠s: {analysis['country']} ({analysis.get('country_type', 'origin')})"
    
    decade_info = ""
    if analysis.get("decade"):
        decade_info = f"D√©cada: {analysis['decade']}"
    
    current_artists = list(set(t.get("Artista") for t in current_tracks if t.get("Artista")))
    
    prompt = f"""
FALTAN RESULTADOS para completar la playlist. Necesito {missing} pistas m√°s.

Petici√≥n original: "{user_prompt}"
{country_info}
{decade_info}

Filtros aplicados: {json.dumps(filters, ensure_ascii=False, default=str)}

Pistas ya incluidas ({len(current_tracks)}):
{chr(10).join([f"- {t.get('Artista', '?')} - {t.get('Titulo', '?')}" for t in current_tracks[:10]])}

Artistas ya incluidos: {', '.join(current_artists[:15])}

CONTEXTO LOCAL DISPONIBLE:
Artistas: {', '.join(context.get('artists', [])[:25])}

INSTRUCCIONES:
1. Sugiere NUEVOS artistas o canciones que NO est√©n en la lista anterior
2. MANT√âN los filtros de pa√≠s/d√©cada/g√©nero
3. Prioriza diversidad de artistas
4. Sugiere hasta {min(missing * 2, 20)} opciones

Devuelve EXCLUSIVAMENTE JSON:
{{
  "suggestions": [
    {{"titulo": "...", "artista": "...", "album": "..."}}
  ]
}}
"""
    return prompt
    
def adjust_limit_based_on_complexity(user_prompt: str, base_limit: int, llm_analysis: dict) -> int:
    """
    Ajusta el l√≠mite basado en la complejidad de la consulta.
    """
    complexity_score = 0
    
    # Factores de complejidad
    if llm_analysis.get("country"):
        complexity_score += 1
    if llm_analysis.get("decade"):
        complexity_score += 1
    if llm_analysis.get("genre"):
        complexity_score += 1
    if llm_analysis.get("mood"):
        complexity_score += 1
    if llm_analysis.get("artist"):
        complexity_score += 2  # Las b√∫squedas de artista son m√°s espec√≠ficas
    
    # Ajustar l√≠mite: consultas m√°s complejas ‚Üí l√≠mites m√°s peque√±os
    if complexity_score >= 3:
        return min(base_limit, 20)
    elif complexity_score >= 2:
        return min(base_limit, 25)
    else:
        return base_limit    

def has_country_filters(filters: dict) -> bool:
    """
    Verifica si los filtros ya incluyen criterios de pa√≠s.
    """
    country_indicators = ["ArtistArea", "TopCountry1", "TopCountry2", "TopCountry3", "country"]
    return any(indicator in filters for indicator in country_indicators)

def extract_validated_tracks(result3: any, local_tracks: list, limit: int) -> list:
    """
    Extrae y valida pistas de la respuesta de la Fase 3.
    """
    validated = []
    
    if isinstance(result3, dict):
        validated = result3.get("suggestions", []) or local_tracks
    elif isinstance(result3, list):
        validated = result3
    else:
        validated = local_tracks
    
    # Si elimin√≥ demasiadas, rellenar con las previas coherentes
    if not validated or len(validated) < limit:
        validated = validated or local_tracks
        # Mantener el orden original tanto como sea posible
        additional_tracks = [t for t in local_tracks if t not in validated]
        validated.extend(additional_tracks[:limit - len(validated)])
    
    return validated[:limit]

def emergency_fallback(user_prompt: str, limit: int, start_time: float, error_msg: str):
    """
    Fallback de emergencia cuando falla el ciclo principal.
    """
    logger.warning(f"üÜò Activando fallback de emergencia: {error_msg}")
    
    try:
        # B√∫squeda simple por palabras clave
        words = [w for w in re.split(r"\W+", user_prompt.lower()) if len(w) > 3]
        if words:
            regex_or = [
                {"Genero": {"$regex": w, "$options": "i"}} for w in words
            ] + [
                {"Titulo": {"$regex": w, "$options": "i"}} for w in words
            ] + [
                {"Artista": {"$regex": w, "$options": "i"}} for w in words
            ]
            
            fallback_q = {"$or": regex_or}
            fallback_tracks = list(tracks_col.find(fallback_q).limit(limit * 2))
            
            # Procesar resultados del fallback
            processed_tracks = apply_intelligent_postprocessing(fallback_tracks, user_prompt, {}, limit)
            
            return finalize_enhanced_response(
                user_prompt, 
                {"fallback": True, "error": error_msg},
                processed_tracks, 
                0,  # Iteraci√≥n 0 indica fallback
                limit, 
                start_time, 
                None
            )
    except Exception as fallback_error:
        logger.error(f"üí• Fallback tambi√©n fall√≥: {fallback_error}")
    
    # √öltimo recurso: pistas aleatorias populares
    random_tracks = list(tracks_col.find().sort("PopularityScore", -1).limit(limit))
    return finalize_enhanced_response(
        user_prompt,
        {"emergency_fallback": True},
        random_tracks,
        0,
        limit,
        start_time,
        None
    )
    
def finalize_enhanced_response(prompt: str, filters: dict, tracks: list, iterations: int, 
                             limit: int, start_time: float, llm_analysis: dict = None):
    """
    Versi√≥n mejorada de finalize_response con m√©tricas.
    """
    total_time = time.time() - start_time
    
    # Enriquecer pistas con URLs
    for t in tracks:
        ruta = t.get("Ruta")
        cover = t.get("CoverCarpeta")
        
        if ruta:
            t["StreamURL"] = convert_path_to_url(ruta)
        if cover:
            t["CoverURL"] = convert_path_to_url(cover)
    
    response = {
        "prompt": prompt,
        "filters": filters,
        "limit": limit,
        "iterations": iterations,
        "total_found": len(tracks),
        "from_local": len(tracks),
        "playlist": tracks,
        "performance_metrics": {
            "total_time_seconds": round(total_time, 2),
            "tracks_per_second": round(len(tracks) / total_time, 2) if total_time > 0 else 0,
            "llm_analysis_used": llm_analysis is not None
        }
    }
    
    # A√±adir an√°lisis sem√°ntico si est√° disponible
    if llm_analysis:
        response["semantic_analysis"] = {
            "type": llm_analysis.get("type"),
            "genre": llm_analysis.get("genre"),
            "decade": llm_analysis.get("decade"),
            "country": llm_analysis.get("country"),
            "detected_limit": llm_analysis.get("detected_limit")
        }
    
    logger.debug(f"üìä M√©tricas finales: {response['performance_metrics']}")
    
    return response    
    
def apply_intelligent_postprocessing(tracks: list, user_prompt: str, llm_analysis: dict, limit: int) -> list:
    """
    Aplica post-procesamiento inteligente a las pistas.
    """
    if not tracks:
        return tracks
    
    # 1. Calcular m√©tricas de popularidad
    global_max = get_global_max_values()
    for t in tracks:
        t["PopularityScore"] = compute_popularity(t, global_max)
    
    # 2. Deduplicar
    deduped = deduplicate_tracks_by_title_keep_best(tracks)
    
    # 3. Normalizar por g√©nero
    compute_relative_popularity_by_genre(deduped)
    
    # 4. Filtrar incongruencias
    filtered = filter_gross_incongruities(deduped, user_prompt)
    
    # 5. Aplicar l√≠mites por artista/√°lbum
    limited = limit_tracks_by_artist_album(filtered)
    
    # 6. Ordenar por popularidad relativa
    limited.sort(key=lambda x: x.get("RelativePopularityScore", 0), reverse=True)
    
    return limited[:limit]

    
def build_enhanced_prompt_with_country(user_prompt: str, context: Dict[str, Any], analysis: Dict[str, Any]) -> str:
    """
    Construye prompt mejorado para Fase 1 con soporte de pa√≠s y d√©cada.
    """
    # Construir secci√≥n de criterios espec√≠ficos
    criteria_sections = []
    
    if analysis.get("country"):
        country = analysis["country"]
        country_type = analysis.get("country_type", "origin")
        criteria_sections.append(f"üéØ PA√çS: {country} ({'origen del artista' if country_type == 'origin' else 'popularidad en el pa√≠s'})")
    
    if analysis.get("decade"):
        decade = analysis["decade"]
        criteria_sections.append(f"üéØ D√âCADA: {decade}")
    
    if analysis.get("genre"):
        genre = analysis["genre"]
        criteria_sections.append(f"üéØ G√âNERO: {genre}")
    
    criteria_text = "\n".join(criteria_sections) if criteria_sections else "üéØ CRITERIO GENERAL: M√∫sica popular y representativa"

    # Formatear contexto de artistas y g√©neros
    artists_sample = ", ".join(context.get('artists', [])[:25]) if context.get('artists') else "No disponible"
    genres_sample = ", ".join(context.get('genres', [])[:20]) if context.get('genres') else "No disponible"
    
    prompt = f"""
ANALIZA esta solicitud musical y genera recomendaciones ESPEC√çFICAS:

SOLICITUD DEL USUARIO: "{user_prompt}"

{criteria_text}

BASE DE DATOS DISPONIBLE:
- Artistas: {artists_sample}
- G√©neros: {genres_sample}

INSTRUCCIONES CR√çTICAS:
1. Sugiere canciones REALES que existan en la base de datos
2. Respeta ESTRICTAMENTE los criterios de pa√≠s/d√©cada/g√©nero
3. Prioriza canciones POPULARES y REPRESENTATIVAS
4. Incluye entre 5-15 sugerencias espec√≠ficas
5. Usa EXCLUSIVAMENTE artistas del contexto proporcionado

EJEMPLOS DE SUGERENCIAS V√ÅLIDAS:
- Para "rock de los 90s": "Smells Like Teen Spirit", "Wonderwall", "Creep"
- Para "pop chileno": "La Ley", "Los Prisioneros", "Los Tres"

DEVUELVE EXCLUSIVAMENTE JSON (sin texto adicional):
{{
  "filters": {{
    "Genero": "rock",
    "Decada": "1990s"
  }},
  "suggestions": [
    {{"titulo": "Smells Like Teen Spirit", "artista": "Nirvana", "album": "Nevermind"}},
    {{"titulo": "Wonderwall", "artista": "Oasis", "album": "(What's the Story) Morning Glory?"}},
    {{"titulo": "Creep", "artista": "Radiohead", "album": "Pablo Honey"}}
  ]
}}
"""

    return prompt

def emergency_country_search(country: str, country_type: str, limit: int = 30) -> List[Dict[str, Any]]:
    """
    B√∫squeda directa de emergencia por pa√≠s con prioridad jer√°rquica en TopCountry.
    """
    logger.debug(f"üö® B√öSQUEDA DE EMERGENCIA para pa√≠s: {country} ({country_type})")
    
    all_results = []
    
    if country_type == "origin":
        # B√∫squeda por origen del artista
        query = {"ArtistArea": {"$regex": f"^{re.escape(country)}$", "$options": "i"}}
        try:
            results = list(tracks_col.find(query).sort("PopularityScore", -1).limit(limit * 3))
            all_results.extend(results)
            logger.debug(f"üö® Resultados por ORIGEN: {len(results)} tracks")
        except Exception as e:
            logger.error(f"üö® Error en b√∫squeda por origen: {e}")
    
    else:
        # ‚úÖ B√öSQUEDA JER√ÅRQUICA POR TOPCOUNTRY
        # 1. Primero TopCountry1 (m√°s relevante)
        try:
            query_tc1 = {"TopCountry1": {"$regex": f"^{re.escape(country)}$", "$options": "i"}}
            results_tc1 = list(tracks_col.find(query_tc1).sort("PopularityScore", -1).limit(limit))
            all_results.extend(results_tc1)
            logger.debug(f"üö® Resultados TopCountry1: {len(results_tc1)} tracks")
            
            # 2. Si no alcanzamos el l√≠mite, buscar en TopCountry2
            if len(all_results) < limit:
                remaining = limit - len(all_results)
                query_tc2 = {
                    "TopCountry2": {"$regex": f"^{re.escape(country)}$", "$options": "i"},
                    "_id": {"$nin": [r["_id"] for r in all_results]}  # Evitar duplicados
                }
                results_tc2 = list(tracks_col.find(query_tc2).sort("PopularityScore", -1).limit(remaining))
                all_results.extend(results_tc2)
                logger.debug(f"üö® + Resultados TopCountry2: {len(results_tc2)} tracks")
            
            # 3. Si a√∫n no alcanzamos el l√≠mite, buscar en TopCountry3
            if len(all_results) < limit:
                remaining = limit - len(all_results)
                query_tc3 = {
                    "TopCountry3": {"$regex": f"^{re.escape(country)}$", "$options": "i"},
                    "_id": {"$nin": [r["_id"] for r in all_results]}  # Evitar duplicados
                }
                results_tc3 = list(tracks_col.find(query_tc3).sort("PopularityScore", -1).limit(remaining))
                all_results.extend(results_tc3)
                logger.debug(f"üö® + Resultados TopCountry3: {len(results_tc3)} tracks")
                
        except Exception as e:
            logger.error(f"üö® Error en b√∫squeda jer√°rquica: {e}")
    
    # Ordenar todos los resultados por popularidad
    all_results.sort(key=lambda x: x.get("PopularityScore", 0), reverse=True)
    
    # Aplicar l√≠mite final
    final_results = all_results[:limit]
    
    # ‚úÖ DEBUG: Mostrar distribuci√≥n por TopCountry
    if country_type != "origin":
        tc1_count = len([r for r in final_results if r.get("TopCountry1") and country.lower() in r.get("TopCountry1", "").lower()])
        tc2_count = len([r for r in final_results if r.get("TopCountry2") and country.lower() in r.get("TopCountry2", "").lower()])
        tc3_count = len([r for r in final_results if r.get("TopCountry3") and country.lower() in r.get("TopCountry3", "").lower()])
        logger.debug(f"üìä Distribuci√≥n TopCountry: TC1={tc1_count}, TC2={tc2_count}, TC3={tc3_count}")
    
    logger.debug(f"üö® Resultados finales de emergencia: {len(final_results)} tracks")
    return final_results
        
def build_enhanced_prompt(user_prompt: str, context: Dict[str, Any], mode: str) -> str:
    logger.debug(f"üîß Construyendo prompt para modo: {mode}")
    logger.debug(f"üîß Contexto recibido: {len(context.get('artists', []))} artistas, {len(context.get('genres', []))} g√©neros")
    """
    Construye prompts enriquecidos seg√∫n el modo de operaci√≥n.
    """
    base_prompt = f"""
Usuario solicita: "{user_prompt}"

üéØ CONTEXTO ENRIQUECIDO DE LA BASE DE DATOS:

ARTISTAS DISPONIBLES ({len(context.get('artists', []))}):
{format_artists_context(context)}

G√âNEROS DISPONIBLES ({len(context.get('genres', []))}):
{format_genres_context(context)}

D√âCADAS DISPONIBLES:
{format_decades_context(context)}

PATRONES EMOCIONALES POR G√âNERO:
{format_emotional_patterns(context)}

"""
    
    if mode == "initial_recommendation":
        base_prompt += """
INSTRUCCIONES PARA RECOMENDACI√ìN INICIAL:
1. Usa SOLO los g√©neros y artistas listados arriba
2. Para "m√∫sica alegre": prioriza pop, disco, dance, synthpop, funk
3. Para "rock energ√©tico": prioriza classic rock, hard rock, alternative
4. Considera los patrones emocionales t√≠picos de cada g√©nero
5. Sugiere artistas que existan en la lista disponible

Devuelve JSON con formato est√°ndar.
"""
    
    elif mode == "completion":
        base_prompt += """
INSTRUCCIONES PARA COMPLETITUD:
1. Faltan resultados - necesitas completar la playlist
2. PRIORIZA artistas de la lista disponible
3. Usa los patrones emocionales como gu√≠a
4. Si el g√©nero solicitado es escaso, sugiere g√©neros relacionados
5. Incluye una "razon" para cada sugerencia

Devuelve JSON con formato de completitud.
"""
    
    return base_prompt

def format_artists_context(context: Dict[str, Any]) -> str:
    """Formatea la informaci√≥n de artistas para el prompt"""
    artists = context.get("artists", [])
    detailed = context.get("artists_detailed", [])
    
    if not artists:
        return "No hay datos de artistas disponibles"
    
    # Agrupar artistas por d√©cada de mayor actividad
    artists_by_decade = {}
    for artist in detailed[:25]:  # Top 25 artistas
        decades = artist.get("decades", [])
        primary_decade = decades[0] if decades else "Desconocida"
        artists_by_decade.setdefault(primary_decade, []).append(artist["_id"])
    
    formatted = []
    for decade, artists_list in list(artists_by_decade.items())[:5]:  # Top 5 d√©cadas
        formatted.append(f"  {decade}: {', '.join(artists_list[:8])}")
    
    return "\n".join(formatted) + f"\n  ... y {len(artists) - 25} artistas m√°s"

def format_genres_context(context: Dict[str, Any]) -> str:
    """Formatea la informaci√≥n de g√©neros para el prompt"""
    genres_detailed = context.get("genres_detailed", [])
    
    if not genres_detailed:
        return "No hay datos de g√©neros disponibles"
    
    formatted = []
    for genre in genres_detailed[:15]:  # Top 15 g√©neros
        artists_sample = genre.get("artist_sample", [])[:5]
        formatted.append(
            f"  {genre['_id']}: {genre['count']} pistas, "
            f"tempo {genre.get('avg_tempo', 0):.0f} BPM, "
            f"energ√≠a {genre.get('avg_energy', 0):.2f}"
        )
    
    return "\n".join(formatted)

def format_emotional_patterns(context: Dict[str, Any]) -> str:
    """Formatea los patrones emocionales por g√©nero"""
    patterns = context.get("emotional_patterns", {})
    
    if not patterns:
        return "No hay datos de patrones emocionales"
    
    formatted = []
    for genre, emotions in list(patterns.items())[:10]:  # Top 10 g√©neros
        if emotions:
            primary_emotion = emotions[0]
            formatted.append(
                f"  {genre}: {primary_emotion['_id']} "
                f"({primary_emotion['count']} pistas)"
            )
    
    return "\n".join(formatted)

def format_decades_context(context: Dict[str, Any]) -> str:
    """Formatea la informaci√≥n de d√©cadas"""
    decades_detailed = context.get("decades_detailed", [])
    
    if not decades_detailed:
        return "No hay datos de d√©cadas disponibles"
    
    formatted = []
    for decade in decades_detailed:
        formatted.append(f"  {decade['_id']}: {decade['count']} pistas")
    
    return "\n".join(formatted)    
    
def build_completion_prompt(user_prompt: str, current_filters: Dict, current_tracks: List, 
                          context: Dict[str, Any], missing_count: int) -> str:
    """
    Prompt mejorado para completitud con an√°lisis del problema actual.
    """
    current_artists = list(set(track.get("Artista") for track in current_tracks))
    current_genres = list(set(
        genre for track in current_tracks 
        for genre in (track.get("Genero") or [])
        if genre
    ))
    
    return f"""
PROBLEMA DE COMPLETITUD:
- Solicitud original: "{user_prompt}"
- Faltan {missing_count} pistas para completar la playlist
- Filtros actuales: {json.dumps(current_filters, ensure_ascii=False)}

CONTEXTO ACTUAL:
- Artistas ya incluidos: {', '.join(current_artists[:8]) or 'Ninguno'}
- G√©neros ya incluidos: {', '.join(current_genres[:8]) or 'Ninguno'}

BASE DE DATOS DISPONIBLE:
{format_artists_context(context)}
{format_genres_context(context)}

INSTRUCCIONES CR√çTICAS:
1. EVITA repetir artistas ya incluidos
2. PRIORIZA g√©neros coherentes pero diferentes a los ya usados
3. Usa artistas de la lista disponible que encajen con el prompt
4. Para "m√∫sica alegre": si hay mucho metal, sugiere m√°s pop/dance
5. Incluye "razon" explicando por qu√© cada sugerencia encaja

Devuelve JSON de completitud.
"""

def build_validation_prompt(user_prompt: str, current_filters: Dict, 
                          current_tracks: List, context: Dict[str, Any]) -> str:
    """
    Prompt mejorado para validaci√≥n final con an√°lisis de coherencia.
    """
    # Analizar distribuci√≥n actual
    artist_counts = {}
    genre_counts = {}
    
    for track in current_tracks:
        artist = track.get("Artista")
        genres = track.get("Genero") or []
        
        artist_counts[artist] = artist_counts.get(artist, 0) + 1
        for genre in genres:
            genre_counts[genre] = genre_counts.get(genre, 0) + 1
    
    # Identificar posibles problemas
    overrepresented_artists = [a for a, c in artist_counts.items() if c > len(current_tracks) * 0.2]
    overrepresented_genres = [g for g, c in genre_counts.items() if c > len(current_tracks) * 0.3]
    
    return f"""
VALIDACI√ìN FINAL SOLICITADA:
- Prompt original: "{user_prompt}"
- {len(current_tracks)} pistas para validar

AN√ÅLISIS ACTUAL:
- Distribuci√≥n por artista: {dict(sorted(artist_counts.items(), key=lambda x: x[1], reverse=True)[:5])}
- Distribuci√≥n por g√©nero: {dict(sorted(genre_counts.items(), key=lambda x: x[1], reverse=True)[:5])}
- Posibles problemas: {{
    "artistas_sobrerrepresentados": {overrepresented_artists},
    "g√©neros_sobrerrepresentados": {overrepresented_genres}
}}

CONTEXTO DE G√âNEROS PARA COHERENCIA:
{format_genres_context(context)}

INSTRUCCIONES DE VALIDACI√ìN:
1. Elimina pistas que NO encajen con "{user_prompt}"
2. Limita a m√°ximo 20% por artista ({max(2, len(current_tracks) // 5)} pistas/artista)
3. Limita a m√°ximo 2 pistas por √°lbum
4. Prioriza coherencia emocional y de g√©nero
5. Mant√©n diversidad art√≠stica

Devuelve JSON de validaci√≥n con lista filtrada.
"""    

def detect_country_intent(query_text: str) -> Dict[str, Any]:
    """
    Detecta intenci√≥n de filtrado por pa√≠s en el prompt.
    Versi√≥n mejorada para fallback.
    """
    text_lower = query_text.lower()
    
    # Mapeo de pa√≠ses comunes
    country_mappings = {
        "chile": "Chile", "chilena": "Chile", "chileno": "Chile",
        "argentina": "Argentina", "argentino": "Argentina", "argentina": "Argentina",
        "m√©xico": "Mexico", "mexico": "Mexico", "mexicana": "Mexico", "mexicano": "Mexico",
        "espa√±a": "Spain", "espa√±ola": "Spain", "espa√±ol": "Spain", "spain": "Spain",
        "colombia": "Colombia", "colombiano": "Colombia",
        "brasil": "Brazil", "brasile√±a": "Brazil", "brasile√±o": "Brazil",
        "per√∫": "Peru", "peruana": "Peru", "peruano": "Peru",
        "eeuu": "United States", "estados unidos": "United States", "usa": "United States",
        "reino unido": "United Kingdom", "uk": "United Kingdom", "british": "United Kingdom",
        "francia": "France", "francesa": "France", "franc√©s": "France",
        "alemania": "Germany", "alemana": "Germany", "alem√°n": "Germany",
        "italia": "Italy", "italiana": "Italy", "italiano": "Italy",
        "jap√≥n": "Japan", "japonesa": "Japan", "japon√©s": "Japan"
    }
    
    detected_country = None
    for term, country in country_mappings.items():
        if term in text_lower:
            detected_country = country
            break
    
    # Detectar tipo de filtro por pa√≠s
    country_type = "origin"  # Por defecto, origen del artista
    
    # Patrones para "popular en [pa√≠s]"
    popular_in_patterns = [
        r"popular en (\w+)",
        r"escuchado en (\w+)", 
        r"m√°s sonado en (\w+)",
        r"√©xitos en (\w+)",
        r"lo m√°s escuchado en (\w+)"
    ]
    
    for pattern in popular_in_patterns:
        match = re.search(pattern, text_lower)
        if match:
            country_type = "popular_in"
            break
    
    # Si no se detect√≥ popular_in, buscar patrones de origen
    if country_type == "origin":
        origin_patterns = [
            r"m√∫sica (\w+)",  # "m√∫sica chilena"
            r"artistas (\w+)",  # "artistas chilenos"
            r"bandas (\w+)",  # "bandas argentinas"
            r"cantantes (\w+)",  # "cantantes mexicanos"
            r"del (\w+)",  # "musica del per√∫"
            r"de (\w+)$"  # "musica de chile"
        ]
        
        for pattern in origin_patterns:
            match = re.search(pattern, text_lower)
            if match:
                country_type = "origin"
                break

    return {
        "country": detected_country,
        "country_type": country_type,
        "has_country_intent": detected_country is not None
    }
    
def detect_time_intent(query_text: str) -> Dict[str, Any]:
    """
    Detecta intenci√≥n temporal: a√±o espec√≠fico, rango de a√±os o d√©cada.
    """
    text_lower = query_text.lower()
    
    # 1Ô∏è‚É£ BUSCAR A√ëO ESPEC√çFICO primero (prioridad m√°xima)
    year_match = re.search(r'\b(19|20)\d{2}\b', query_text)
    year_specific = None
    if year_match:
        year_candidate = int(year_match.group())
        # Validar que sea un a√±o razonable y no parte de otra cosa
        if 1950 <= year_candidate <= 2030:
            # Verificar contexto - no debe ser parte de una d√©cada
            context = query_text.lower()
            if not any(decade_term in context for decade_term in ["d√©cada", "decada", "a√±os", "los"]):
                year_specific = year_candidate
                logger.debug(f"üìÖ A√±o espec√≠fico detectado en fallback: {year_specific}")
    
    # 2Ô∏è‚É£ BUSCAR RANGO DE A√ëOS
    year_range = None
    range_match = re.search(r'(\d{4})\s*(?:a|al|hasta|y|-)\s*(\d{4})', query_text)
    if range_match:
        start_year = int(range_match.group(1))
        end_year = int(range_match.group(2))
        if 1950 <= start_year <= end_year <= 2030:
            year_range = {"from": start_year, "to": end_year}
            logger.debug(f"üìÖ Rango de a√±os detectado: {start_year}-{end_year}")
    
    # 3Ô∏è‚É£ BUSCAR D√âCADAS (solo si no hay a√±o espec√≠fico ni rango)
    decade = None
    if not year_specific and not year_range:
        decade_patterns = {
            "70": "1970s", "setenta": "1970s", "70s": "1970s",
            "80": "1980s", "ochenta": "1980s", "80s": "1980s", 
            "90": "1990s", "noventa": "1990s", "90s": "1990s",
            "2000": "2000s", "dos mil": "2000s", "2000s": "2000s",
            "2010": "2010s", "dos mil diez": "2010s", "2010s": "2010s",
            "2020": "2020s", "dos mil veinte": "2020s", "2020s": "2020s"
        }
        
        for term, decade_value in decade_patterns.items():
            if term in text_lower:
                # Verificar que sea contexto de d√©cada, no a√±o suelto
                if f"a√±os {term}" in text_lower or f"d√©cada {term}" in text_lower or f"los {term}" in text_lower:
                    decade = decade_value
                    logger.debug(f"üï∞Ô∏è D√©cada detectada en fallback: {decade}")
                    break
                elif term in ["70s", "80s", "90s", "2000s", "2010s", "2020s"]:
                    # Si termina en 's', es muy probable que sea d√©cada
                    decade = decade_value
                    logger.debug(f"üï∞Ô∏è D√©cada detectada por sufijo: {decade}")
                    break
    
    # 4Ô∏è‚É£ DETECTAR M√öLTIPLES D√âCADAS
    multiple_decades = []
    if not year_specific and not year_range and not decade:
        decade_terms = []
        for term in ["70", "80", "90", "2000", "2010", "2020"]:
            if term in text_lower:
                decade_terms.append(term)
        
        if len(decade_terms) >= 2:
            decade_map = {"70": "1970s", "80": "1980s", "90": "1990s", "2000": "2000s", "2010": "2010s", "2020": "2020s"}
            multiple_decades = [decade_map[term] for term in decade_terms if term in decade_map]
            if multiple_decades:
                decade = multiple_decades  # Lista de d√©cadas
                logger.debug(f"üï∞Ô∏è M√∫ltiples d√©cadas detectadas: {multiple_decades}")

    return {
        "year": year_specific,
        "year_range": year_range,
        "decade": decade,
        "has_time_intent": any([year_specific, year_range, decade])
    }
    
def extract_conservative_limit(query_text: str) -> Optional[int]:
    """
    Extrae l√≠mites de forma ultra-conservadora para evitar falsos positivos.
    """
    text_lower = query_text.lower()
    
    # Solo patrones muy expl√≠citos de l√≠mites
    explicit_limit_patterns = [
        r'\b(?:top|primer[oa]s?)\s+(\d+)\s+(?:canciones|temas|pistas|temas)\b',
        r'\b(\d+)\s+(?:canciones|temas|pistas)\s+(?:de|para)\b',
        r'\b(?:las|los)\s+(\d+)\s+mejores\s+(?:canciones|temas)\b',
        r'\b(?:primer|primera)\s+(\d+)\s+(?:canciones|temas)\b',
        r'\bsolo\s+(\d+)\s+(?:canciones|temas)\b',
        r'\b(?:√∫nicamente|solamente)\s+(\d+)\s+(?:canciones|temas)\b'
    ]
    
    for pattern in explicit_limit_patterns:
        match = re.search(pattern, text_lower)
        if match:
            try:
                candidate = int(match.group(1))
                # Verificaci√≥n extra conservadora
                if (1 <= candidate <= 50) and not is_likely_year_in_context(candidate, query_text):
                    logger.debug(f"üî¢ L√≠mite conservador detectado: {candidate}")
                    return candidate
            except (ValueError, IndexError):
                continue
    
    return None
    
def detect_query_type(text_lower: str, country_analysis: Dict, time_analysis: Dict) -> str:
    """
    Determina el tipo de consulta basado en patrones espec√≠ficos.
    """
    # 1. Solicitudes de pa√≠s tienen prioridad
    if country_analysis["has_country_intent"]:
        return "country_request"
    
    # 2. Solicitudes de similitud
    if re.search(r"(similares a|parecidas a|similar a|como|recomendaciones de)", text_lower, re.I):
        return "similar_to_request"
    
    # 3. Solicitudes de artista espec√≠fico
    if re.search(r"(mejor de|best of|grandes √©xitos|top de|discograf√≠a de|canciones de)\s+[^0-9]", text_lower, re.I):
        return "artist_request"
    
    # 4. Solicitudes de √°lbum
    if re.search(r"(√°lbum|album|disco)\s+.+\s+(de|del)", text_lower, re.I):
        return "album_request"
    
    # 5. Por defecto, g√©nero/mood/√©poca
    return "genre_or_mood_request"    
    
def detect_explicit_genre(query_text: str) -> Optional[str]:
    """
    Detecta g√©neros musicales solo cuando son expl√≠citamente mencionados.
    Evita a√±adir g√©neros por defecto como "pop".
    """
    text_lower = query_text.lower()
    
    # G√©neros expl√≠citos y sus patrones
    explicit_genres = {
        "rock": ["rock", "rock and roll", "rock & roll"],
        "pop": ["pop", "m√∫sica pop"],
        "jazz": ["jazz"],
        "blues": ["blues"],
        "reggae": ["reggae"],
        "hip hop": ["hip hop", "hip-hop", "rap"],
        "electronic": ["electr√≥nica", "electr√≥nico", "electronic", "edm"],
        "classical": ["cl√°sica", "cl√°sico", "classical"],
        "folk": ["folk", "folcl√≥rica", "folcl√≥rico"],
        "metal": ["metal", "heavy metal"],
        "punk": ["punk"],
        "reggaeton": ["reggaeton", "reguet√≥n"],
        "salsa": ["salsa"],
        "cumbia": ["cumbia"],
        "bachata": ["bachata"],
        "tango": ["tango"],
        "bolero": ["bolero"]
    }
    
    for genre, patterns in explicit_genres.items():
        for pattern in patterns:
            if pattern in text_lower:
                # Verificar que no sea parte de una palabra m√°s larga
                if re.search(r'\b' + re.escape(pattern) + r'\b', text_lower):
                    logger.debug(f"üéµ G√©nero expl√≠cito detectado: {genre}")
                    return genre
    
    return None

def detect_mood_intent(query_text: str) -> Optional[str]:
    """
    Detecta intenciones de mood/emoci√≥n en el prompt.
    """
    text_lower = query_text.lower()
    
    mood_mappings = {
        "alegre": ["alegre", "feliz", "contento", "alegr√≠a", "felicidad"],
        "triste": ["triste", "tristeza", "melancol√≠a", "melanc√≥lico"],
        "energ√©tico": ["energ√©tico", "energ√©tica", "energ√≠a", "potente", "intenso"],
        "relajante": ["relajante", "relajado", "calma", "tranquilo", "suave"],
        "rom√°ntico": ["rom√°ntico", "rom√°ntica", "amor", "pasi√≥n", "coraz√≥n"],
        "nost√°lgico": ["nost√°lgico", "nostalgia", "recuerdos"],
        "bailable": ["bailable", "baile", "fiesta", "party", "dance"]
    }
    
    for mood, terms in mood_mappings.items():
        for term in terms:
            if term in text_lower:
                logger.debug(f"üòä Mood detectado: {mood}")
                return mood
    
    return None    
    
def get_topcountry_distribution(tracks: List[Dict[str, Any]], country: str) -> Dict[str, int]:
    """
    Calcula la distribuci√≥n de canciones por TopCountry para un pa√≠s espec√≠fico.
    """
    distribution = {"TopCountry1": 0, "TopCountry2": 0, "TopCountry3": 0}
    country_lower = country.lower()
    
    for track in tracks:
        if track.get("TopCountry1") and country_lower in track.get("TopCountry1", "").lower():
            distribution["TopCountry1"] += 1
        elif track.get("TopCountry2") and country_lower in track.get("TopCountry2", "").lower():
            distribution["TopCountry2"] += 1
        elif track.get("TopCountry3") and country_lower in track.get("TopCountry3", "").lower():
            distribution["TopCountry3"] += 1
    
    return distribution    
    
    
REGION_DEFINITIONS = {
    "latin_america": {
        "name": "Latinoam√©rica",
        "countries": [
            "Mexico", "Argentina", "Chile", "Colombia", "Peru", "Brazil",
            "Cuba", "Puerto Rico", "Dominican Republic", "Venezuela",
            "Ecuador", "Uruguay", "Paraguay", "Bolivia", "Costa Rica",
            "Panama", "Guatemala", "Honduras", "El Salvador", "Nicaragua"
        ],
        "description": "Pa√≠ses de Am√©rica Latina y el Caribe"
    },
    "europe": {
        "name": "Europa", 
        "countries": [
            "Spain", "France", "Italy", "Germany", "United Kingdom", "Portugal",
            "Netherlands", "Belgium", "Switzerland", "Sweden", "Norway", "Denmark",
            "Finland", "Ireland", "Austria", "Greece", "Poland", "Russia"
        ],
        "description": "Pa√≠ses europeos"
    },
    "asia": {
        "name": "Asia",
        "countries": [
            "Japan", "South Korea", "China", "India", "Thailand", "Philippines",
            "Vietnam", "Indonesia", "Malaysia", "Singapore", "Taiwan"
        ],
        "description": "Pa√≠ses asi√°ticos"
    },
    "north_america": {
        "name": "Am√©rica del Norte", 
        "countries": ["United States", "Canada"],
        "description": "Estados Unidos y Canad√°"
    },
    "africa": {
        "name": "√Åfrica",
        "countries": [
            "Nigeria", "South Africa", "Egypt", "Kenya", "Ghana", "Morocco",
            "Ethiopia", "Tanzania", "Algeria", "Uganda"
        ],
        "description": "Pa√≠ses africanos"
    },
        "Oceania": {
        "name": "Oceania",
        "countries": [
            "australia", "Fiyi", "Kiribati", "Islas Marshall", "Micronesia",
            "Nauru", "Nueva Zelanda", "Palaos", "Pap√∫a Nueva Guinea", "Samoa",
            "Islas Salom√≥n", "Tonga", "Tuvalu", "Vanuatu"
        ],
        "description": "Pa√≠ses Oceania"
    }
}
def compute_region_relevance_score(track: Dict[str, Any], region_id: str, user_genre: str = None) -> float:
    """
    Calcula un score de relevancia para una regi√≥n espec√≠fica
    Considera popularidad + coherencia regional + g√©nero si est√° especificado
    """
    base_popularity = track.get("RelativePopularityScore", 0) or track.get("PopularityScore", 0)
    
    # Score base de popularidad (0-1)
    popularity_score = min(1.0, base_popularity * 1.5)  # Ajustar escala
    
    # Bonus por coherencia regional (artistas muy representativos de su regi√≥n)
    regional_bonus = compute_regional_representativeness(track, region_id)
    
    # Bonus por matching de g√©nero si el usuario lo especific√≥
    genre_bonus = 0.0
    if user_genre:
        genre_bonus = compute_genre_match_bonus(track, user_genre, region_id)
    
    # F√≥rmula final
    final_score = (
        popularity_score * 0.7 +      # Popularidad es lo m√°s importante
        regional_bonus * 0.2 +        # Representatividad regional
        genre_bonus * 0.1             # G√©nero espec√≠fico si se pidi√≥
    )
    
    return round(final_score, 4)

def compute_regional_representativeness(track: Dict[str, Any], region_id: str) -> float:
    """
    Calcula qu√© tan representativo es un artista de su regi√≥n
    Basado en popularidad regional y distintividad cultural
    """
    score = 0.0
    
    # Bonus por alta popularidad en pa√≠ses de la regi√≥n
    region_countries = REGION_DEFINITIONS[region_id]["countries"]
    track_countries = []
    
    # Verificar TopCountry matches
    for i in range(1, 4):
        country_field = f"TopCountry{i}"
        country = track.get(country_field)
        if country and country in region_countries:
            score += 0.1  # Bonus por ser popular en su propia regi√≥n
    
    # Bonus por idioma distintivo de la regi√≥n
    language = track.get("Idioma", "").lower()
    if region_id == "latin_america" and language in ["spanish", "portuguese"]:
        score += 0.15
    elif region_id == "asia" and language in ["japanese", "korean", "mandarin", "hindi"]:
        score += 0.15
    
    # Bonus por g√©nero culturalmente distintivo (sin ser restrictivo)
    genre = track.get("Genero")
    if genre and is_culturally_distinctive(genre, region_id):
        score += 0.1
    
    return min(score, 0.3)  # Cap m√°ximo

def compute_genre_match_bonus(track: Dict[str, Any], user_genre: str, region_id: str) -> float:
    """
    Bonus adicional cuando el usuario especifica un g√©nero
    """
    track_genre = track.get("Genero")
    if not track_genre:
        return 0.0
    
    # Normalizar g√©neros para matching
    track_genres = [track_genre] if isinstance(track_genre, str) else track_genre
    user_genre_lower = user_genre.lower()
    
    # Matching exacto o parcial
    for genre in track_genres:
        if genre and user_genre_lower in genre.lower():
            return 0.2  # Bonus por matching de g√©nero
    
    return 0.0

def is_culturally_distinctive(genre, region_id: str) -> bool:
    """
    Identifica g√©neros musicalmente distintivos de cada regi√≥n
    SIN ser exclusivo - solo para bonus de relevancia
    """
    distinctive_genres = {
        "latin_america": {"salsa", "merengue", "bachata", "cumbia", "reggaeton", "samba", "tango", "bossa nova"},
        "asia": {"k-pop", "j-pop", "mandopop", "c-pop", "bollywood", "anison"},
        "africa": {"afrobeats", "highlife", "soukous", "bongo flava", "gqom"},
        "europe": {"europop", "eurodance", "eurodisco", "schlager", "fado", "flamenco"}
    }
    
    genre_str = genre.lower() if isinstance(genre, str) else str(genre).lower()
    region_genres = distinctive_genres.get(region_id, set())
    
    return any(distinctive in genre_str for distinctive in region_genres)    
    
def search_tracks_by_region(region_id: str, user_genre: str = None, limit: int = 30) -> List[Dict[str, Any]]:
    """
    Busca tracks por regi√≥n geogr√°fica con ordenamiento inteligente
    """
    if region_id not in REGION_DEFINITIONS:
        logger.warning(f"‚ö†Ô∏è Regi√≥n desconocida: {region_id}")
        return []
    
    region_countries = REGION_DEFINITIONS[region_id]["countries"]
    
    # Filtro base: origen geogr√°fico
    base_query = {"ArtistArea": {"$in": region_countries}}
    
    # Si el usuario especific√≥ g√©nero, a√±adirlo como filtro (no restrictivo)
    if user_genre:
        base_query["Genero"] = {"$regex": user_genre, "$options": "i"}
    
    logger.debug(f"üó∫Ô∏è Buscando {limit} tracks para regi√≥n {region_id}, g√©nero: {user_genre or 'cualquiera'}")
    
    try:
        # Primera pasada: obtener candidatos
        candidate_tracks = list(tracks_col.find(base_query).limit(limit * 3))  # Buscar m√°s para seleccionar
        
        if not candidate_tracks:
            logger.debug(f"‚ö†Ô∏è No se encontraron tracks para regi√≥n {region_id}")
            return []
        
        # Calcular scores de relevancia regional para cada track
        for track in candidate_tracks:
            track["RegionRelevanceScore"] = compute_region_relevance_score(
                track, region_id, user_genre
            )
        
        # Ordenar por relevancia regional + popularidad
        candidate_tracks.sort(
            key=lambda x: (
                x.get("RegionRelevanceScore", 0), 
                x.get("RelativePopularityScore", 0)
            ), 
            reverse=True
        )
        
        # Aplicar l√≠mites por artista/√°lbum
        final_tracks = limit_tracks_by_artist_album(candidate_tracks)
        
        logger.debug(f"üéØ Regi√≥n {region_id}: {len(candidate_tracks)} candidatos ‚Üí {len(final_tracks)} finales")
        
        return final_tracks[:limit]
        
    except Exception as e:
        logger.error(f"‚ùå Error en b√∫squeda por regi√≥n {region_id}: {e}")
        return []    
        
def build_region_genre_prompt(user_prompt: str, context: Dict[str, Any], analysis: Dict[str, Any]) -> str:
    """
    Prompt que maneja combinaciones de regi√≥n + g√©nero
    """
    
    region_info = ""
    detected_region = analysis.get("region")
    user_genre = analysis.get("genre")
    
    if detected_region and detected_region in REGION_DEFINITIONS:
        region_data = REGION_DEFINITIONS[detected_region]
        region_info = f"""
üéØ SOLICITUD REGIONAL DETECTADA: {region_data['name']}
- REGI√ìN: {region_data['description']}
- Pa√≠ses: {', '.join(region_data['countries'][:6])}{'...' if len(region_data['countries']) > 6 else ''}
- G√©nero solicitado: {user_genre or 'CUALQUIER g√©nero'}
- INSTRUCCI√ìN: Buscar artistas de ESTA regi√≥n + g√©nero si se especifica
- NO limitar a g√©neros "t√≠picos" - incluir TODOS los g√©neros de la regi√≥n
        """
    
    prompt = f"""
ANALIZA esta solicitud musical y genera recomendaciones INTELIGENTES:

SOLICITUD: "{user_prompt}"

{region_info}

CONTEXTO DISPONIBLE:
- Artistas: {', '.join(context.get('artists', [])[:20])}
- G√©neros: {', '.join(context.get('genres', [])[:12])}

INSTRUCCIONES CR√çTICAS:
1. Para "m√∫sica [regi√≥n]": filtrar por ORIGEN geogr√°fico (ArtistArea)
2. Para "[g√©nero] de [regi√≥n]": combinar origen + g√©nero
3. NO asumir g√©neros espec√≠ficos para regiones
4. Priorizar popularidad + representatividad regional

EJEMPLOS:
- "rock asi√°tico" ‚Üí artistas asi√°ticos + g√©nero rock
- "m√∫sica latina" ‚Üí artistas latinoamericanos (cualquier g√©nero)
- "pop europeo" ‚Üí artistas europeos + g√©nero pop

PARA "{user_prompt}", devuelve JSON:
{{
  "filters": {{
    "region": "{detected_region if detected_region else ''}",
    "genre": "{user_genre if user_genre else ''}"
  }},
  "suggestions": ["artistas representativos de la regi√≥n"],
  "sort_by": "RegionRelevanceScore",  // ‚úÖ NUEVO campo
  "order": -1
}}
"""
    return prompt        

def detect_region_from_query(query_text: str) -> Optional[str]:
    """
    Detecta autom√°ticamente la regi√≥n solicitada en el query
    """
    query_lower = query_text.lower()
    
    for region, keywords in REGION_DEFINITIONS .items():
        if any(keyword in query_lower for keyword in keywords):
            logger.debug(f"üó∫Ô∏è Regi√≥n detectada: {region}")
            return region
    
    return None

def enhance_region_detection(analysis: Dict[str, Any], query_text: str) -> Dict[str, Any]:
    """
    Mejora el an√°lisis con detecci√≥n de regiones
    """
    detected_region = detect_region_from_query(query_text)
    
    if detected_region:
        region_info = REGION_DEFINITIONS[detected_region]
        
        analysis.update({
            "type": "region_request",
            "region": detected_region,
            "region_name": region_info["name"],
            "genre": None,  # Limpiar g√©nero vago
            "country": None,
            "country_type": None,
            "region_corrected": True,
            "intent": f"M√∫sica {region_info['name']}: {query_text}"
        })
        logger.debug(f"üó∫Ô∏è Correcci√≥n aplicada: Regi√≥n {region_info['name']}")
    
    return analysis    